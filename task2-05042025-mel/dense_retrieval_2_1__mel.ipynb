{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E4iAVd-eqO5"
      },
      "source": [
        "## !! Important: Do not forget to save your notebook frequently to avoid losing your progress if the colab session crashes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVR1DtqCeqO7"
      },
      "source": [
        "### Download precalculated embedding tables\n",
        "\n",
        "We have preencoded all the texts into vectors and saved them as numpy tables to save time. You can download this zipped file to your current Google Colab working space under the `content` directory by following the steps below, ensuring it won't occupy any space in your Google Drive.\n",
        "\n",
        "However, please note that you will need to redownload it each time you quit Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxEkWrtVeqO8",
        "outputId": "ee52ba1a-e5f3-4d1e-f16b-cfbc5296bbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK\n",
            "From (redirected): https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK&confirm=t&uuid=eac2dc79-487a-4007-87bb-bc1f820b7659\n",
            "To: /content/embeddings.tar.gz\n",
            "100% 316M/316M [00:08<00:00, 37.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download precalculated embeddings via a google drive shared link\n",
        "!gdown 'https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK'\n",
        "\n",
        "# if error \"failed to retrieve file url: too many users ....\" ==> solution:\n",
        "# https://stackoverflow.com/questions/65312867/how-to-download-large-file-from-google-drive-from-terminal-gdown-doesnt-work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-oVL1rHeqO9"
      },
      "source": [
        "if error \"failed to retrieve file url: too many users ....\" => solution:\n",
        "https://stackoverflow.com/questions/65312867/how-to-download-large-file-from-google-drive-from-terminal-gdown-doesnt-work\n",
        "\n",
        "\n",
        "**TODO: replace ACCESS_TOKEN in the next block** (your personal token generateed following the steps in previous solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Sc7jQDeqO9"
      },
      "outputs": [],
      "source": [
        "# ACCESS_TOKEN = \"ya29.a0Ad52N39RvcgSxR64dCWPRT2zf7ryi0ib0oPhXi7lte1Nho0Agtz0eTf7cmND4VDIQGSHw0IA6RqL_Zi1T7MsYiObSIrdn3anaSMSZPUBN1To4WSDcuPcYRkUC6xoZOdU2MkHTb_IZCQI5nOJEdY0UH20rNAG4cAXBdsvaCgYKAUgSARMSFQHGX2Mi3HfwxDpNGH4ku8ghMpfEPg0171\" # CHANGE TO YOUR OWN TOKEN\n",
        "# FILE_ID1 = \"1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK\" # DO NOT CHANGE\n",
        "# FILE_NAME1 = \"embeddings.tar.gz\" # DO NOT CHANGE\n",
        "\n",
        "# # print the command that you are going to run\n",
        "# print(f'! curl -H \"Authorization: Bearer {ACCESS_TOKEN}\" https://www.googleapis.com/drive/v3/files/{FILE_ID1}?alt=media -o {FILE_NAME1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6jYp-QBeqO9"
      },
      "outputs": [],
      "source": [
        "# # run the command\n",
        "# ! curl -H \"Authorization: Bearer ya29.a0Ad52N39RvcgSxR64dCWPRT2zf7ryi0ib0oPhXi7lte1Nho0Agtz0eTf7cmND4VDIQGSHw0IA6RqL_Zi1T7MsYiObSIrdn3anaSMSZPUBN1To4WSDcuPcYRkUC6xoZOdU2MkHTb_IZCQI5nOJEdY0UH20rNAG4cAXBdsvaCgYKAUgSARMSFQHGX2Mi3HfwxDpNGH4ku8ghMpfEPg0171\" https://www.googleapis.com/drive/v3/files/1ZNHJE4qXLgRLlQGYjGtpufd-56ydZfM4?alt=media -o embeddings.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDZGu7p1eqO9",
        "outputId": "4c18be69-a28e-4269-9819-8809a2da50e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_precalculated_docs/\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
            "embeddings_precalculated_train/\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
            "embeddings_precalculated_test/\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n"
          ]
        }
      ],
      "source": [
        "# unzip the file  (may take around 10 mins)\n",
        "! tar -xvzf ./embeddings.tar.gz\n",
        "\n",
        "# remove the zip file\n",
        "! rm embeddings.tar.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6oSSGD_eqO9"
      },
      "source": [
        "### Download citation mapping\n",
        "\n",
        "You can download them in the same manner as embedding tables, or alternatively, drag them directly into the `content` directory if you've already downloaded the file to your local PC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_gfogheqO-",
        "outputId": "de3a7528-9718-41c4-e9ce-caeafbd6fc7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun\n",
            "To: /content/citation_mapping.tar.gz\n",
            "\r  0% 0.00/264k [00:00<?, ?B/s]\r100% 264k/264k [00:00<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown 'https://drive.google.com/uc?id=1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nk8ZeFZeqO-"
      },
      "outputs": [],
      "source": [
        "# # same solution if error \"failed to retrieve file url: too many users ....\"\n",
        "\n",
        "# FILE_ID2 = \"1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun\" # DO NOT CHANGE\n",
        "# FILE_NAME2 = \"citation_mapping.tar.gz\" # DO NOT CHANGE\n",
        "\n",
        "# # print the command that you are going to run\n",
        "# print(f'! curl -H \"Authorization: Bearer {ACCESS_TOKEN}\" https://www.googleapis.com/drive/v3/files/{FILE_ID2}?alt=media -o {FILE_NAME2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "156Lk_CpeqO-"
      },
      "outputs": [],
      "source": [
        "## run the command\n",
        "# ! curl -H \"Authorization: Bearer ya29.a0Ad52N38YT1rg1pylsmsVav74fF8nFNaHSaIQMRNEmu47r4fdmNqf1R6GzzgavIVgLJlkwB2s1K5d2oaxq15VVb9dMIBLPhY9Ul0G4GSrP_jNgYwljBCV7oEMIAVkIatlCuoM5DBqZEfOu05aaLSvYU63Y_qsvhFWn9AaaCgYKAQMSARMSFQHGX2Mi8czeY5M2cvOV-OUbAFmYkw0171\" https://www.googleapis.com/drive/v3/files/1mOCcOmM_AcLG3qK_mxM_SYp-2OgDys-L?alt=media -o citation_mapping.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_M9T0jieqO-",
        "outputId": "06e696af-cdb8-46c8-cd16-173d8cdfe792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Citation_JSONs/\n",
            "Citation_JSONs/Citation_Train.json\n"
          ]
        }
      ],
      "source": [
        "# unzip the file  (may take around 10 mins)\n",
        "! tar -xvzf ./citation_mapping.tar.gz\n",
        "\n",
        "# remove the zip file\n",
        "! rm citation_mapping.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM1Pj-ioeqO-"
      },
      "source": [
        "# Dense retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHHm-AV8eqO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si8uyrk9eqO_"
      },
      "outputs": [],
      "source": [
        "# Model settings\n",
        "MODEL_NAME = \"all-MiniLM-L6-v2\"  # Choose from: \"all-MiniLM-L6-v2\" or \"PatentSBERTa\"\n",
        "CONTENT_TYPE = \"TA\"              # Choose from: \"TA\", \"claims\", or \"TAC\"\n",
        "POOLING = \"mean\"                 # The pooling strategy used in create_embeddings.py\n",
        "QUERY_SET = \"train\"              # Choose from: \"train\" or \"test\"\n",
        "SAVE_RESULTS = False\n",
        "\n",
        "# Retrieval settings\n",
        "TOP_N = 100  # Number of documents to retrieve for each query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leXBaamIeqO_"
      },
      "outputs": [],
      "source": [
        "# Colab paths\n",
        "BASE_DIR = \"/content\"\n",
        "DOC_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_docs\")\n",
        "TRAIN_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_train\")\n",
        "TEST_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_test\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"results\")\n",
        "CITATION_FILE = os.path.join(BASE_DIR, \"Citation_JSONs/Citation_Train.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsFfnqzleqO_"
      },
      "outputs": [],
      "source": [
        "# Embedding files\n",
        "DOC_EMBEDDING_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.npy\")\n",
        "DOC_APP_IDS_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.json\")\n",
        "\n",
        "# Select query embedding directory based on QUERY_SET\n",
        "QUERY_EMBEDDING_DIR = TRAIN_EMBEDDING_DIR if QUERY_SET == \"train\" else TEST_EMBEDDING_DIR\n",
        "QUERY_EMBEDDING_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.npy\")\n",
        "QUERY_APP_IDS_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.json\")\n",
        "\n",
        "# Evaluation settings\n",
        "K_VALUE = 10  # K value for Recall@K evaluation\n",
        "METRICS_TYPE = \"all\"  # Metrics to calculate: \"recall_at_k\", \"mean_ranking\", \"mean_inv_ranking\", or \"all\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w64uFYNoeqO_"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uh1OV-OeqO_"
      },
      "outputs": [],
      "source": [
        "# === CELL: Utility functions for cosine similarity ===\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
        "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
        "    \"\"\"\n",
        "    if not isinstance(a, torch.Tensor):\n",
        "        a = torch.tensor(a)\n",
        "\n",
        "    if not isinstance(b, torch.Tensor):\n",
        "        b = torch.tensor(b)\n",
        "\n",
        "    if len(a.shape) == 1:\n",
        "        a = a.unsqueeze(0)\n",
        "\n",
        "    if len(b.shape) == 1:\n",
        "        b = b.unsqueeze(0)\n",
        "\n",
        "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
        "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
        "\n",
        "def pytorch_cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
        "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
        "    \"\"\"\n",
        "    return cos_sim(a, b)\n",
        "\n",
        "# === CELL: Utility functions for evaluation metrics ===\n",
        "def mean_recall_at_k(true_labels, predicted_labels, k=10):\n",
        "    \"\"\"\n",
        "    Calculate the mean Recall@k for a list of recommendations.\n",
        "    \"\"\"\n",
        "    recalls_at_k = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate Recall@k for each recommendation list\n",
        "        true_set = set(true)\n",
        "        k = min(k, len(pred))\n",
        "        relevant_count = sum(1 for item in pred[:k] if item in true_set)\n",
        "        recalls_at_k.append(relevant_count / len(true_set) if len(true_set) > 0 else 0)\n",
        "\n",
        "    # Calculate the mean Recall@k\n",
        "    mean_recall = sum(recalls_at_k) / len(recalls_at_k) if recalls_at_k else 0\n",
        "\n",
        "    return mean_recall\n",
        "\n",
        "def mean_inv_ranking(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Calculate the mean of lists of the mean inverse rank of true relevant items\n",
        "    in the lists of sorted recommended items.\n",
        "    \"\"\"\n",
        "    mean_ranks = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate the inverse rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        ranks = []\n",
        "        for item in true:\n",
        "            try:\n",
        "                rank = 1 / (pred.index(item) + 1)\n",
        "            except ValueError:\n",
        "                rank = 0  # If item not found, assign 0\n",
        "            ranks.append(rank)\n",
        "\n",
        "        # Calculate the mean inverse rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
        "        mean_ranks.append(mean_rank)\n",
        "\n",
        "    # Calculate the mean of the mean inverse ranks across all recommendation lists\n",
        "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
        "\n",
        "    return mean_of_mean_ranks\n",
        "\n",
        "def mean_ranking(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Calculate the mean of lists of the mean rank of true relevant items\n",
        "    in the lists of sorted recommended items.\n",
        "    \"\"\"\n",
        "    mean_ranks = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate the rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        ranks = []\n",
        "        for item in true:\n",
        "            try:\n",
        "                rank = pred.index(item) + 1\n",
        "            except ValueError:\n",
        "                rank = len(pred)  # If item not found, assign the length of the list\n",
        "            ranks.append(rank)\n",
        "\n",
        "        # Calculate the mean rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
        "        mean_ranks.append(mean_rank)\n",
        "\n",
        "    # Calculate the mean of the mean ranks across all recommendation lists\n",
        "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
        "\n",
        "    return mean_of_mean_ranks\n",
        "\n",
        "# === CELL: Citation utility functions ===\n",
        "def citation_to_citing_to_cited_dict(citations):\n",
        "    \"\"\"\n",
        "    Put a citation mapping in a dict format\n",
        "    \"\"\"\n",
        "    # Initialize an empty dictionary to store the results\n",
        "    citing_to_cited_dict = {}\n",
        "\n",
        "    # Iterate over the items in the JSON list\n",
        "    for citation in citations:\n",
        "        # Check if the citing id already exists in the resulting dictionary\n",
        "        if citation[0] in citing_to_cited_dict:\n",
        "            # If the citing id exists, append the cited id to the existing list\n",
        "            citing_to_cited_dict[citation[0]].append(citation[2])\n",
        "        else:\n",
        "            # If the citing id doesn't exist, create a new list with the cited id for that citing id\n",
        "            citing_to_cited_dict[citation[0]] = [citation[2]]\n",
        "\n",
        "    return citing_to_cited_dict\n",
        "\n",
        "def get_true_and_predicted(citing_to_cited_dict, recommendations_dict):\n",
        "    \"\"\"\n",
        "    Get the true and predicted labels for the metrics calculation.\n",
        "    \"\"\"\n",
        "    # Initialize lists to store true labels and predicted labels\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    not_in_citation_mapping = 0\n",
        "\n",
        "    # Iterate over the items in both dictionaries\n",
        "    for citing_id in recommendations_dict.keys():\n",
        "        # Check if the citing_id is present in both dictionaries\n",
        "        if citing_id in citing_to_cited_dict:\n",
        "            # If yes, append the recommended items from both dictionaries to the respective lists\n",
        "            true_labels.append(citing_to_cited_dict[citing_id])\n",
        "            predicted_labels.append(recommendations_dict[citing_id])\n",
        "        else:\n",
        "            print(citing_id, \"not in citation mapping\")\n",
        "            not_in_citation_mapping += 1\n",
        "\n",
        "    return true_labels, predicted_labels, not_in_citation_mapping\n",
        "\n",
        "# === CELL: Function to load embeddings ===\n",
        "def load_embeddings_and_ids(embedding_file, app_ids_file):\n",
        "    \"\"\"\n",
        "    Load the embeddings and application IDs from saved files\n",
        "    \"\"\"\n",
        "    print(f\"Loading embeddings from {embedding_file}\")\n",
        "    embeddings = torch.from_numpy(np.load(embedding_file))\n",
        "\n",
        "    print(f\"Loading app_ids from {app_ids_file}\")\n",
        "    with open(app_ids_file, 'r') as f:\n",
        "        app_ids = json.load(f)\n",
        "\n",
        "    print(f\"Loaded {len(embeddings)} embeddings and {len(app_ids)} app_ids\")\n",
        "    return embeddings, app_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_57rjN4LeqO_"
      },
      "source": [
        "## Load document and query embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-G7iCVreqPA",
        "outputId": "2d9d34b5-6cd0-459e-8ba6-000a3086312c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings from /content/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "Loading app_ids from /content/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "Loaded 16837 embeddings and 16837 app_ids\n",
            "Loading embeddings from /content/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "Loading app_ids from /content/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "Loaded 6831 embeddings and 6831 app_ids\n",
            "Running retrieval with 6831 queries against 16837 documents\n"
          ]
        }
      ],
      "source": [
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# Load document embeddings and app_ids\n",
        "doc_embeddings, doc_app_ids = load_embeddings_and_ids(DOC_EMBEDDING_FILE, DOC_APP_IDS_FILE)\n",
        "\n",
        "# Load query embeddings and app_ids\n",
        "query_embeddings, query_app_ids = load_embeddings_and_ids(QUERY_EMBEDDING_FILE, QUERY_APP_IDS_FILE)\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "doc_embeddings = doc_embeddings.to(device)\n",
        "query_embeddings = query_embeddings.to(device)\n",
        "\n",
        "print(f\"Running retrieval with {len(query_embeddings)} queries against {len(doc_embeddings)} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4KnUoieqPA",
        "outputId": "d5acaa88-9419-4a45-8da5-207db0eb0869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100 results for query 3650293A1:\n",
            "App ID: 3225473A1, Similarity: 0.8639\n",
            "App ID: 3085590A1, Similarity: 0.7953\n",
            "App ID: 2974926A1, Similarity: 0.7210\n",
            "App ID: 3202629A1, Similarity: 0.6818\n",
            "App ID: 3075617A1, Similarity: 0.6802\n",
            "App ID: 1979185B1, Similarity: 0.6651\n",
            "App ID: 2072359B1, Similarity: 0.6554\n",
            "App ID: 2500221A1, Similarity: 0.6351\n",
            "App ID: 2871104A1, Similarity: 0.6329\n",
            "App ID: 2072363B1, Similarity: 0.6329\n",
            "App ID: 3000672A1, Similarity: 0.6318\n",
            "App ID: 1965363B1, Similarity: 0.6194\n",
            "App ID: 2824007A1, Similarity: 0.6174\n",
            "App ID: 2022690B1, Similarity: 0.6143\n",
            "App ID: 3000631A1, Similarity: 0.6134\n",
            "App ID: 3056400A1, Similarity: 0.6122\n",
            "App ID: 1731789B1, Similarity: 0.6047\n",
            "App ID: 2982556A1, Similarity: 0.6004\n",
            "App ID: 2024208B1, Similarity: 0.5889\n",
            "App ID: 2719605A1, Similarity: 0.5880\n",
            "App ID: 2794368B1, Similarity: 0.5849\n",
            "App ID: 2378154A1, Similarity: 0.5849\n",
            "App ID: 3225475A1, Similarity: 0.5836\n",
            "App ID: 3243715A1, Similarity: 0.5805\n",
            "App ID: 3175691A1, Similarity: 0.5755\n",
            "App ID: 2623386A1, Similarity: 0.5722\n",
            "App ID: 2665177A2, Similarity: 0.5698\n",
            "App ID: 3202630A1, Similarity: 0.5685\n",
            "App ID: 2591926A1, Similarity: 0.5671\n",
            "App ID: 2689957A1, Similarity: 0.5664\n",
            "App ID: 2692555A1, Similarity: 0.5640\n",
            "App ID: 3124370A2, Similarity: 0.5624\n",
            "App ID: 3292959A1, Similarity: 0.5572\n",
            "App ID: 3299660A1, Similarity: 0.5543\n",
            "App ID: 3225087A2, Similarity: 0.5516\n",
            "App ID: 2319291A1, Similarity: 0.5507\n",
            "App ID: 3301319A1, Similarity: 0.5500\n",
            "App ID: 2338821A1, Similarity: 0.5489\n",
            "App ID: 2070788B1, Similarity: 0.5486\n",
            "App ID: 3258277A1, Similarity: 0.5457\n",
            "App ID: 3179674A1, Similarity: 0.5446\n",
            "App ID: 3222129A1, Similarity: 0.5435\n",
            "App ID: 1938905B1, Similarity: 0.5415\n",
            "App ID: 2036745B1, Similarity: 0.5410\n",
            "App ID: 3020874A1, Similarity: 0.5401\n",
            "App ID: 2223836A1, Similarity: 0.5397\n",
            "App ID: 1781516B1, Similarity: 0.5390\n",
            "App ID: 1751446B1, Similarity: 0.5381\n",
            "App ID: 2565093A1, Similarity: 0.5377\n",
            "App ID: 2910401A1, Similarity: 0.5377\n",
            "App ID: 2835293A1, Similarity: 0.5366\n",
            "App ID: 3006283A1, Similarity: 0.5361\n",
            "App ID: 2425933A2, Similarity: 0.5350\n",
            "App ID: 2878501A1, Similarity: 0.5344\n",
            "App ID: 3388380A1, Similarity: 0.5294\n",
            "App ID: 2805868A2, Similarity: 0.5293\n",
            "App ID: 1795414B1, Similarity: 0.5273\n",
            "App ID: 2821302A1, Similarity: 0.5252\n",
            "App ID: 3239092A1, Similarity: 0.5232\n",
            "App ID: 3470707A1, Similarity: 0.5214\n",
            "App ID: 3330123A1, Similarity: 0.5210\n",
            "App ID: 1912313B1, Similarity: 0.5189\n",
            "App ID: 2537790A1, Similarity: 0.5188\n",
            "App ID: 3326955A1, Similarity: 0.5166\n",
            "App ID: 3184383A1, Similarity: 0.5149\n",
            "App ID: 3088641A1, Similarity: 0.5146\n",
            "App ID: 2910440A1, Similarity: 0.5124\n",
            "App ID: 2990239A1, Similarity: 0.5106\n",
            "App ID: 3093197A1, Similarity: 0.5078\n",
            "App ID: 2778113A1, Similarity: 0.5076\n",
            "App ID: 2980317A1, Similarity: 0.5063\n",
            "App ID: 3225578A1, Similarity: 0.5058\n",
            "App ID: 2910402A1, Similarity: 0.5056\n",
            "App ID: 3081829A1, Similarity: 0.5056\n",
            "App ID: 2422607A1, Similarity: 0.5054\n",
            "App ID: 3287657A1, Similarity: 0.5047\n",
            "App ID: 1979550B1, Similarity: 0.5032\n",
            "App ID: 2851267A1, Similarity: 0.5019\n",
            "App ID: 3078837A1, Similarity: 0.5016\n",
            "App ID: 2644015A2, Similarity: 0.5015\n",
            "App ID: 3420798A1, Similarity: 0.5014\n",
            "App ID: 3000456A1, Similarity: 0.4996\n",
            "App ID: 2878504A1, Similarity: 0.4994\n",
            "App ID: 1768891B1, Similarity: 0.4989\n",
            "App ID: 3150046A1, Similarity: 0.4980\n",
            "App ID: 2955104A1, Similarity: 0.4967\n",
            "App ID: 2632031A2, Similarity: 0.4958\n",
            "App ID: 3048035A1, Similarity: 0.4937\n",
            "App ID: 3056404A1, Similarity: 0.4935\n",
            "App ID: 3278842A2, Similarity: 0.4916\n",
            "App ID: 2415504A1, Similarity: 0.4910\n",
            "App ID: 3257712A1, Similarity: 0.4892\n",
            "App ID: 3115602A2, Similarity: 0.4877\n",
            "App ID: 2298689A2, Similarity: 0.4873\n",
            "App ID: 2949539A1, Similarity: 0.4865\n",
            "App ID: 1752739B1, Similarity: 0.4859\n",
            "App ID: 1975470B1, Similarity: 0.4855\n",
            "App ID: 2048046B1, Similarity: 0.4855\n",
            "App ID: 3239801A1, Similarity: 0.4852\n",
            "App ID: 3269604A1, Similarity: 0.4846\n"
          ]
        }
      ],
      "source": [
        "def retrieve_by_app_id(target_app_id, query_app_ids, query_embeddings, doc_embeddings, doc_app_ids, top_n=10):\n",
        "    \"\"\"\n",
        "    Retrieve top N documents for a single query by its app_id\n",
        "\n",
        "    Parameters:\n",
        "    - target_app_id: The application ID of the query to search for\n",
        "    - query_app_ids: List of all query application IDs\n",
        "    - query_embeddings: Embeddings for all queries\n",
        "    - doc_embeddings: Embeddings for all documents in the corpus\n",
        "    - doc_app_ids: Application IDs for all documents\n",
        "    - top_n: Number of results to return\n",
        "\n",
        "    Returns:\n",
        "    - List of top N document app_ids similar to the query\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Find the index of the target app_id in query_app_ids\n",
        "        query_index = query_app_ids.index(target_app_id)\n",
        "\n",
        "        # Get the corresponding embedding\n",
        "        query_embedding = query_embeddings[query_index].unsqueeze(0)\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        cos_scores = pytorch_cos_sim(query_embedding, doc_embeddings)[0].cpu()\n",
        "\n",
        "        # Sort results and get top N\n",
        "        top_n_index = torch.argsort(cos_scores, descending=True)[:top_n].numpy()\n",
        "\n",
        "        # Get application IDs of top N documents\n",
        "        top_n_app_ids = [doc_app_ids[i] for i in top_n_index]\n",
        "        top_n_scores = [cos_scores[i].item() for i in top_n_index]\n",
        "\n",
        "        return top_n_app_ids, top_n_scores\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Error: Application ID '{target_app_id}' not found in query_app_ids\")\n",
        "        return [], []\n",
        "\n",
        "# Example usage\n",
        "target_app_id = query_app_ids[0]  # Replace with the specific app_id you want to query\n",
        "retrieved_app_ids, similarity_scores = retrieve_by_app_id(\n",
        "    target_app_id,\n",
        "    query_app_ids,\n",
        "    query_embeddings,\n",
        "    doc_embeddings,\n",
        "    doc_app_ids,\n",
        "    top_n=TOP_N\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(f\"Top {TOP_N} results for query {target_app_id}:\")\n",
        "for app_id, score in zip(retrieved_app_ids, similarity_scores):\n",
        "    print(f\"App ID: {app_id}, Similarity: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6IoJ7FHeqPA"
      },
      "source": [
        "## Perform retrieval for each query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIxU_ZLOeqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709252bb-fc69-4a5d-fb2a-19f5788f2e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6831/6831 [00:14<00:00, 465.30it/s]\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "for i, (query_embedding, query_id) in enumerate(tqdm(zip(query_embeddings, query_app_ids), total=len(query_embeddings))):\n",
        "    # Compute cosine similarity\n",
        "    query_embedding = query_embedding.unsqueeze(0)\n",
        "    cos_scores = pytorch_cos_sim(query_embedding, doc_embeddings)[0].cpu()\n",
        "\n",
        "    # Sort results and get top N\n",
        "    top_n_index = torch.argsort(cos_scores, descending=True)[:TOP_N].numpy()\n",
        "\n",
        "    # Get application IDs of top N documents\n",
        "    top_n_app_ids = [doc_app_ids[i] for i in top_n_index]\n",
        "    results[query_id] = top_n_app_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVtXsgC0eqPA"
      },
      "source": [
        "## Save results (if applicable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzMZZgU7eqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd6172f-89c4-4999-9d5a-8b287bc3af4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results not saved (SAVE_RESULTS=False)\n"
          ]
        }
      ],
      "source": [
        "if QUERY_SET == \"train\":\n",
        "    output_file = f\"{OUTPUT_DIR}/{MODEL_NAME}_{CONTENT_TYPE}_{QUERY_SET}_retrieved.json\"\n",
        "else:\n",
        "    output_file = f\"{OUTPUT_DIR}/prediction2.json\"  # Standard filename for test predictions\n",
        "\n",
        "if SAVE_RESULTS:\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f)\n",
        "    print(f\"Saved retrieval results to {output_file}\")\n",
        "else:\n",
        "    print(f\"Results not saved (SAVE_RESULTS={SAVE_RESULTS})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVZ9FwoReqPA"
      },
      "source": [
        "## Evaluation (for training set only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LZOd-6JeqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8160fe-51a3-42ff-b8b7-23115ecf5e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating train set results...\n",
            "Loading citation data from /content/Citation_JSONs/Citation_Train.json\n",
            "\n",
            "Evaluation Results:\n",
            "-------------------\n",
            "Recall@10: 0.5459\n",
            "Mean Ranking: 29.5900\n",
            "Mean Inverse Ranking: 0.3453\n",
            "\n",
            "Number of patents measured: 6831\n",
            "Number of patents not in citation mapping: 0\n"
          ]
        }
      ],
      "source": [
        "if QUERY_SET == \"train\":\n",
        "    print(\"Evaluating train set results...\")\n",
        "\n",
        "    # Load citation mapping\n",
        "    print(f\"Loading citation data from {CITATION_FILE}\")\n",
        "    with open(CITATION_FILE, 'r') as f:\n",
        "        citations = json.load(f)\n",
        "\n",
        "    # Convert citations to citing-to-cited dictionary\n",
        "    citing_to_cited_dict = citation_to_citing_to_cited_dict(citations)\n",
        "\n",
        "    # Get true and predicted labels\n",
        "    true_labels, predicted_labels, not_in_citation_mapping = get_true_and_predicted(\n",
        "        citing_to_cited_dict, results\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(\"-------------------\")\n",
        "\n",
        "    if METRICS_TYPE in ['recall_at_k', 'all']:\n",
        "        recall_at_k = mean_recall_at_k(true_labels, predicted_labels, k=K_VALUE)\n",
        "        print(f\"Recall@{K_VALUE}: {recall_at_k:.4f}\")\n",
        "\n",
        "    if METRICS_TYPE in ['mean_ranking', 'all']:\n",
        "        mean_rank = mean_ranking(true_labels, predicted_labels)\n",
        "        print(f\"Mean Ranking: {mean_rank:.4f}\")\n",
        "\n",
        "    if METRICS_TYPE in ['mean_inv_ranking', 'all']:\n",
        "        mean_inv_rank = mean_inv_ranking(true_labels, predicted_labels)\n",
        "        print(f\"Mean Inverse Ranking: {mean_inv_rank:.4f}\")\n",
        "\n",
        "    print(f\"\\nNumber of patents measured: {len(predicted_labels)}\")\n",
        "    print(f\"Number of patents not in citation mapping: {not_in_citation_mapping}\")\n",
        "else:\n",
        "    print(\"\\nTest set retrieval completed. No evaluation performed.\")\n",
        "    if SAVE_RESULTS:\n",
        "        print(f\"Predictions saved to {OUTPUT_DIR}/prediction1.json\")\n",
        "    print(\"Note: For the test set, citation data is not available for evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcXigwGceqPA"
      },
      "source": [
        "# TODOs : Reciprocal Rank Fusion and Embedding Combinations\n",
        "\n",
        "## Reciprocal Rank Fusion (RRF)\n",
        "\n",
        "Reciprocal Rank Fusion is a simple yet effective method for combining multiple ranking lists. Instead of using raw scores from different retrieval systems, RRF uses the *positions* of documents in each ranking list:\n",
        "\n",
        "1. For each document in any of the ranking lists, calculate:\n",
        "   ```\n",
        "   RRF_score(d) = ∑ 1/(k + rank_i(d))\n",
        "   ```\n",
        "   Where `k` is a constant (typically 60) that mitigates the impact of high rankings, and `rank_i(d)` is the rank of document `d` in the i-th ranking list.\n",
        "\n",
        "2. If a document doesn't appear in a ranking list, its contribution to the sum is zero.\n",
        "\n",
        "3. Re-rank documents by their RRF scores in descending order.\n",
        "\n",
        "## Implementation Expectations\n",
        "\n",
        "Students are expected to:\n",
        "\n",
        "* Implement RRF to combine rankings from different retrieval methods (sparse, dense)\n",
        "* Experiment with embedding combinations using various aggregation strategies:\n",
        "  * **Sum**: Adding embedding vectors\n",
        "  * **Average**: Taking the mean of embedding vectors\n",
        "  * **Concatenation**: Joining vectors end-to-end\n",
        "  * **Weighted combinations**: Assigning different weights to different embeddings\n",
        "\n",
        "* Try combining embeddings of the same model but different content types:\n",
        "  * PatentSBERTa TA with PatentSBERTa claims\n",
        "  * PatentSBERTa TA with PatentSBERTa TAC\n",
        "  * And other combinations\n",
        "\n",
        "## Analysis and Evaluation\n",
        "\n",
        "Your submission will be evaluated on:\n",
        "\n",
        "* **Creativity**: Exploring novel combinations and beyond standard methods\n",
        "* **Research depth**: Investigating why certain combinations work better\n",
        "* **Analysis quality**: Providing insights about which strategies perform best and why\n",
        "* **Experimental rigor**: Systematically testing different approaches\n",
        "\n",
        "The information retrieval field is rapidly evolving - creative approaches that surpass traditional methods are strongly encouraged. The most innovative and effective solution will earn the challenge bonus and valuable CV credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References:\n",
        "\n",
        "https://github.com/opensearch-project/neural-search/issues/865\n",
        "\n",
        "https://rodgerbenham.github.io/bc17-adcs.pdf\n",
        "\n",
        "https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\n",
        "\n",
        "https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a\n",
        "\n",
        "https://arxiv.org/html/2503.20698v1\n",
        "\n",
        "https://arxiv.org/pdf/2210.11934\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hLWSf4hRr52r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FROM 0"
      ],
      "metadata": {
        "id": "7JyldJJx647M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RRF ALGO"
      ],
      "metadata": {
        "id": "lMUbtAgh69N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def reciprocal_rank_fusion(rankings_list, k=60):\n",
        "    \"\"\"\n",
        "    Combines multiple ranked lists using Reciprocal Rank Fusion\n",
        "\n",
        "    Args:\n",
        "        rankings_list (list of dict): List of dictionaries where each dict has\n",
        "            {query_id: [ordered list of document IDs]}\n",
        "        k (int): Smoothing parameter (typically 60 by default // a value used by the community)\n",
        "\n",
        "    Returns:\n",
        "        dict: {query_id: [ordered list of merged document IDs]}\n",
        "    \"\"\"\n",
        "    fused_rankings = {}\n",
        "\n",
        "    # Get all unique query IDs\n",
        "    query_ids = set.intersection(*[set(r.keys()) for r in rankings_list])\n",
        "\n",
        "    for qid in query_ids:\n",
        "        doc_scores = defaultdict(float)\n",
        "\n",
        "        # Calculate RRF scores for each ranking\n",
        "        for ranking in rankings_list:\n",
        "            ranked_docs = ranking[qid]\n",
        "            for rank_pos, doc_id in enumerate(ranked_docs):\n",
        "                doc_scores[doc_id] += 1 / (k + rank_pos + 1)  # +1 because ranks are 0-indexed\n",
        "\n",
        "        # Sort documents by descending RRF score\n",
        "        sorted_docs = sorted(doc_scores.items(), key=lambda x: -x[1])\n",
        "\n",
        "        # Extract ordered document IDs\n",
        "        fused_rankings[qid] = [doc_id for doc_id, score in sorted_docs]\n",
        "\n",
        "    return fused_rankings\n",
        "\n",
        "def load_ranking(file_path):\n",
        "    \"\"\"\n",
        "    Load a ranking from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "dense_rankings = load_ranking(\"results/prediction1.json\")  # From current dense retrieval for ranking\n",
        "sparse_rankings = load_ranking(\"results/prediction1_tfidf.json\")     # From previous sparse retrieval\n",
        "combined_ranking = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "# Print top results\n",
        "for doc_id, score in combined_ranking:\n",
        "  print(doc_id, score)\n",
        "\n",
        "# Save fused results if needed\n",
        "if SAVE_RESULTS:\n",
        "    output_file = f\"{OUTPUT_DIR}/rrf_prediction2.json\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(combined_ranking, f)\n",
        "    print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "id": "w2Rwe3LM64PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agregation functions\n",
        "\n",
        "Experimenting with embedding combinations using various aggregation strategies:\n",
        "\n",
        "- Sum: Adding embedding vectors\n",
        "- Average: Taking the mean of embedding vectors\n",
        "- Concatenation: Joining vectors end-to-end\n",
        "- Weighted combinations: Assigning different weights to different embeddings"
      ],
      "metadata": {
        "id": "T2QSZSR47QvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation Functions\n",
        "\n",
        "def combine_sum(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by element-wise summation.\n",
        "    \"\"\"\n",
        "    return emb1 + emb2\n",
        "\n",
        "def combine_average(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by taking their element-wise average.\n",
        "    \"\"\"\n",
        "    return (emb1 + emb2) / 2\n",
        "\n",
        "def combine_concatenate(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by concatenating them along the last dimension.\n",
        "    \"\"\"\n",
        "    return np.concatenate((emb1, emb2), axis=-1)\n",
        "\n",
        "def combine_weighted(emb1, emb2, weight1=0.5, weight2=0.5):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by a weighted sum.\n",
        "\n",
        "    Parameters:\n",
        "      weight1: weight for emb1\n",
        "      weight2: weight for emb2\n",
        "    \"\"\"\n",
        "    return weight1 * emb1 + weight2 * emb2\n",
        "\n",
        "# a function that takes a list of embeddings and combines them with the chosen strategy.\n",
        "def combine_multiple_embeddings(embeddings, method=\"average\", weights=None):\n",
        "    \"\"\"\n",
        "    Combine multiple embeddings using the specified method.\n",
        "\n",
        "    Parameters:\n",
        "      embeddings (list of np.array): List of embedding vectors.\n",
        "      method (str): One of \"sum\", \"average\", \"concatenate\", \"weighted\".\n",
        "      weights (list of float): Only used for \"weighted\" method. Should sum to 1.\n",
        "\n",
        "    Returns:\n",
        "      np.array: The combined embedding.\n",
        "    \"\"\"\n",
        "    if method == \"sum\":\n",
        "        combined = np.sum(embeddings, axis=0)\n",
        "    elif method == \"average\":\n",
        "        combined = np.mean(embeddings, axis=0)\n",
        "    elif method == \"concatenate\":\n",
        "        combined = np.concatenate(embeddings, axis=-1)\n",
        "    elif method == \"weighted\":\n",
        "        if weights is None or len(weights) != len(embeddings):\n",
        "            raise ValueError(\"Provide a weights list with the same length as embeddings\")\n",
        "        combined = np.zeros_like(embeddings[0], dtype=float)\n",
        "        for emb, w in zip(embeddings, weights):\n",
        "            combined += w * emb\n",
        "    else:\n",
        "        raise ValueError(\"Unknown method: choose from 'sum', 'average', 'concatenate', or 'weighted'\")\n",
        "    return combined"
      ],
      "metadata": {
        "id": "AJ60Ca9t7QCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the files"
      ],
      "metadata": {
        "id": "f5L5ciqe7jvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# ------------------ TRAINING QUERIES + GOLD MAPPING -----------------------\n",
        "\n",
        "# List of query patent IDs for training\n",
        "with open('/content/dataset2/train_queries.json') as f:\n",
        "    train_qids = json.load(f)\n",
        "\n",
        "#  Gold standard mappings of relevant documents for each training query\n",
        "with open('/content/dataset2/train_gold_mapping.json') as f:\n",
        "    gold_mappings = json.load(f)\n",
        "\n",
        "#  Content of the query patents with LLM-extracted features\n",
        "with open('/content/dataset2/queries_content_with_features.json') as f:\n",
        "    all_queries = {q['FAN']: q for q in json.load(f)}\n",
        "\n",
        "# ------------------ TEST QUERIES --------------------------------------\n",
        "# List of query patent IDs for testing (gold not accessible during the challenge)\n",
        "with open('/content/dataset2/test_queries.json') as f:\n",
        "    test_qids = json.load(f)\n",
        "\n",
        "# ---------------- shuffeled_pre_ranking -------------------------------\n",
        "# Initial random ranking of documents for each query\n",
        "with open('/content/dataset2/shuffled_pre_ranking.json') as f:\n",
        "    shuffled_pre_ranking = json.load(f)\n",
        "\n",
        "# --------------- docs_content_with_features ---------------------------\n",
        "# Content of the candidate documents with LLM-extracted features\n",
        "with open('/content/dataset2/documents_content_with_features.json') as f:\n",
        "    docs_content_with_features = json.load(f)"
      ],
      "metadata": {
        "id": "p-fZiLkw7lAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation of results (1) from re-ranking"
      ],
      "metadata": {
        "id": "MucVMw6F8Nw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Runing the cross_encoder_renaking (training only)"
      ],
      "metadata": {
        "id": "xEuYK4g-ZiQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##### With the model intfloat/e5-large-v2"
      ],
      "metadata": {
        "id": "YiJEq8-O2Ea6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python cross_encoder_reranking_train.py \\\n",
        "  --pre_ranking shuffled_pre_ranking.json \\\n",
        "  --output predictions2.json \\\n",
        "  --queries_content queries_content_with_features.json \\\n",
        "  --documents_content documents_content_with_features.json \\\n",
        "  --queries_list train_queries.json \\\n",
        "  --text_type tac1 \\\n",
        "  --model_name intfloat/e5-large-v2 \\\n",
        "  --batch_size 8 \\\n",
        "  --max_length 512 \\\n",
        "  --device cpu \\\n",
        "  --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHR9upivQL-n",
        "outputId": "7202baa8-37d7-4682-d77f-11e90aba0e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training queries from train_queries.json...\n",
            "Loaded 20 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 20 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model intfloat/e5-large-v2...\n",
            "2025-04-05 09:55:43.636683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743846943.687422   12482 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743846943.703179   12482 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 09:55:43.758465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/20 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 79314580\n",
            "Original pre-ranking (first 3): ['99159171', '95503744', '77860027']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:53, 58.00s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.39s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:01<01:00, 60.96s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:45<00:00, 54.39s/it]\u001b[A\n",
            "Processing queries:   5% 1/20 [03:45<1:11:24, 225.51s/it]\n",
            "Re-ranking 30 documents for training query 78061231\n",
            "Original pre-ranking (first 3): ['72681493', '105616053', '66645142']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:02, 60.82s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:05<02:06, 63.18s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:14<01:05, 65.71s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [04:00<00:00, 58.04s/it]\u001b[A\n",
            "Processing queries:  10% 2/20 [07:46<1:10:19, 234.42s/it]\n",
            "Re-ranking 30 documents for training query 66336898\n",
            "Original pre-ranking (first 3): ['7881264', '71288419', '44193822']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:01<03:03, 61.11s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:02<02:02, 61.26s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:53<00:56, 56.51s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:41<00:00, 53.31s/it]\u001b[A\n",
            "Processing queries:  15% 3/20 [11:27<1:04:46, 228.63s/it]\n",
            "Re-ranking 30 documents for training query 105235513\n",
            "Original pre-ranking (first 3): ['99616608', '6423024', '91500742']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:01<03:05, 61.77s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:02<02:02, 61.18s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:03<01:01, 61.08s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:50<00:00, 55.42s/it]\u001b[A\n",
            "Processing queries:  20% 4/20 [15:18<1:01:08, 229.27s/it]\n",
            "Re-ranking 30 documents for training query 77017157\n",
            "Original pre-ranking (first 3): ['76191452', '44359627', '43728980']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:02<03:08, 62.69s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:08<02:08, 64.45s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:11<01:03, 63.80s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:56<00:00, 56.40s/it]\u001b[A\n",
            "Processing queries:  25% 5/20 [19:14<57:57, 231.86s/it]  \n",
            "Re-ranking 30 documents for training query 106232152\n",
            "Original pre-ranking (first 3): ['64464686', '43867066', '45808372']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:03<03:09, 63.06s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:06<02:06, 63.32s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:04<01:00, 60.79s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:51<00:00, 55.60s/it]\u001b[A\n",
            "Processing queries:  30% 6/20 [23:06<54:06, 231.90s/it]\n",
            "Re-ranking 30 documents for training query 76353708\n",
            "Original pre-ranking (first 3): ['87707840', '87854266', '43591520']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:02<03:08, 62.75s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:02<02:01, 60.94s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:01<01:00, 60.22s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:47<00:00, 54.38s/it]\u001b[A\n",
            "Processing queries:  35% 7/20 [26:53<49:54, 230.37s/it]\n",
            "Re-ranking 30 documents for training query 79741091\n",
            "Original pre-ranking (first 3): ['46019838', '71187327', '52035153']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.04s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:59, 59.65s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:02<01:01, 61.41s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:49<00:00, 55.37s/it]\u001b[A\n",
            "Processing queries:  40% 8/20 [30:42<45:59, 229.95s/it]\n",
            "Re-ranking 30 documents for training query 86860100\n",
            "Original pre-ranking (first 3): ['98396291', '89793282', '80708349']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:03<03:10, 63.35s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:09<02:10, 65.17s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:08<01:02, 62.40s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:55<00:00, 56.00s/it]\u001b[A\n",
            "Processing queries:  45% 9/20 [34:37<42:27, 231.55s/it]\n",
            "Re-ranking 30 documents for training query 79045164\n",
            "Original pre-ranking (first 3): ['21116140', '29184345', '33352117']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:01, 60.44s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.05s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:55<00:58, 58.44s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:41<00:00, 53.35s/it]\u001b[A\n",
            "Processing queries:  50% 10/20 [38:19<38:03, 228.38s/it]\n",
            "Re-ranking 30 documents for training query 85176564\n",
            "Original pre-ranking (first 3): ['45096562', '32416570', '67147862']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:57, 59.22s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.33s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<01:00, 60.12s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:43<00:00, 53.86s/it]\u001b[A\n",
            "Processing queries:  55% 11/20 [42:03<34:03, 227.03s/it]\n",
            "Re-ranking 30 documents for training query 74598812\n",
            "Original pre-ranking (first 3): ['78616844', '44961149', '91960790']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.15s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:58, 59.44s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.27s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 53.99s/it]\u001b[A\n",
            "Processing queries:  60% 12/20 [45:47<30:10, 226.33s/it]\n",
            "Re-ranking 30 documents for training query 78286001\n",
            "Original pre-ranking (first 3): ['86430033', '69569655', '87559850']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.11s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:01<02:01, 60.75s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.71s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 53.69s/it]\u001b[A\n",
            "Processing queries:  65% 13/20 [49:32<26:19, 225.70s/it]\n",
            "Re-ranking 30 documents for training query 79098180\n",
            "Original pre-ranking (first 3): ['84117280', '86237859', '44417984']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.29s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:59, 59.65s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:58<00:59, 59.47s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 54.06s/it]\u001b[A\n",
            "Processing queries:  70% 14/20 [53:16<22:32, 225.35s/it]\n",
            "Re-ranking 30 documents for training query 78090091\n",
            "Original pre-ranking (first 3): ['72990387', '106235322', '44002297']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:57, 59.27s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.17s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:57<00:59, 59.43s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:42<00:00, 53.88s/it]\u001b[A\n",
            "Processing queries:  75% 15/20 [56:59<18:43, 224.63s/it]\n",
            "Re-ranking 30 documents for training query 80155730\n",
            "Original pre-ranking (first 3): ['67610635', '92933079', '75057499']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.93s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:58, 59.49s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.26s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:43<00:00, 53.62s/it]\u001b[A\n",
            "Processing queries:  80% 16/20 [1:00:43<14:57, 224.36s/it]\n",
            "Re-ranking 30 documents for training query 76109734\n",
            "Original pre-ranking (first 3): ['71546239', '67177917', '106884384']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.88s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:01, 60.51s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.89s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 53.64s/it]\u001b[A\n",
            "Processing queries:  85% 17/20 [1:04:27<11:12, 224.27s/it]\n",
            "Re-ranking 30 documents for training query 106318129\n",
            "Original pre-ranking (first 3): ['81915722', '22135206', '88406090']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:02, 60.71s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.37s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.65s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:38<00:00, 51.37s/it]\u001b[A\n",
            "Processing queries:  90% 18/20 [1:08:05<07:24, 222.48s/it]\n",
            "Re-ranking 30 documents for training query 1864211\n",
            "Original pre-ranking (first 3): ['74893664', '14904274', '73417734']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:01<03:03, 61.16s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:59, 59.67s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.74s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:46<00:00, 54.49s/it]\u001b[A\n",
            "Processing queries:  95% 19/20 [1:11:51<03:43, 223.55s/it]\n",
            "Re-ranking 30 documents for training query 61277994\n",
            "Original pre-ranking (first 3): ['13996136', '87721730', '43824316']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:57, 59.25s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:01<02:01, 60.80s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.29s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:46<00:00, 54.66s/it]\u001b[A\n",
            "Processing queries: 100% 20/20 [1:15:38<00:00, 226.93s/it]\n",
            "Saving re-ranked results to /content/dataset2/predictions2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python cross_encoder_reranking_train.py \\\n",
        "  --pre_ranking shuffled_pre_ranking.json \\\n",
        "  --output predictions2.json \\\n",
        "  --queries_content queries_content_with_features.json \\\n",
        "  --documents_content documents_content_with_features.json \\\n",
        "  --queries_list train_queries.json \\\n",
        "  --text_type tac1 \\\n",
        "  --model_name intfloat/e5-large-v2 \\\n",
        "  --batch_size 8 \\\n",
        "  --max_length 512 \\\n",
        "  --device cpu \\\n",
        "  --base_dir /content/dataset2/"
      ],
      "metadata": {
        "id": "dg-Pjt522IC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Using this combination: 'BAAI/bge-large-en-v1.5 and description`"
      ],
      "metadata": {
        "id": "WZrCqgC22ohH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python cross_encoder_reranking_train.py \\\n",
        "  --pre_ranking shuffled_pre_ranking.json \\\n",
        "  --output predictions2.json \\\n",
        "  --queries_content queries_content_with_features.json \\\n",
        "  --documents_content documents_content_with_features.json \\\n",
        "  --queries_list train_queries.json \\\n",
        "  --text_type  description \\\n",
        "  --model_name BAAI/bge-large-en-v1.5 \\\n",
        "  --batch_size 8 \\\n",
        "  --max_length 512 \\\n",
        "  --device cpu \\\n",
        "  --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOaey82N2-fm",
        "outputId": "4d6a14fb-0060-4db7-fe0b-e310c0224824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training queries from train_queries.json...\n",
            "Loaded 20 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 20 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model BAAI/bge-large-en-v1.5...\n",
            "2025-04-05 12:13:18.175723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743855198.204891   45352 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743855198.219676   45352 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 12:13:18.262877: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 1.34G/1.34G [00:14<00:00, 76.3MB/s]\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/20 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 79314580\n",
            "Original pre-ranking (first 3): ['99159171', '95503744', '77860027']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:54, 58.22s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.40s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:03<01:01, 61.76s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:48<00:00, 55.27s/it]\u001b[A\n",
            "Processing queries:   5% 1/20 [03:48<1:12:28, 228.86s/it]\n",
            "Re-ranking 30 documents for training query 78061231\n",
            "Original pre-ranking (first 3): ['72681493', '105616053', '66645142']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:55, 58.53s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:57<01:57, 58.69s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:54<00:57, 57.88s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:40<00:00, 53.12s/it]\u001b[A\n",
            "Processing queries:  10% 2/20 [07:28<1:07:06, 223.70s/it]\n",
            "Re-ranking 30 documents for training query 66336898\n",
            "Original pre-ranking (first 3): ['7881264', '71288419', '44193822']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:53, 57.76s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.45s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:54<00:58, 58.29s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:41<00:00, 53.89s/it]\u001b[A\n",
            "Processing queries:  15% 3/20 [11:10<1:03:09, 222.90s/it]\n",
            "Re-ranking 30 documents for training query 105235513\n",
            "Original pre-ranking (first 3): ['99616608', '6423024', '91500742']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:56<02:48, 56.31s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:02<02:04, 62.03s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:04<01:02, 62.06s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:53<00:00, 57.03s/it]\u001b[A\n",
            "Processing queries:  20% 4/20 [15:04<1:00:35, 227.19s/it]\n",
            "Re-ranking 30 documents for training query 77017157\n",
            "Original pre-ranking (first 3): ['76191452', '44359627', '43728980']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:58, 59.47s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:03<02:03, 61.95s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:02<01:00, 60.53s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:55<00:00, 57.73s/it]\u001b[A\n",
            "Processing queries:  25% 5/20 [19:00<57:32, 230.17s/it]  \n",
            "Re-ranking 30 documents for training query 106232152\n",
            "Original pre-ranking (first 3): ['64464686', '43867066', '45808372']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:58, 59.43s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.21s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:57<00:59, 59.03s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:50<00:00, 56.47s/it]\u001b[A\n",
            "Processing queries:  30% 6/20 [22:50<53:43, 230.24s/it]\n",
            "Re-ranking 30 documents for training query 76353708\n",
            "Original pre-ranking (first 3): ['87707840', '87854266', '43591520']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:52, 57.65s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:54<01:54, 57.33s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:53<00:57, 57.84s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:40<00:00, 53.51s/it]\u001b[A\n",
            "Processing queries:  35% 7/20 [26:30<49:10, 226.93s/it]\n",
            "Re-ranking 30 documents for training query 79741091\n",
            "Original pre-ranking (first 3): ['46019838', '71187327', '52035153']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:56<02:50, 56.97s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:57, 58.52s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:01, 61.14s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:45<00:00, 54.80s/it]\u001b[A\n",
            "Processing queries:  40% 8/20 [30:16<45:19, 226.61s/it]\n",
            "Re-ranking 30 documents for training query 86860100\n",
            "Original pre-ranking (first 3): ['98396291', '89793282', '80708349']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:53, 57.90s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:55<01:56, 58.00s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:58<00:59, 59.99s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 54.45s/it]\u001b[A\n",
            "Processing queries:  45% 9/20 [34:00<41:24, 225.88s/it]\n",
            "Re-ranking 30 documents for training query 79045164\n",
            "Original pre-ranking (first 3): ['21116140', '29184345', '33352117']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.78s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:57<01:57, 58.68s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:56<00:58, 58.89s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:44<00:00, 54.28s/it]\u001b[A\n",
            "Processing queries:  50% 10/20 [37:44<37:33, 225.32s/it]\n",
            "Re-ranking 30 documents for training query 85176564\n",
            "Original pre-ranking (first 3): ['45096562', '32416570', '67147862']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:56, 58.78s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.42s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.64s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:45<00:00, 54.55s/it]\u001b[A\n",
            "Processing queries:  55% 11/20 [41:30<33:48, 225.36s/it]\n",
            "Re-ranking 30 documents for training query 74598812\n",
            "Original pre-ranking (first 3): ['78616844', '44961149', '91960790']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:52, 57.63s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:54<01:53, 56.91s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:53<00:57, 57.86s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:37<00:00, 52.59s/it]\u001b[A\n",
            "Processing queries:  60% 12/20 [45:07<29:43, 222.98s/it]\n",
            "Re-ranking 30 documents for training query 78286001\n",
            "Original pre-ranking (first 3): ['86430033', '69569655', '87559850']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:52, 57.65s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.43s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:54<00:58, 58.21s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:39<00:00, 52.95s/it]\u001b[A\n",
            "Processing queries:  65% 13/20 [48:47<25:53, 221.92s/it]\n",
            "Re-ranking 30 documents for training query 79098180\n",
            "Original pre-ranking (first 3): ['84117280', '86237859', '44417984']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:51, 57.15s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:55<01:55, 57.67s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:52<00:57, 57.48s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:38<00:00, 52.83s/it]\u001b[A\n",
            "Processing queries:  70% 14/20 [52:25<22:04, 220.78s/it]\n",
            "Re-ranking 30 documents for training query 78090091\n",
            "Original pre-ranking (first 3): ['72990387', '106235322', '44002297']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:51, 57.04s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:54<01:54, 57.42s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:51<00:57, 57.01s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:37<00:00, 52.60s/it]\u001b[A\n",
            "Processing queries:  75% 15/20 [56:02<18:18, 219.67s/it]\n",
            "Re-ranking 30 documents for training query 80155730\n",
            "Original pre-ranking (first 3): ['67610635', '92933079', '75057499']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:06<03:20, 66.92s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:11<02:10, 65.35s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:10<01:02, 62.55s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:56<00:00, 55.90s/it]\u001b[A\n",
            "Processing queries:  80% 16/20 [59:58<14:58, 224.62s/it]\n",
            "Re-ranking 30 documents for training query 76109734\n",
            "Original pre-ranking (first 3): ['71546239', '67177917', '106884384']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.12s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:59, 59.89s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:02<01:01, 61.38s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:49<00:00, 55.32s/it]\u001b[A\n",
            "Processing queries:  85% 17/20 [1:03:47<11:17, 225.95s/it]\n",
            "Re-ranking 30 documents for training query 106318129\n",
            "Original pre-ranking (first 3): ['81915722', '22135206', '88406090']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:02, 60.97s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:58, 59.36s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.17s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:47<00:00, 54.92s/it]\u001b[A\n",
            "Processing queries:  90% 18/20 [1:07:34<07:32, 226.33s/it]\n",
            "Re-ranking 30 documents for training query 1864211\n",
            "Original pre-ranking (first 3): ['74893664', '14904274', '73417734']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:54, 58.28s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:59, 59.69s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:57<00:59, 59.15s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:42<00:00, 53.56s/it]\u001b[A\n",
            "Processing queries:  95% 19/20 [1:11:17<03:45, 225.17s/it]\n",
            "Re-ranking 30 documents for training query 61277994\n",
            "Original pre-ranking (first 3): ['13996136', '87721730', '43824316']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:54, 58.13s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:56<01:56, 58.19s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:56<00:59, 59.08s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:46<00:00, 55.50s/it]\u001b[A\n",
            "Processing queries: 100% 20/20 [1:15:03<00:00, 225.20s/it]\n",
            "Saving re-ranked results to /content/dataset2/predictions2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation (training only)"
      ],
      "metadata": {
        "id": "jRNpIuXLZmWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##### With the model intfloat/e5-large-v2"
      ],
      "metadata": {
        "id": "w48geBc33sNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_train_rankings.py --re_ranking /content/dataset2/prediction2.json   --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725t8jk9YuR6",
        "outputId": "70497280-3b2f-4662-9dca-132723afff6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training queries...\n",
            "Loaded 20 training queries\n",
            "Loading ranking data and gold standard...\n",
            "Evaluating rankings for 20 training queries...\n",
            "\n",
            "Pre-ranking performance (training queries only):\n",
            "  Recall@3: 0.1108\n",
            "  Recall@5: 0.2083\n",
            "  Recall@10: 0.4046\n",
            "  Recall@20: 0.6565\n",
            "  MAP: 0.2140\n",
            "  Mean Inverse Rank: 0.2984\n",
            "  Mean Rank: 7.20\n",
            "\n",
            "Re-ranking performance (training queries only):\n",
            "  Recall@3: 0.1063\n",
            "  Recall@5: 0.1580\n",
            "  Recall@10: 0.3646\n",
            "  Recall@20: 0.6832\n",
            "  MAP: 0.1993\n",
            "  Mean Inverse Rank: 0.2777\n",
            "  Mean Rank: 7.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using this combination: 'BAAI/bge-large-en-v1.5 and description`"
      ],
      "metadata": {
        "id": "kfnZYweg3zJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_train_rankings.py --re_ranking prediction2_desc.json   --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ZAn_yV3qtG",
        "outputId": "bd4077e8-dca1-4ea9-dcd4-9acb8316bd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training queries...\n",
            "Loaded 20 training queries\n",
            "Loading ranking data and gold standard...\n",
            "Evaluating rankings for 20 training queries...\n",
            "\n",
            "Pre-ranking performance (training queries only):\n",
            "  Recall@3: 0.1108\n",
            "  Recall@5: 0.2083\n",
            "  Recall@10: 0.4046\n",
            "  Recall@20: 0.6565\n",
            "  MAP: 0.2140\n",
            "  Mean Inverse Rank: 0.2984\n",
            "  Mean Rank: 7.20\n",
            "\n",
            "Re-ranking performance (training queries only):\n",
            "  Recall@3: 0.1183\n",
            "  Recall@5: 0.2892\n",
            "  Recall@10: 0.4743\n",
            "  Recall@20: 0.7787\n",
            "  MAP: 0.2288\n",
            "  Mean Inverse Rank: 0.2261\n",
            "  Mean Rank: 7.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ON TEST DATA"
      ],
      "metadata": {
        "id": "NB5LmyvOZtGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##### With the model intfloat/e5-large-v2"
      ],
      "metadata": {
        "id": "sFb-uS4J16cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python cross_encoder_reranking_test.py \\\n",
        "  --pre_ranking shuffled_pre_ranking.json \\\n",
        "  --output prediction2_test.json \\\n",
        "  --queries_content queries_content_with_features.json \\\n",
        "  --documents_content documents_content_with_features.json \\\n",
        "  --queries_list test_queries.json \\\n",
        "  --text_type tac1 \\\n",
        "  --model_name intfloat/e5-large-v2 \\\n",
        "  --batch_size 8 \\\n",
        "  --max_length 512 \\\n",
        "  --device cpu \\\n",
        "  --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crxNw3t7qyx3",
        "outputId": "a757c98c-e741-45e6-a007-4fa254652f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading testing queries from test_queries.json...\n",
            "Loaded 10 testing queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 testing queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model intfloat/e5-large-v2...\n",
            "2025-04-05 11:18:05.986698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743851886.054113   32120 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743851886.072426   32120 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 11:18:06.166301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for testing queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for testing query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:02, 60.96s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:01<02:01, 60.66s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:54<00:57, 57.42s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:40<00:00, 52.66s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [03:40<33:03, 220.35s/it]\n",
            "Re-ranking 30 documents for testing query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:01, 60.57s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.39s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:00<01:00, 60.27s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:43<00:00, 53.30s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [07:23<29:37, 222.24s/it]\n",
            "Re-ranking 30 documents for testing query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:55, 58.57s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.17s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:05<01:02, 62.81s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:51<00:00, 56.37s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [11:15<26:26, 226.60s/it]\n",
            "Re-ranking 30 documents for testing query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.73s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:59, 59.98s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:58<00:59, 59.57s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:45<00:00, 54.60s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [15:01<22:38, 226.35s/it]\n",
            "Re-ranking 30 documents for testing query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.67s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:59<01:58, 59.47s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.83s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:43<00:00, 53.50s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [18:44<18:45, 225.16s/it]\n",
            "Re-ranking 30 documents for testing query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:53, 57.96s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:57<01:57, 58.68s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:56<00:58, 58.97s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:42<00:00, 53.80s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [22:27<14:56, 224.21s/it]\n",
            "Re-ranking 30 documents for testing query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:57<02:53, 57.97s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:57<01:58, 59.18s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:56<00:59, 59.07s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:42<00:00, 53.72s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [26:09<11:10, 223.63s/it]\n",
            "Re-ranking 30 documents for testing query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:44<02:13, 44.47s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:45<01:47, 53.96s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:43<00:55, 55.94s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:29<00:00, 51.90s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [29:38<07:17, 219.00s/it]\n",
            "Re-ranking 30 documents for testing query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.17s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.17s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:57<00:59, 59.21s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:43<00:00, 54.01s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [33:22<03:40, 220.54s/it]\n",
            "Re-ranking 30 documents for testing query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:58<02:56, 58.98s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:57<01:57, 58.71s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:57<00:59, 59.35s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:41<00:00, 53.19s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [37:03<00:00, 222.39s/it]\n",
            "Saving re-ranked results to /content/dataset2/prediction2_test.json...\n",
            "Re-ranking complete!\n",
            "Number of testing queries processed: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using this combination: 'BAAI/bge-large-en-v1.5 and description`"
      ],
      "metadata": {
        "id": "KfZw3tdsRG8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python cross_encoder_reranking_test.py \\\n",
        "  --pre_ranking shuffled_pre_ranking.json \\\n",
        "  --output prediction2_desc_test.json \\\n",
        "  --queries_content queries_content_with_features.json \\\n",
        "  --documents_content documents_content_with_features.json \\\n",
        "  --queries_list test_queries.json \\\n",
        "  --text_type tac1 \\\n",
        "  --model_name BAAI/bge-large-en-v1.5 \\\n",
        "  --batch_size 8 \\\n",
        "  --max_length 512 \\\n",
        "  --device cpu \\\n",
        "  --base_dir /content/dataset2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcXzuo0Hqyp-",
        "outputId": "3e901f3c-63d9-443f-e469-08a2d477c386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading testing queries from test_queries.json...\n",
            "Loaded 10 testing queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 testing queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model BAAI/bge-large-en-v1.5...\n",
            "2025-04-05 14:05:50.592306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743861950.638701   72304 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743861950.650973   72304 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 14:05:50.690468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for testing queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for testing query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:02<03:07, 62.37s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.15s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:53<00:56, 56.81s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:46<00:00, 55.37s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [03:46<34:02, 226.97s/it]\n",
            "Re-ranking 30 documents for testing query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:02, 60.71s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.12s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:59<00:59, 59.71s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:40<00:00, 52.46s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [07:27<29:45, 223.15s/it]\n",
            "Re-ranking 30 documents for testing query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:01, 60.55s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:01<02:01, 60.95s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:02<01:00, 60.96s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:49<00:00, 55.52s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [11:17<26:23, 226.24s/it]\n",
            "Re-ranking 30 documents for testing query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.17s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.18s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:07<01:03, 63.31s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:51<00:00, 55.60s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [15:08<22:49, 228.19s/it]\n",
            "Re-ranking 30 documents for testing query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:00<03:00, 60.02s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.28s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:58<00:59, 59.70s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:42<00:00, 53.36s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [18:51<18:50, 226.18s/it]\n",
            "Re-ranking 30 documents for testing query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:01<03:03, 61.18s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:00<02:00, 60.14s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:01<01:00, 60.47s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:45<00:00, 54.11s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [22:36<15:04, 226.06s/it]\n",
            "Re-ranking 30 documents for testing query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:01<03:03, 61.15s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:08<02:09, 64.52s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:08<01:02, 62.67s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:55<00:00, 56.45s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [26:32<11:27, 229.11s/it]\n",
            "Re-ranking 30 documents for testing query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:46<02:20, 46.94s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:45<01:47, 53.68s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:45<00:56, 56.63s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:29<00:00, 51.46s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [30:01<07:25, 222.72s/it]\n",
            "Re-ranking 30 documents for testing query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [00:59<02:59, 59.94s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [01:58<01:58, 59.10s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [02:58<00:59, 59.34s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [03:46<00:00, 55.07s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [33:48<03:43, 223.93s/it]\n",
            "Re-ranking 30 documents for testing query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  25% 1/4 [01:12<03:37, 72.54s/it]\u001b[A\n",
            "Scoring documents:  50% 2/4 [02:15<02:13, 66.68s/it]\u001b[A\n",
            "Scoring documents:  75% 3/4 [03:14<01:03, 63.31s/it]\u001b[A\n",
            "Scoring documents: 100% 4/4 [04:01<00:00, 57.00s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [37:49<00:00, 226.97s/it]\n",
            "Saving re-ranked results to /content/dataset2/prediction2_desc_test.json...\n",
            "Re-ranking complete!\n",
            "Number of testing queries processed: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dCY5d0Hcb7t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation of results (2) using embeddings"
      ],
      "metadata": {
        "id": "pkeHf_UyEzyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers"
      ],
      "metadata": {
        "id": "SEM5MvBdFlxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python create_embeddings.py \\\n",
        "  --pooling mean \\\n",
        "  --model AI-Growth-Lab/PatentSBERTa \\\n",
        "  --input_file /content/dataset2/documents_content_with_features.json \\\n",
        "  --output_dir ./patentsberta_embeddings \\\n",
        "  --content_types TA,claims,TAC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VowTWPAWFkvn",
        "outputId": "2c981298-1193-4f51-880f-839e572219ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-05 14:52:31.370774: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743864751.419532   83409 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743864751.434935   83409 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 14:52:31.479248: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded 900 documents from /content/dataset2/documents_content_with_features.json\n",
            "Processing TA embeddings...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/create_embeddings.py\", line 114, in <module>\n",
            "    main()\n",
            "  File \"/content/create_embeddings.py\", line 93, in main\n",
            "    app_ids.append(doc['Application_Number'] + doc['Application_Category'])\n",
            "                   ~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyError: 'Application_Number'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load PatentSBERTa model, use the default model if the specified one is unavailable\n",
        "try:\n",
        "    model_TA = SentenceTransformer(\"AI-Growth-Lab/PatentSBERTa\")  # Example for TA\n",
        "except OSError:\n",
        "    print(\"WARNING: 'whitphx/PatentSBERTa' not found, using 'AI-Growth-Lab/PatentSBERTa' instead.\")\n",
        "    model_TA = SentenceTransformer(\"AI-Growth-Lab/PatentSBERTa\")  # Default model\n",
        "\n",
        "# For claims and TAC, you might need to use different checkpoints if available,\n",
        "# or extract different parts of the text and then use the same model.\n",
        "\n",
        "# For demonstration, let's assume you have functions to extract TA, claims, and TAC:\n",
        "def extract_TA(patent):\n",
        "    return patent.get(\"title\", \"\") + \" \" + patent.get(\"abstract\", \"\")\n",
        "\n",
        "def extract_claims(patent):\n",
        "    return patent.get(\"claims\", \"\")\n",
        "\n",
        "def extract_TAC(patent):\n",
        "    return extract_TA(patent) + \" \" + extract_claims(patent)\n",
        "\n",
        "# Create embeddings for documents:\n",
        "doc_texts_TA = [extract_TA(doc) for doc in docs_content_with_features]\n",
        "doc_texts_claims = [extract_claims(doc) for doc in docs_content_with_features]\n",
        "doc_texts_TAC = [extract_TAC(doc) for doc in docs_content_with_features]\n",
        "\n",
        "embeddings_TA = model_TA.encode(doc_texts_TA, convert_to_numpy=True)\n",
        "embeddings_claims = model_TA.encode(doc_texts_claims, convert_to_numpy=True)\n",
        "embeddings_TAC = model_TA.encode(doc_texts_TAC, convert_to_numpy=True)\n",
        "\n",
        "# Save the embeddings to reuse later if desired\n",
        "np.save(\"embeddings_TA.npy\", embeddings_TA)\n",
        "np.save(\"embeddings_claims.npy\", embeddings_claims)\n",
        "np.save(\"embeddings_TAC.npy\", embeddings_TAC)"
      ],
      "metadata": {
        "id": "CGxo18WZcTkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_sum(emb1, emb2):\n",
        "    return emb1 + emb2\n",
        "\n",
        "def combine_average(emb1, emb2):\n",
        "    return (emb1 + emb2) / 2\n",
        "\n",
        "def combine_concatenate(emb1, emb2):\n",
        "    return np.concatenate((emb1, emb2), axis=-1)\n",
        "\n",
        "def combine_weighted(emb1, emb2, weight1=0.5, weight2=0.5):\n",
        "    return weight1 * emb1 + weight2 * emb2\n"
      ],
      "metadata": {
        "id": "FlTdSxKTdujH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings_avg = combine_average(embeddings_TA, embeddings_claims)\n",
        "combined_embeddings_weighted = combine_weighted(embeddings_TA, embeddings_claims, weight1=0.7, weight2=0.3)\n"
      ],
      "metadata": {
        "id": "exYXd-l3d0K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming combined_embeddings_avg and combined_embeddings_weighted are already computed\n",
        "# as NumPy arrays.\n",
        "\n",
        "np.save(\"combined_embeddings_avg.npy\", combined_embeddings_avg)\n",
        "np.save(\"combined_embeddings_weighted.npy\", combined_embeddings_weighted)\n"
      ],
      "metadata": {
        "id": "G4_JmgKuepwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combination of the results using the RRF ALGO"
      ],
      "metadata": {
        "id": "dF33rzUuE5T9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FqDKVx_8OhG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "w64uFYNoeqO_",
        "XcXigwGceqPA",
        "lMUbtAgh69N5",
        "MucVMw6F8Nw9",
        "xEuYK4g-ZiQr",
        "WZrCqgC22ohH",
        "w48geBc33sNM",
        "kfnZYweg3zJN",
        "NB5LmyvOZtGZ",
        "sFb-uS4J16cn",
        "KfZw3tdsRG8_"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}