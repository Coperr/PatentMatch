{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGj5wN1v-5ko"
      },
      "source": [
        "# Dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxRosCDp_k4O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dq4ZzzFroSe",
        "outputId": "3869e991-fb91-458d-9f9a-6fce736503f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YtFbXim-8b7"
      },
      "source": [
        "# 0. Loading data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx5y8Z_-rrbn",
        "outputId": "350a91c8-8189-4ab9-e55c-3c2466e38b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Necessary data files for the test set found.\n"
          ]
        }
      ],
      "source": [
        "# PATHS\n",
        "train_queries_file = \"train_queries.json\"\n",
        "test_queries_file = \"test_queries.json\"\n",
        "train_gold_mapping_file = \"train_gold_mapping.json\"\n",
        "shuffled_pre_ranking_file = \"shuffled_pre_ranking.json\"\n",
        "queries_content_file = \"queries_content_with_features.json\"\n",
        "documents_content_file = \"documents_content_with_features.json\"\n",
        "\n",
        "test_predictions_file = \"prediction2.json\"\n",
        "\n",
        "if not all(os.path.exists(f) for f in [test_queries_file, shuffled_pre_ranking_file, queries_content_file, documents_content_file]):\n",
        "    print(\"Error: One or more necessary data files for the test set are missing.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"Necessary data files for the test set found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5F18z5rsAn_",
        "outputId": "723ea5b2-d9ef-4537-de46-396988ab12ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 test queries.\n",
            "Filtered pre-ranking to 10 test queries.\n",
            "Reranking script found.\n"
          ]
        }
      ],
      "source": [
        "# LOAD\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "test_queries = load_json_file(test_queries_file)\n",
        "print(f\"Loaded {len(test_queries)} test queries.\")\n",
        "\n",
        "pre_ranking_test = load_json_file(shuffled_pre_ranking_file)\n",
        "# filter pre-ranking to include only test queries (important!)\n",
        "pre_ranking_test_filtered = {fan: docs for fan, docs in pre_ranking_test.items() if fan in test_queries}\n",
        "print(f\"Filtered pre-ranking to {len(pre_ranking_test_filtered)} test queries.\")\n",
        "\n",
        "\n",
        "queries_content = load_json_file(queries_content_file)\n",
        "documents_content = load_json_file(documents_content_file)\n",
        "\n",
        "\n",
        "if not os.path.exists(\"cross_encoder_reranking_train.py\"):\n",
        "    print(\"Error: The 'cross_encoder_reranking_train.py' script is missing. Please upload it.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"Reranking script found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqOzl2wK0ddz"
      },
      "source": [
        "# 1. Re-ranking the results with cross-encoder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51m24r7i0kzL"
      },
      "source": [
        "We will use the model ` \"intfloat/e5-large-v2\" `with different combinations of the documents parts like: `ta`, `tac1`....etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI4-4ulb3Xn_"
      },
      "outputs": [],
      "source": [
        "base_dir =\"/content\" # adapt this base dir according to your folders  (/content when using google colab and the files are directly in /content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xVLY1oI0w9l"
      },
      "source": [
        "## 1.1. E5 LARGE TA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SciWrL5J6-8Z",
        "outputId": "49849197-cb4d-4669-850a-9de3998815e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model intfloat/e5-large-v2...\n",
            "tokenizer_config.json: 100% 314/314 [00:00<00:00, 2.66MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 5.93MB/s]\n",
            "tokenizer.json: 100% 711k/711k [00:00<00:00, 15.3MB/s]\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 1.25MB/s]\n",
            "config.json: 100% 616/616 [00:00<00:00, 4.77MB/s]\n",
            "model.safetensors: 100% 1.34G/1.34G [00:05<00:00, 245MB/s]\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:01<00:07,  1.00s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.17it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:03,  1.31it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.30it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:03<00:02,  1.32it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:04<00:01,  1.35it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.31it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:05<00:00,  1.50it/s]\u001b[A\n",
            "Processing queries:  10% 1/10 [00:05<00:53,  5.90s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:05,  1.28it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.50it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:03,  1.52it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:02<00:02,  1.70it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:03<00:01,  1.71it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.47it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:04<00:00,  1.59it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:04<00:00,  1.81it/s]\u001b[A\n",
            "Processing queries:  20% 2/10 [00:10<00:42,  5.28s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:04,  1.69it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:03,  1.76it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  1.84it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:02<00:02,  1.79it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  1.72it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.74it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:04<00:00,  1.83it/s]\u001b[A\n",
            "Processing queries:  30% 3/10 [00:15<00:34,  4.92s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:03,  1.96it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:02,  2.04it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  2.02it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:02<00:02,  1.95it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  1.96it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.88it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  1.88it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:03<00:00,  2.10it/s]\u001b[A\n",
            "Processing queries:  40% 4/10 [00:19<00:27,  4.56s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:04,  1.75it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:03,  1.92it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  1.96it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:02<00:02,  1.86it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  1.86it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.86it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  1.87it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:04<00:00,  2.07it/s]\u001b[A\n",
            "Processing queries:  50% 5/10 [00:23<00:21,  4.40s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:03,  2.05it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:02,  2.11it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  2.12it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:01<00:01,  2.14it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  2.09it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:02<00:00,  2.04it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  2.04it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:03<00:00,  2.13it/s]\u001b[A\n",
            "Processing queries:  60% 6/10 [00:27<00:16,  4.20s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:05,  1.32it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.29it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:03,  1.35it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:02<00:02,  1.44it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:04<00:01,  1.56it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:04<00:00,  1.66it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:05<00:00,  1.79it/s]\u001b[A\n",
            "Processing queries:  70% 7/10 [00:32<00:13,  4.48s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:03,  2.07it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:02,  2.07it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  2.12it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:01<00:01,  2.16it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  2.12it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:02<00:00,  2.15it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  2.14it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:03<00:00,  2.28it/s]\u001b[A\n",
            "Processing queries:  80% 8/10 [00:35<00:08,  4.22s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:03,  2.10it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:02,  2.11it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  2.07it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:01<00:01,  2.02it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  2.06it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.77it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  1.84it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:04<00:00,  2.05it/s]\u001b[A\n",
            "Processing queries:  90% 9/10 [00:39<00:04,  4.16s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:03,  1.94it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:02,  2.08it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:01<00:02,  2.08it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:01<00:01,  2.09it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:02<00:01,  2.05it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:03<00:01,  1.90it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:03<00:00,  2.17it/s]\u001b[A\n",
            "Processing queries: 100% 10/10 [00:43<00:00,  4.38s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# E5 LARGE ta\n",
        "\n",
        "best_model_name = \"intfloat/e5-large-v2\"\n",
        "best_text_type = \"TA\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKs_03YK23AD"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_e5Large_TA.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLgfLq01C2q"
      },
      "source": [
        "## 1.2. E5 LARGE tac1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHgGozrztq7I",
        "outputId": "f952e1b0-ddd2-47a6-e443-3fff7bc28e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model intfloat/e5-large-v2...\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:18,  2.59s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:05<00:15,  2.58s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.57s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.27s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:06,  2.19s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:13<00:04,  2.04s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:15<00:02,  2.17s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:16<00:00,  1.82s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [00:16<02:31, 16.84s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.44s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.47s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.49s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:08,  2.20s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:06,  2.29s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.33s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.28s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:16<00:00,  1.74s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [00:33<02:14, 16.83s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.51s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.48s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.50s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.50s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.47s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:15<00:05,  2.52s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.52s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.18s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [00:52<02:04, 17.82s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.49s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.48s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.46s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:10<00:10,  2.55s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.46s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.45s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.44s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  1.98s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [01:10<01:47, 17.98s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.46s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:05<00:15,  2.54s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.52s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.28s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:06,  2.31s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.38s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.25s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:17<00:00,  1.94s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [01:28<01:29, 17.85s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.46s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.45s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.41s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.43s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.45s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.44s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.44s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.09s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [01:46<01:12, 18.04s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.51s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:05<00:15,  2.62s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:13,  2.61s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:10<00:10,  2.56s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.51s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:15<00:05,  2.53s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.57s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:19<00:00,  2.14s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [02:06<00:55, 18.40s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:01<00:11,  1.58s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:03<00:09,  1.52s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:05<00:09,  1.97s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:08<00:08,  2.18s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:10<00:06,  2.31s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:12<00:04,  2.05s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:14<00:02,  2.21s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:16<00:00,  1.94s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [02:22<00:35, 17.65s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.53s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.49s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:13,  2.64s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:10<00:10,  2.64s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.60s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:15<00:05,  2.56s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.55s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:19<00:00,  2.18s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [02:41<00:18, 18.19s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.51s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.40s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.36s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.41s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.44s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.41s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.42s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.07s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [02:59<00:00, 17.97s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# E5 LARGE tac1\n",
        "\n",
        "best_model_name = \"intfloat/e5-large-v2\"\n",
        "best_text_type = \"tac1\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOiBwZcP3eDy"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_e5Large_TAC1.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4SbN_2y3d9E"
      },
      "source": [
        "## 1.3. E5 LARGE CLAIMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksH7DVKFsSKm",
        "outputId": "aefcc79b-d545-4e11-c3a0-619136ca94de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model intfloat/e5-large-v2...\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:18,  2.68s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:05<00:15,  2.63s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.52s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:10<00:09,  2.46s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.45s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:15<00:05,  2.51s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.51s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:19<00:00,  2.19s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [00:19<02:52, 19.13s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.33s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.35s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.38s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.34s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:07,  2.34s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.34s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.35s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:17<00:00,  2.09s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [00:37<02:27, 18.45s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.39s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:13,  2.33s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:06<00:11,  2.31s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.29s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:06,  2.31s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.38s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.36s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:17<00:00,  2.10s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [00:55<02:07, 18.23s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.32s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:13,  2.32s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.34s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.37s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:07,  2.34s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.33s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.31s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:17<00:00,  2.06s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [01:12<01:48, 18.06s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:17,  2.47s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.48s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.42s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.39s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.39s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.39s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.46s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.16s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [01:31<01:31, 18.23s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.38s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.34s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.36s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.41s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:07,  2.40s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.35s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.35s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.08s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [01:49<01:12, 18.17s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.36s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.37s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.47s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:10,  2.53s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.47s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.41s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.42s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.13s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [02:08<00:54, 18.30s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.37s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.36s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.34s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.32s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:07,  2.40s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.38s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.36s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.09s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [02:26<00:36, 18.22s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.34s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.36s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:11,  2.39s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:09,  2.37s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:11<00:07,  2.34s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:04,  2.37s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:16<00:02,  2.39s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:18<00:00,  2.19s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [02:44<00:18, 18.27s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:02<00:16,  2.40s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:04<00:14,  2.39s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:07<00:12,  2.44s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:09<00:10,  2.50s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:12<00:07,  2.42s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:14<00:05,  2.56s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:17<00:02,  2.58s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:19<00:00,  2.25s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [03:03<00:00, 18.36s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# E5 LARGE CLAIMS\n",
        "\n",
        "best_model_name = \"intfloat/e5-large-v2\"\n",
        "best_text_type = \"claims\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvMtr06n3rE4"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_e5Large_CLAIMS.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3BqCDky3rA7"
      },
      "source": [
        "## 1.4. MPNET TA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjvHOL-ju0xA",
        "outputId": "c5e5065a-3198-489c-e28a-8acbb123ec0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model sentence-transformers/all-mpnet-base-v2...\n",
            "tokenizer_config.json: 100% 363/363 [00:00<00:00, 3.27MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 5.33MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 892kB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.43MB/s]\n",
            "config.json: 100% 571/571 [00:00<00:00, 4.45MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 438M/438M [00:01<00:00, 255MB/s]\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  3.73it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  4.41it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:01,  4.68it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  4.83it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:01<00:00,  4.92it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  4.93it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  4.90it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  5.62it/s]\u001b[A\n",
            "Processing queries:  10% 1/10 [00:01<00:14,  1.59s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  4.89it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  6.00it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:01,  4.81it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  5.82it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  5.92it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  5.29it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  5.75it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.64it/s]\u001b[A\n",
            "Processing queries:  20% 2/10 [00:02<00:11,  1.45s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  5.46it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  5.50it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  6.06it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  5.58it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  5.50it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  5.47it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.00it/s]\u001b[A\n",
            "Processing queries:  30% 3/10 [00:04<00:09,  1.42s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  6.37it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:00,  6.80it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  6.37it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  6.49it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:00<00:00,  6.38it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  6.36it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.84it/s]\u001b[A\n",
            "Processing queries:  40% 4/10 [00:05<00:08,  1.34s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  5.84it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  5.85it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  6.42it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  4.63it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  5.25it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  5.77it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  6.18it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.84it/s]\u001b[A\n",
            "Processing queries:  50% 5/10 [00:06<00:06,  1.33s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  6.62it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:00,  6.63it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  6.34it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  6.14it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:00<00:00,  6.31it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  6.14it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.28it/s]\u001b[A\n",
            "Processing queries:  60% 6/10 [00:08<00:05,  1.31s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  4.11it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  4.16it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:01,  4.52it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  4.33it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:01<00:00,  4.32it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  4.50it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  4.74it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  5.36it/s]\u001b[A\n",
            "Processing queries:  70% 7/10 [00:09<00:04,  1.43s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  6.63it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:00,  6.31it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  6.34it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  6.41it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  5.97it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:00<00:00,  5.88it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  6.02it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.38it/s]\u001b[A\n",
            "Processing queries:  80% 8/10 [00:11<00:02,  1.39s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  5.19it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:01,  5.38it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  5.43it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  4.80it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  4.93it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  4.32it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  4.70it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  5.41it/s]\u001b[A\n",
            "Processing queries:  90% 9/10 [00:12<00:01,  1.45s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:01,  5.64it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:00<00:00,  6.07it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:00<00:00,  6.09it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:00<00:00,  5.97it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:00<00:00,  5.76it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:01<00:00,  5.16it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:01<00:00,  5.78it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:01<00:00,  6.35it/s]\u001b[A\n",
            "Processing queries: 100% 10/10 [00:14<00:00,  1.40s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# MPNET TA\n",
        "\n",
        "best_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "best_text_type = \"TA\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYWq9sc737Q2"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_MPNET_TA.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBnZvgT37Ny"
      },
      "source": [
        "## 1.5. MPNET CLAIMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbxxPdIlskVt",
        "outputId": "6cc20399-5535-4a77-d410-71c27403b6a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model sentence-transformers/all-mpnet-base-v2...\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.03it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.08it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.11it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.13it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.13it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.16it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:06<00:00,  1.17it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.40it/s]\u001b[A\n",
            "Processing queries:  10% 1/10 [00:06<00:59,  6.56s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:05,  1.21it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.24it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.21it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.20it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.19it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.18it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:06<00:00,  1.12it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.32it/s]\u001b[A\n",
            "Processing queries:  20% 2/10 [00:13<00:52,  6.51s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.11it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.14it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.16it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.19it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.21it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.20it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.19it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.44it/s]\u001b[A\n",
            "Processing queries:  30% 3/10 [00:19<00:44,  6.42s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.15it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.17it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.11it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.14it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.12it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.14it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:06<00:00,  1.13it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.31it/s]\u001b[A\n",
            "Processing queries:  40% 4/10 [00:26<00:39,  6.52s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.12it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.22it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.25it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.22it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.21it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:04<00:01,  1.22it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.26it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.53it/s]\u001b[A\n",
            "Processing queries:  50% 5/10 [00:32<00:31,  6.35s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:05,  1.29it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.15it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.16it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.17it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.21it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.21it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.19it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.37it/s]\u001b[A\n",
            "Processing queries:  60% 6/10 [00:38<00:25,  6.35s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.16it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.18it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.16it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.19it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.20it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.17it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.17it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.38it/s]\u001b[A\n",
            "Processing queries:  70% 7/10 [00:44<00:19,  6.37s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.16it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.21it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.21it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.18it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.18it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.20it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.18it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.35it/s]\u001b[A\n",
            "Processing queries:  80% 8/10 [00:51<00:12,  6.39s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:06,  1.16it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:05,  1.11it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:04,  1.05it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.09it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.13it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:05<00:01,  1.14it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:06<00:00,  1.14it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.33it/s]\u001b[A\n",
            "Processing queries:  90% 9/10 [00:57<00:06,  6.49s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:00<00:05,  1.18it/s]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:01<00:04,  1.39it/s]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:02<00:03,  1.27it/s]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:03<00:03,  1.21it/s]\u001b[A\n",
            "Scoring documents:  62% 5/8 [00:04<00:02,  1.16it/s]\u001b[A\n",
            "Scoring documents:  75% 6/8 [00:04<00:01,  1.20it/s]\u001b[A\n",
            "Scoring documents:  88% 7/8 [00:05<00:00,  1.16it/s]\u001b[A\n",
            "Scoring documents: 100% 8/8 [00:06<00:00,  1.31it/s]\u001b[A\n",
            "Processing queries: 100% 10/10 [01:04<00:00,  6.44s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# MPNET CLAIMS\n",
        "\n",
        "best_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "best_text_type = \"claims\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT0firGk4Bys"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_MPNET_CLAIMS.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpCIlXlEoIS"
      },
      "source": [
        "## 1.5+. MPNET full (very bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nsRCFsCFGre",
        "outputId": "df777196-c583-417a-8c07-6f5700d302f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model sentence-transformers/all-mpnet-base-v2...\n",
            "2025-04-08 20:40:35.933535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744144835.980489    4422 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744144835.992981    4422 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-08 20:40:36.034571: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:31, 13.01s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:25<01:14, 12.50s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:01, 12.33s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:49<00:49, 12.34s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:01<00:37, 12.34s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:14<00:24, 12.34s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:26<00:12, 12.27s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:32<00:00, 10.42s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [01:32<13:56, 92.91s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:11<01:23, 11.87s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:29<01:33, 15.51s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:42<01:10, 14.08s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:56<00:57, 14.31s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:11<00:43, 14.45s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:23<00:26, 13.46s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:35<00:12, 12.99s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:42<00:00, 11.11s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [03:15<13:07, 98.44s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:11<01:23, 11.96s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:13, 12.25s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:03, 12.64s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:49<00:49, 12.50s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:04<00:40, 13.45s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:17<00:26, 13.08s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:29<00:12, 12.79s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:35<00:00, 10.64s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [04:50<11:19, 97.11s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:24, 12.12s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:26<01:20, 13.38s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:42<01:13, 14.75s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:58<01:00, 15.04s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:13<00:45, 15.26s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:29<00:30, 15.34s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:47<00:16, 16.23s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:56<00:00, 13.98s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [06:47<10:28, 104.81s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:15<01:50, 15.85s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:29<01:25, 14.31s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:47<01:21, 16.31s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [01:05<01:07, 16.99s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:21<00:50, 16.67s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:40<00:34, 17.45s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:59<00:17, 17.92s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [02:09<00:00, 15.22s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [08:56<09:28, 113.61s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:25, 12.19s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:12, 12.11s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:02, 12.48s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:50<00:50, 12.63s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:04<00:40, 13.35s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:17<00:26, 13.19s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:30<00:12, 13.00s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:36<00:00, 10.83s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [10:32<07:10, 107.74s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:11<01:22, 11.84s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:23<01:11, 11.99s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:36<01:00, 12.17s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:48<00:48, 12.20s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:02<00:38, 12.72s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:14<00:25, 12.50s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:26<00:12, 12.42s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:33<00:00, 10.56s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [12:06<05:08, 102.95s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:11<01:23, 11.97s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:12, 12.12s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:41<01:12, 14.59s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:55<00:56, 14.11s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:13<00:46, 15.60s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:25<00:28, 14.33s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:37<00:13, 13.68s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:43<00:00, 11.23s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [13:49<03:26, 103.14s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:25, 12.28s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:14, 12.36s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:01, 12.40s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:49<00:49, 12.37s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:01<00:36, 12.19s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:13<00:24, 12.32s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:26<00:12, 12.32s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:33<00:00, 10.69s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [15:22<01:40, 100.11s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:24, 12.04s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:23<01:11, 11.88s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:36<01:00, 12.11s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:48<00:48, 12.11s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:00<00:36, 12.10s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:12<00:24, 12.18s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:24<00:12, 12.03s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:30<00:00, 10.12s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [16:53<00:00, 101.35s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# MPNET CLAIMS\n",
        "\n",
        "best_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "best_text_type = \"full\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neA3jShwGBYG"
      },
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_MPNET_full.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading truth and prediction\n",
        "Checking Accuracy\n",
        "Scores:\n",
        "{'recall_at_3': 0.08055555555555556, 'recall_at_5': 0.10555555555555556, 'recall_at_10': 0.2595238095238095, 'recall_at_20': 0.7492063492063492, 'mean_rank': 14.783333333333331, 'mean_inv_rank': 0.10828456299601233, 'mean_average_precision': 0.19408953742409024}\n",
        "Scoring completed"
      ],
      "metadata": {
        "id": "i8_-weHO43SK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5++. MPNET description"
      ],
      "metadata": {
        "id": "o4WGxHsd_WPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MPNET description\n",
        "\n",
        "best_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "best_text_type = \"description\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfUwtkCU_Vp0",
        "outputId": "551c491f-eaf9-4c76-d9f9-9b5de19e35f6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model sentence-transformers/all-mpnet-base-v2...\n",
            "2025-04-09 00:40:54.119862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744159254.153456   61864 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744159254.163426   61864 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-09 00:40:54.212405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:29, 12.79s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.79s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:41<01:09, 13.84s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:53<00:52, 13.14s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:05<00:38, 12.84s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:17<00:25, 12.57s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:30<00:12, 12.70s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:44<00:00, 13.11s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [01:44<15:41, 104.56s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:15<01:51, 15.88s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:28<01:22, 13.73s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:05, 13.09s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:52<00:51, 12.76s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:04<00:37, 12.57s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:16<00:24, 12.38s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:29<00:12, 12.36s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:35<00:00, 10.46s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [03:20<13:14, 99.31s/it] \n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:19<02:14, 19.15s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:40<02:02, 20.34s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:56<01:32, 18.45s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [01:08<01:03, 15.87s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:23<00:46, 15.46s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:40<00:32, 16.18s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:59<00:16, 16.86s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [02:09<00:00, 14.75s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [05:29<13:10, 112.99s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:32, 13.24s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:28<01:28, 14.72s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:46<01:19, 15.92s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:57<00:56, 14.20s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:09<00:39, 13.16s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:21<00:25, 12.84s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:33<00:12, 12.66s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:41<00:00, 11.04s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [07:10<10:50, 108.38s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:26, 12.39s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:25<01:16, 12.82s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:03, 12.61s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:50<00:50, 12.53s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:02<00:36, 12.33s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:13<00:24, 12.02s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:25<00:12, 12.04s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:33<00:00, 10.53s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [08:43<08:34, 102.85s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:26, 12.38s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:14, 12.46s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:37<01:03, 12.72s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:50<00:50, 12.66s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:02<00:37, 12.48s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:15<00:25, 12.64s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:27<00:12, 12.54s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:34<00:00, 10.72s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [10:18<06:40, 100.10s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:24, 12.04s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:12, 12.10s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:36<01:00, 12.16s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:48<00:49, 12.29s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:01<00:36, 12.26s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:13<00:24, 12.31s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:25<00:12, 12.26s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:32<00:00, 10.47s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [11:50<04:52, 97.55s/it] \n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:26, 12.36s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:13, 12.32s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:36<01:01, 12.29s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:49<00:49, 12.33s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:01<00:36, 12.32s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:13<00:24, 12.13s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:25<00:12, 12.07s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:31<00:00, 10.20s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [13:22<03:11, 95.62s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:25, 12.21s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:24<01:14, 12.45s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:45<01:20, 16.03s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:56<00:57, 14.32s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:08<00:40, 13.52s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:21<00:26, 13.20s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:33<00:12, 12.81s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:41<00:00, 11.14s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [15:03<01:37, 97.33s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:12<01:26, 12.41s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.76s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:39<01:05, 13.04s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:51<00:50, 12.65s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:03<00:37, 12.62s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:16<00:25, 12.58s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:34<00:14, 14.42s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:45<00:00, 13.21s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [16:48<00:00, 100.87s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_MPNET_description.json`"
      ],
      "metadata": {
        "id": "2QrteM_LFiih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 +++. MPNET description + features\n"
      ],
      "metadata": {
        "id": "EkqQ4JnwRA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "best_text_type = \"description_features\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length} \\\n",
        "    --base_dir \"{base_dir}\"\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U97qOozRRAUf",
        "outputId": "6d5b3b54-9e9f-4539-9251-ea8e6552d9d8"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model sentence-transformers/all-mpnet-base-v2...\n",
            "2025-04-09 02:12:07.679515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744164727.715707   83684 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744164727.725714   83684 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-09 02:12:07.773526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:14<01:38, 14.13s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:21, 13.55s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:42<01:10, 14.16s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:55<00:54, 13.70s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:08<00:40, 13.66s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:22<00:27, 13.57s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:35<00:13, 13.63s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:42<00:00, 11.39s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [01:42<15:22, 102.47s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:34, 13.49s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:21, 13.53s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:08, 13.68s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:54<00:54, 13.68s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:07<00:40, 13.58s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:21<00:27, 13.62s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:35<00:13, 13.57s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:42<00:00, 11.68s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [03:25<13:41, 102.67s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:36, 13.78s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.72s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:41<01:10, 14.04s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:54<00:53, 13.32s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:07<00:40, 13.48s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:20<00:26, 13.06s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:33<00:13, 13.21s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:40<00:00, 11.35s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [05:06<11:53, 101.90s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:37, 13.94s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:28<01:24, 14.04s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:42<01:10, 14.07s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:56<00:56, 14.04s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:10<00:42, 14.05s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:24<00:27, 13.96s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:37<00:13, 13.90s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:45<00:00, 11.80s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [06:51<10:18, 103.16s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:36, 13.82s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.71s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:41<01:08, 13.77s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:55<00:55, 13.84s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:09<00:41, 13.92s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:23<00:27, 14.00s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:37<00:13, 13.98s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:44<00:00, 11.72s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [08:35<08:37, 103.56s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:35, 13.61s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.70s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:08, 13.66s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:55<00:55, 13.81s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:08<00:41, 13.79s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:23<00:27, 13.95s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:37<00:14, 14.01s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:45<00:00, 12.06s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [10:20<06:56, 104.07s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:33, 13.38s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:26<01:20, 13.37s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:07, 13.51s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:53<00:53, 13.49s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:07<00:40, 13.42s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:20<00:27, 13.50s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:34<00:13, 13.47s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:41<00:00, 11.53s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [12:02<05:09, 103.28s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:37, 13.97s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:27<01:22, 13.69s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:41<01:08, 13.62s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:54<00:54, 13.59s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:07<00:40, 13.52s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:21<00:26, 13.49s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:35<00:13, 13.57s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:42<00:00, 11.51s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [13:44<03:25, 102.94s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:33, 13.38s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:26<01:21, 13.50s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:07, 13.56s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:54<00:54, 13.51s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:07<00:40, 13.42s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:20<00:26, 13.45s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:34<00:13, 13.48s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:42<00:00, 11.85s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [15:27<01:42, 102.87s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:13<01:33, 13.40s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:26<01:20, 13.37s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [00:40<01:07, 13.45s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [00:53<00:53, 13.40s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [01:06<00:39, 13.21s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [01:18<00:25, 12.87s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [01:31<00:12, 12.89s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [01:38<00:00, 11.13s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [17:06<00:00, 102.63s/it]\n",
            "Saving re-ranked results to /content/prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMARK**: We rename the `Test set predictions saved to: prediction2.json`to `prediction2_MPNET_DescFeat.json`"
      ],
      "metadata": {
        "id": "4H3ZcHLhRXpB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c8X6KXg4Bw3"
      },
      "source": [
        "## 1.6. BGE TA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj086sJHGIfc",
        "outputId": "d6ab11c5-d2a2-4aa6-97b5-496a4c07026a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running reranking on the test set...\n",
            "Loading training queries from test_queries.json...\n",
            "Loaded 10 training queries\n",
            "Loading pre-ranking data from shuffled_pre_ranking.json...\n",
            "Filtered pre-ranking to 10 training queries\n",
            "Loading query content from queries_content_with_features.json...\n",
            "Loading document content from documents_content_with_features.json...\n",
            "Loading model BAAI/bge-large-en...\n",
            "2025-04-07 16:57:57.396788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744045077.475814  135585 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744045077.496851  135585 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-07 16:57:57.597356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting re-ranking process for training queries...\n",
            "Processing queries:   0% 0/10 [00:00<?, ?it/s]\n",
            "Re-ranking 30 documents for training query 103964109\n",
            "Original pre-ranking (first 3): ['94596291', '65451984', '81098918']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:34<04:00, 34.31s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:06<03:17, 32.91s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:40<02:46, 33.38s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:06<02:02, 30.63s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:35<01:30, 30.16s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:03<00:58, 29.42s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:36<00:30, 30.46s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [03:52<00:00, 26.01s/it]\u001b[A\n",
            "Processing queries:  10% 1/10 [03:52<34:56, 233.00s/it]\n",
            "Re-ranking 30 documents for training query 72214279\n",
            "Original pre-ranking (first 3): ['4112132', '7126783', '66704221']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:32<03:44, 32.02s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:05<03:16, 32.73s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:37<02:41, 32.39s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:02<01:58, 29.67s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:35<01:32, 30.91s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:07<01:02, 31.28s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:37<00:30, 30.85s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [03:51<00:00, 25.29s/it]\u001b[A\n",
            "Processing queries:  20% 2/10 [07:44<30:55, 231.94s/it]\n",
            "Re-ranking 30 documents for training query 68249923\n",
            "Original pre-ranking (first 3): ['35246469', '80619246', '7191590']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:33<03:52, 33.26s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:05<03:14, 32.46s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:38<02:44, 32.80s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:12<02:12, 33.15s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:45<01:39, 33.20s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:17<01:05, 32.79s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:50<00:32, 32.92s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:09<00:00, 28.35s/it]\u001b[A\n",
            "Processing queries:  30% 3/10 [11:53<27:58, 239.77s/it]\n",
            "Re-ranking 30 documents for training query 79740635\n",
            "Original pre-ranking (first 3): ['72282319', '80126462', '6507475']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:33<03:52, 33.17s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:05<03:14, 32.43s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:38<02:43, 32.76s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:10<02:09, 32.45s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:43<01:38, 32.67s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:15<01:04, 32.45s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:48<00:32, 32.71s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:07<00:00, 28.19s/it]\u001b[A\n",
            "Processing queries:  40% 4/10 [16:00<24:15, 242.64s/it]\n",
            "Re-ranking 30 documents for training query 100251983\n",
            "Original pre-ranking (first 3): ['82028496', '89295990', '78872192']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:34<04:00, 34.35s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:06<03:18, 33.12s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:39<02:44, 32.96s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:08<02:06, 31.58s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:40<01:35, 31.72s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:14<01:04, 32.25s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:42<00:31, 31.02s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:00<00:00, 26.74s/it]\u001b[A\n",
            "Processing queries:  50% 5/10 [20:00<20:08, 241.75s/it]\n",
            "Re-ranking 30 documents for training query 76109416\n",
            "Original pre-ranking (first 3): ['67929958', '1212129', '74871145']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:33<03:53, 33.35s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:05<03:15, 32.66s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:40<02:47, 33.53s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:12<02:12, 33.03s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:45<01:39, 33.12s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:17<01:05, 32.77s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:51<00:32, 32.98s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:09<00:00, 28.40s/it]\u001b[A\n",
            "Processing queries:  60% 6/10 [24:10<16:17, 244.45s/it]\n",
            "Re-ranking 30 documents for training query 85685768\n",
            "Original pre-ranking (first 3): ['5399125', '103242931', '96992323']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:32<03:48, 32.62s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:04<03:12, 32.16s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:36<02:39, 31.95s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:09<02:09, 32.33s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:41<01:37, 32.54s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:14<01:05, 32.64s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:46<00:32, 32.33s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:06<00:00, 28.37s/it]\u001b[A\n",
            "Processing queries:  70% 7/10 [28:16<12:15, 245.09s/it]\n",
            "Re-ranking 30 documents for training query 70563808\n",
            "Original pre-ranking (first 3): ['76578541', '66791385', '44519425']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:25<03:00, 25.72s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [00:48<02:23, 23.94s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:21<02:20, 28.01s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [01:52<01:57, 29.44s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:25<01:31, 30.59s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [02:48<00:56, 28.16s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:22<00:29, 29.79s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [03:41<00:00, 26.48s/it]\u001b[A\n",
            "Processing queries:  80% 8/10 [31:58<07:55, 237.58s/it]\n",
            "Re-ranking 30 documents for training query 79482665\n",
            "Original pre-ranking (first 3): ['87571623', '92503480', '68914227']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:32<03:44, 32.10s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:03<03:11, 31.95s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:36<02:41, 32.36s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:08<02:08, 32.13s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:41<01:37, 32.36s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:12<01:04, 32.11s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:45<00:32, 32.35s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:04<00:00, 27.98s/it]\u001b[A\n",
            "Processing queries:  90% 9/10 [36:02<03:59, 239.72s/it]\n",
            "Re-ranking 30 documents for training query 75800075\n",
            "Original pre-ranking (first 3): ['33464411', '34284570', '74966633']\n",
            "\n",
            "Scoring documents:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Scoring documents:  12% 1/8 [00:34<03:58, 34.02s/it]\u001b[A\n",
            "Scoring documents:  25% 2/8 [01:04<03:11, 31.94s/it]\u001b[A\n",
            "Scoring documents:  38% 3/8 [01:34<02:36, 31.27s/it]\u001b[A\n",
            "Scoring documents:  50% 4/8 [02:07<02:07, 31.90s/it]\u001b[A\n",
            "Scoring documents:  62% 5/8 [02:39<01:35, 31.71s/it]\u001b[A\n",
            "Scoring documents:  75% 6/8 [03:10<01:03, 31.67s/it]\u001b[A\n",
            "Scoring documents:  88% 7/8 [03:42<00:31, 31.71s/it]\u001b[A\n",
            "Scoring documents: 100% 8/8 [04:00<00:00, 27.32s/it]\u001b[A\n",
            "Processing queries: 100% 10/10 [40:03<00:00, 240.31s/it]\n",
            "Saving re-ranked results to prediction2.json...\n",
            "Re-ranking complete!\n",
            "Number of training queries processed: 10\n",
            "\n",
            "Test set predictions saved to: prediction2.json\n"
          ]
        }
      ],
      "source": [
        "# BGE TA\n",
        "\n",
        "best_model_name = \"BAAI/bge-large-en\"\n",
        "\n",
        "best_text_type = \"tac1\"\n",
        "max_length = 512\n",
        "\n",
        "print(\"\\nRunning reranking on the test set...\")\n",
        "!python cross_encoder_reranking_train.py \\\n",
        "    --model_name \"{best_model_name}\" \\\n",
        "    --text_type \"{best_text_type}\" \\\n",
        "    --pre_ranking \"{shuffled_pre_ranking_file}\" \\\n",
        "    --queries_list \"{test_queries_file}\" \\\n",
        "    --queries_content \"{queries_content_file}\" \\\n",
        "    --documents_content \"{documents_content_file}\" \\\n",
        "    --output \"{test_predictions_file}\" \\\n",
        "    --max_length {max_length}\n",
        "\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cdBRtHV7rx_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjv58W4L7rjt"
      },
      "source": [
        "## 1.7. GEMINI try (an attempts)\n",
        "\n",
        "For this model there are some limitations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvRu6UgbN9yi",
        "outputId": "635dc882-4090-48b0-d0ab-66b7778333d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Necessary data files for the test set found.\n",
            "Loaded 10 test queries.\n",
            "Filtered pre-ranking to 10 test queries.\n",
            "\n",
            "Starting reranking process for test queries using Gemini Embedding Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing queries:  10%|█         | 1/10 [00:12<01:53, 12.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error getting Gemini embeddings for batch starting at index 6: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 103964109. Keeping original ranking.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing queries:  40%|████      | 4/10 [00:13<00:12,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 72214279. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 68249923. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 79740635. Keeping original ranking.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessing queries:  60%|██████    | 6/10 [00:13<00:04,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 100251983. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 76109416. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 85685768. Keeping original ranking.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing queries: 100%|██████████| 10/10 [00:13<00:00,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 70563808. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 79482665. Keeping original ranking.\n",
            "Error getting Gemini embeddings for batch starting at index 0: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
            "Warning: Could not get embeddings for query 75800075. Keeping original ranking.\n",
            "\n",
            "Test set predictions saved to: predictions_gemini_exp.json\n",
            "\n",
            "Remember to download '{test_predictions_file}' and submit it to Codabench.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# GEMINI TRY\n",
        "\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google import genai\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "GEMINI_API_KEY = \"ton api\"\n",
        "\n",
        "# Initialize Gemini Client\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "embedding_model_name = \"gemini-embedding-exp-03-07\"\n",
        "\n",
        "# Define the paths to your data files\n",
        "train_queries_file = \"train_queries.json\"\n",
        "test_queries_file = \"test_queries.json\"\n",
        "train_gold_mapping_file = \"train_gold_mapping.json\"\n",
        "shuffled_pre_ranking_file = \"shuffled_pre_ranking.json\"\n",
        "queries_content_file = \"queries_content_with_features.json\"\n",
        "documents_content_file = \"documents_content_with_features.json\"\n",
        "\n",
        "# Define the output file for test predictions\n",
        "test_predictions_file = \"predictions_gemini_exp.json\"\n",
        "\n",
        "# Check if necessary data files exist\n",
        "if not all(os.path.exists(f) for f in [test_queries_file, shuffled_pre_ranking_file, queries_content_file, documents_content_file]):\n",
        "    print(\"Error: One or more necessary data files for the test set are missing.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"Necessary data files for the test set found.\")\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"Load JSON data from a file\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def save_json_file(data, file_path):\n",
        "    \"\"\"Save data to a JSON file\"\"\"\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "\n",
        "def load_content_data(file_path):\n",
        "    \"\"\"Load content data from a JSON file\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    # Create a dictionary mapping FAN to Content\n",
        "    content_dict = {item['FAN']: item['Content'] for item in data}\n",
        "    return content_dict\n",
        "\n",
        "def extract_text(content_dict, text_type=\"full\"):\n",
        "    \"\"\"Extract text from patent content based on text_type\"\"\"\n",
        "    if text_type == \"TA\" or text_type == \"title_abstract\":\n",
        "        title = content_dict.get(\"title\", \"\")\n",
        "        abstract = content_dict.get(\"pa01\", \"\")\n",
        "        return f\"{title} {abstract}\".strip()\n",
        "    elif text_type == \"claims\":\n",
        "        claims = \" \".join([v for k, v in content_dict.items() if k.startswith('c-')])\n",
        "        return claims.strip()\n",
        "    elif text_type == \"description\":\n",
        "        description = \" \".join([v for k, v in content_dict.items() if k.startswith('p')])\n",
        "        return description.strip()\n",
        "    elif text_type == \"full\":\n",
        "        all_text = []\n",
        "        if \"title\" in content_dict:\n",
        "            all_text.append(content_dict[\"title\"])\n",
        "        if \"pa01\" in content_dict:\n",
        "            all_text.append(content_dict[\"pa01\"])\n",
        "        for key, value in content_dict.items():\n",
        "            if key not in [\"title\", \"pa01\"]:\n",
        "                all_text.append(value)\n",
        "        return \" \".join(all_text).strip()\n",
        "    elif text_type == \"tac1\":\n",
        "        title = content_dict.get(\"title\", \"\")\n",
        "        abstract = content_dict.get(\"pa01\", \"\")\n",
        "        first_claim = next((v for k, v in content_dict.items() if k.startswith('c-')), \"\")\n",
        "        return f\"{title} {abstract} {first_claim}\".strip()\n",
        "    return \"\"\n",
        "\n",
        "def get_embedding_gemini(text_list, batch_size=1):  # Adjust batch_size\n",
        "    \"\"\"Get embeddings for a list of texts using the specified Gemini embedding model with batching.\"\"\"\n",
        "    embeddings = []\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        batch = text_list[i:i + batch_size]\n",
        "        try:\n",
        "            result = client.models.embed_content(\n",
        "                model=embedding_model_name,\n",
        "                contents=batch,  # Send a list of texts\n",
        "            )\n",
        "            if result.embeddings:\n",
        "                for embedding in result.embeddings:\n",
        "                    embeddings.append(embedding.values)\n",
        "            else:\n",
        "                print(f\"Warning: No embeddings returned for the batch starting at index {i}\")\n",
        "                return None\n",
        "            time.sleep(1)  # Add a small delay to avoid rate limits\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting Gemini embeddings for batch starting at index {i}: {e}\")\n",
        "            return None\n",
        "    return embeddings\n",
        "\n",
        "# Load test queries and pre-ranking\n",
        "test_queries = load_json_file(test_queries_file)\n",
        "print(f\"Loaded {len(test_queries)} test queries.\")\n",
        "pre_ranking_test = load_json_file(shuffled_pre_ranking_file)\n",
        "pre_ranking_test_filtered = {fan: docs for fan, docs in pre_ranking_test.items() if fan in test_queries}\n",
        "print(f\"Filtered pre-ranking to {len(pre_ranking_test_filtered)} test queries.\")\n",
        "\n",
        "# Load content data\n",
        "queries_content = load_content_data(queries_content_file)\n",
        "documents_content = load_content_data(documents_content_file)\n",
        "\n",
        "# Rerank using Gemini embeddings\n",
        "re_ranked_predictions = {}\n",
        "best_text_type = \"claims\"  # You can experiment with other text types\n",
        "\n",
        "print(\"\\nStarting reranking process for test queries using Gemini Embedding Model...\")\n",
        "for query_fan, pre_ranked_docs in tqdm(pre_ranking_test_filtered.items(), desc=\"Processing queries\"):\n",
        "    if query_fan not in queries_content:\n",
        "        print(f\"Warning: Query FAN {query_fan} not found in content.\")\n",
        "        re_ranked_predictions[query_fan] = pre_ranked_docs  # Keep original ranking\n",
        "        continue\n",
        "\n",
        "    query_text = extract_text(queries_content[query_fan], best_text_type)\n",
        "    doc_texts = []\n",
        "    doc_fans = []\n",
        "    for doc_fan in pre_ranked_docs:\n",
        "        if doc_fan in documents_content:\n",
        "            doc_texts.append(extract_text(documents_content[doc_fan], best_text_type))\n",
        "            doc_fans.append(doc_fan)\n",
        "        else:\n",
        "            print(f\"Warning: Document FAN {doc_fan} not found in content.\")\n",
        "\n",
        "    if not doc_texts:\n",
        "        re_ranked_predictions[query_fan] = []\n",
        "        continue\n",
        "\n",
        "    all_texts = [query_text] + doc_texts\n",
        "    embeddings = get_embedding_gemini(all_texts)\n",
        "\n",
        "    if embeddings and len(embeddings) == len(all_texts):\n",
        "        query_embedding = embeddings[0]\n",
        "        doc_embeddings = embeddings[1:]\n",
        "        similarity_scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "        ranked_indices = np.argsort(similarity_scores)[::-1]\n",
        "        re_ranked_predictions[query_fan] = [doc_fans[i] for i in ranked_indices]\n",
        "    else:\n",
        "        print(f\"Warning: Could not get embeddings for query {query_fan}. Keeping original ranking.\")\n",
        "        re_ranked_predictions[query_fan] = pre_ranked_docs\n",
        "\n",
        "# Save the re-ranked predictions\n",
        "save_json_file(re_ranked_predictions, test_predictions_file)\n",
        "print(f\"\\nTest set predictions saved to: {test_predictions_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJUIacEyPmfU",
        "outputId": "8ee87e1a-f0af-4833-be9b-4b3567c35ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Necessary data files found.\n",
            "Loaded and processed 0 query content items.\n",
            "Loaded and processed 0 document content items.\n",
            "\n",
            "Creative test set predictions saved to: creative_predictions.json\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from collections import Counter\n",
        "from fuzzywuzzy import fuzz  # pip install fuzzywuzzy\n",
        "from nltk.corpus import wordnet  # pip install nltk (and download wordnet data: import nltk; nltk.download('wordnet'))\n",
        "\n",
        "# PATHS\n",
        "train_queries_file = \"train_queries.json\"\n",
        "test_queries_file = \"test_queries.json\"\n",
        "train_gold_mapping_file = \"train_gold_mapping.json\"\n",
        "shuffled_pre_ranking_file = \"shuffled_pre_ranking.json\"\n",
        "queries_content_file = \"queries_content_with_features.json\"\n",
        "documents_content_file = \"documents_content_with_features.json\"\n",
        "test_predictions_file = \"creative_predictions.json\"\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "if not all(os.path.exists(f) for f in [test_queries_file, shuffled_pre_ranking_file, queries_content_file, documents_content_file, train_gold_mapping_file, queries_content_file, documents_content_file, train_queries_file]):\n",
        "    print(\"Error: One or more necessary data files are missing.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"Necessary data files found.\")\n",
        "\n",
        "test_queries = load_json_file(test_queries_file)\n",
        "pre_ranking_test = load_json_file(shuffled_pre_ranking_file)\n",
        "pre_ranking_test_filtered = {fan: docs for fan, docs in pre_ranking_test.items() if fan in test_queries}\n",
        "train_gold_mapping = load_json_file(train_gold_mapping_file)\n",
        "train_queries = load_json_file(train_queries_file)\n",
        "\n",
        "# --- Load and Transform queries_content ---\n",
        "queries_content_list = load_json_file(queries_content_file)\n",
        "queries_content = {}\n",
        "for item in queries_content_list:\n",
        "    patent_id = item.get(\"patent_id\")\n",
        "    if patent_id:\n",
        "        queries_content[patent_id] = item\n",
        "print(f\"Loaded and processed {len(queries_content)} query content items.\")\n",
        "\n",
        "# --- Load and Transform documents_content ---\n",
        "documents_content_list = load_json_file(documents_content_file)\n",
        "documents_content = {}\n",
        "for item in documents_content_list:\n",
        "    patent_id = item.get(\"patent_id\")\n",
        "    if patent_id:\n",
        "        documents_content[patent_id] = item\n",
        "print(f\"Loaded and processed {len(documents_content)} document content items.\")\n",
        "\n",
        "queries_content_train = {k: v for k, v in queries_content.items() if k in train_queries}\n",
        "documents_content_train = documents_content\n",
        "\n",
        "def prepare_feature_weights_tfidf(train_gold_mapping, queries_content, documents_content):\n",
        "    doc_feature_counts = {}\n",
        "    all_docs = {**queries_content, **documents_content}\n",
        "    total_num_docs = len(all_docs)\n",
        "\n",
        "    for doc_id, content in all_docs.items():\n",
        "        features = content.get('features', [])\n",
        "        doc_feature_counts[doc_id] = Counter(features)\n",
        "\n",
        "    feature_doc_frequency = Counter()\n",
        "    for doc_id, counts in doc_feature_counts.items():\n",
        "        for feature in counts:\n",
        "            feature_doc_frequency[feature] += 1\n",
        "\n",
        "    feature_weights_tfidf = {}\n",
        "    for doc_id, counts in doc_feature_counts.items():\n",
        "        for feature, count in counts.items():\n",
        "            tf = count / (sum(counts.values()) + 1e-6)\n",
        "            idf = math.log(total_num_docs / (feature_doc_frequency[feature] + 1) + 1e-6)\n",
        "            feature_weights_tfidf[feature] = feature_weights_tfidf.get(feature, 0) + tf * idf\n",
        "\n",
        "    return dict(feature_weights_tfidf)\n",
        "\n",
        "def calculate_feature_similarity_improved(query_features, doc_features, feature_weights_tfidf=None):\n",
        "    score = 0\n",
        "\n",
        "    # 1. TF-IDF Weighted Overlap\n",
        "    if feature_weights_tfidf:\n",
        "        common_features = set(query_features) & set(doc_features)\n",
        "        for feature in common_features:\n",
        "            score += feature_weights_tfidf.get(feature, 0)\n",
        "\n",
        "    # 2. Fuzzy Matching\n",
        "    fuzzy_score = 0\n",
        "    for q_feature in query_features:\n",
        "        for d_feature in doc_features:\n",
        "            ratio = fuzz.ratio(q_feature, d_feature)\n",
        "            if ratio > 85:  # Increased threshold\n",
        "                fuzzy_score += ratio / 100.0 * 0.2  # Reduced weight\n",
        "\n",
        "    score += fuzzy_score\n",
        "\n",
        "    # 3. N-gram Overlap (bi-grams)\n",
        "    def get_ngrams(text, n):\n",
        "        n_grams = set()\n",
        "        words = text.split()\n",
        "        for i in range(len(words) - n + 1):\n",
        "            n_grams.add(\" \".join(words[i:i+n]))\n",
        "        return n_grams\n",
        "\n",
        "    ngram_overlap_score = 0\n",
        "    for q_feature in query_features:\n",
        "        for d_feature in doc_features:\n",
        "            q_2grams = get_ngrams(q_feature, 2)\n",
        "            d_2grams = get_ngrams(d_feature, 2)\n",
        "            overlap = len(q_2grams & d_2grams)\n",
        "            union = len(q_2grams | d_2grams)\n",
        "            if union > 0:\n",
        "                ngram_overlap_score += overlap / union * 0.1  # Jaccard-like\n",
        "\n",
        "    score += ngram_overlap_score\n",
        "\n",
        "    return score\n",
        "\n",
        "def creative_reranking(pre_ranking, queries_content, documents_content, feature_weights_tfidf=None):\n",
        "    ranked_results = {}\n",
        "    for query_id, initial_ranking in pre_ranking.items():\n",
        "        if query_id in queries_content:\n",
        "            query_features = queries_content[query_id].get('features', [])\n",
        "            scored_documents = []\n",
        "            for doc_id in initial_ranking:\n",
        "                if doc_id in documents_content:\n",
        "                    doc_features = documents_content[doc_id].get('features', [])\n",
        "                    similarity_score = calculate_feature_similarity_improved(\n",
        "                        query_features,\n",
        "                        doc_features,\n",
        "                        feature_weights_tfidf=feature_weights_tfidf\n",
        "                    )\n",
        "                    scored_documents.append((doc_id, similarity_score))\n",
        "            scored_documents.sort(key=lambda item: item[1], reverse=True)\n",
        "            ranked_results[query_id] = [doc_id for doc_id, score in scored_documents]\n",
        "        else:\n",
        "            ranked_results[query_id] = initial_ranking\n",
        "    return ranked_results\n",
        "\n",
        "# --- Prepare Feature Weights using TF-IDF ---\n",
        "feature_weights_tfidf = prepare_feature_weights_tfidf(train_gold_mapping, queries_content_train, documents_content_train)\n",
        "\n",
        "# --- Perform Creative Reranking on Test Set ---\n",
        "reranked_predictions = creative_reranking(\n",
        "    pre_ranking_test_filtered,\n",
        "    queries_content,\n",
        "    documents_content,\n",
        "    feature_weights_tfidf=feature_weights_tfidf\n",
        ")\n",
        "\n",
        "# --- Save Predictions ---\n",
        "with open(test_predictions_file, 'w') as f:\n",
        "    json.dump(reranked_predictions, f, indent=4)\n",
        "\n",
        "print(f\"\\nCreative test set predictions saved to: {test_predictions_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbMyKJVN8MeQ"
      },
      "source": [
        "# 2. Spars ranking with tf-idf vectorizer (from task 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Z5NEBe9sT4"
      },
      "source": [
        "## 2.1. Utilis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "WIPATc-s-P74"
      },
      "outputs": [],
      "source": [
        "def load_json_data(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        contents = json.load(file)\n",
        "    return contents\n",
        "\n",
        "\n",
        "def create_tfidf_matrix(citing_dataset, nonciting_dataset, vectorizer=TfidfVectorizer()):\n",
        "    \"\"\"\n",
        "    Creates TF-IDF matrix for the given citing and non-citing datasets based on the specified text column.\n",
        "\n",
        "    Parameters:\n",
        "    citing_dataset (json)): DataFrame containing citing patents.\n",
        "    nonciting_dataset (json): DataFrame containing non-citing patents.\n",
        "    vectorizer (TfidfVectorizer, optional): TfidfVectorizer object for vectorizing text data.\n",
        "                                             Defaults to TfidfVectorizer().\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing TF-IDF matrices for citing and non-citing patents respectively.\n",
        "           (tfidf_matrix_citing, tfidf_matrix_nonciting)\n",
        "    \"\"\"\n",
        "    all_text = [patent['text'] for patent in citing_dataset + nonciting_dataset]\n",
        "\n",
        "    # Vectorizing descriptions\n",
        "    print(\"Vectorizing descriptions...\")\n",
        "    tfidf_matrix = vectorizer.fit_transform(tqdm(all_text, desc=\"TF-IDF\"))\n",
        "\n",
        "    # Since we're interested in similarities between citing and cited patents,\n",
        "    # we need to split the TF-IDF matrix back into two parts\n",
        "    split_index = len(citing_dataset)\n",
        "    tfidf_matrix_citing = tfidf_matrix[:split_index]\n",
        "    tfidf_matrix_nonciting = tfidf_matrix[split_index:]\n",
        "\n",
        "    # Size of vocabulary\n",
        "    print(\"Size of vocabulary:\", len(vectorizer.vocabulary_))\n",
        "\n",
        "    return tfidf_matrix_citing, tfidf_matrix_nonciting\n",
        "\n",
        "\n",
        "# a new function to create the copus\n",
        "import re\n",
        "\n",
        "def create_corpus(corpus, text_type):\n",
        "    \"\"\"\n",
        "    Extracts text data from a corpus based on the specified text type.\n",
        "\n",
        "    Parameters:\n",
        "    corpus (list): List of dictionaries representing documents.\n",
        "    text_type (str): Type of text to extract ('title', 'abstract', 'claim1', 'claims', 'description', 'fulltext',\n",
        "                     'features', 'TAC1', 'TA', 'TAC1F', 'description_F').\n",
        "\n",
        "    Returns:\n",
        "    list: List of dictionaries with 'id' and 'text' keys representing each document in the corpus.\n",
        "    \"\"\"\n",
        "    import re  # Ensure re is imported\n",
        "\n",
        "    valid_app_ids = []\n",
        "    texts = []\n",
        "    cnt = 0  # Count of documents without required text\n",
        "    ids_to_remove = []\n",
        "\n",
        "    for docBloc in corpus:\n",
        "        doc_id = docBloc.get('FAN')\n",
        "        if doc_id is None:\n",
        "            continue\n",
        "\n",
        "        doc = docBloc['Content']\n",
        "        valid = False\n",
        "        text = ''\n",
        "\n",
        "        if text_type == 'title':\n",
        "            if 'title' in doc:\n",
        "                text = doc['title']\n",
        "                valid = True\n",
        "        elif text_type == 'abstract':\n",
        "            if 'pa01' in doc:\n",
        "                text = doc['pa01']\n",
        "                valid = True\n",
        "        elif text_type == 'claim1':\n",
        "            if 'c-en-0001' in doc:\n",
        "                text = doc['c-en-0001']\n",
        "                valid = True\n",
        "        elif text_type == 'claims':\n",
        "            claims = [doc[k] for k in doc if k.startswith('c-en-')]\n",
        "            if claims:\n",
        "                text = ' '.join(claims)\n",
        "                valid = True\n",
        "        elif text_type == 'description':\n",
        "            desc_parts = [doc[k] for k in doc if re.match(r'^p\\d{4}$', k)]\n",
        "            if desc_parts:\n",
        "                text = ' '.join(desc_parts)\n",
        "                valid = True\n",
        "        elif text_type == 'fulltext':\n",
        "            text_parts = [str(doc[k]) for k in doc if k != 'id']\n",
        "            if text_parts:\n",
        "                text = ' '.join(text_parts)\n",
        "                valid = True\n",
        "        elif text_type == 'features':\n",
        "            try:\n",
        "                features_dict = doc['features']\n",
        "                features = list(features_dict.values())\n",
        "                if features:\n",
        "                    text = ' '.join(features)\n",
        "                    valid = True\n",
        "                else:\n",
        "                    raise KeyError  # Treat empty features as missing\n",
        "            except KeyError:\n",
        "                print(\"an error !\")\n",
        "        elif text_type == 'TAC1':\n",
        "            required = ['title', 'pa01', 'c-en-0001']\n",
        "            if all(k in doc for k in required):\n",
        "                text = ' '.join([doc['title'], doc['pa01'], doc['c-en-0001']])\n",
        "                valid = True\n",
        "        elif text_type == 'TA':\n",
        "            required = ['title', 'pa01']\n",
        "            if all(k in doc for k in required):\n",
        "                text = ' '.join([doc['title'], doc['pa01']])\n",
        "                valid = True\n",
        "        elif text_type == 'TAC1F':\n",
        "            required = ['title', 'pa01', 'c-en-0001', 'features']\n",
        "            if all(k in doc for k in required):\n",
        "                text_parts = [doc['title'], doc['pa01'], doc['c-en-0001']]\n",
        "                try:\n",
        "                    features_dict = doc['features']\n",
        "                    features = list(features_dict.values())\n",
        "                    if features:\n",
        "                        text_parts.append(' '.join(features))\n",
        "                        text = ' '.join(text_parts)\n",
        "                        valid = True\n",
        "                    else:\n",
        "                        raise KeyError\n",
        "                except KeyError:\n",
        "                    print(\"an error !\")\n",
        "        elif text_type == 'description_F':\n",
        "            desc_parts = [doc[k] for k in doc if re.match(r'^p\\d{4}$', k)]\n",
        "            try:\n",
        "                features_dict = doc['features']\n",
        "                features = list(features_dict.values())\n",
        "                if features:\n",
        "                    text = ' '.join(desc_parts) + ' ' + ' '.join(features)\n",
        "                    valid = True\n",
        "                else:\n",
        "                    raise KeyError\n",
        "            except KeyError:\n",
        "                print(\"an error !\")\n",
        "        else:\n",
        "            raise ValueError(\"Invalid text type\")\n",
        "\n",
        "        if valid:\n",
        "            valid_app_ids.append(doc_id)\n",
        "            texts.append(text)\n",
        "        else:\n",
        "            cnt += 1\n",
        "            ids_to_remove.append(doc_id)\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"Number of documents without {text_type}: {cnt}\")\n",
        "    if ids_to_remove:\n",
        "        print(f\"Removing {len(ids_to_remove)} documents without required text\")\n",
        "\n",
        "    # Create the corpus data\n",
        "    corpus_data = [{'id': app_id, 'text': text} for app_id, text in zip(valid_app_ids, texts)]\n",
        "\n",
        "    return corpus_data\n",
        "\n",
        "\n",
        "\n",
        "def top_k_ranks(citing, cited, cosine_similarities, k=10):\n",
        "    # Create a dictionary to store the top k ranks for each citing patent\n",
        "    top_k_ranks = {}\n",
        "    for i, content_id in enumerate(citing):\n",
        "        top_k_ranks[content_id['FAN']] = [cited[j]['FAN'] for j in np.argsort(cosine_similarities[i])[::-1][:k]]\n",
        "    return top_k_ranks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z52WrzU9nFS"
      },
      "source": [
        "## 2.2 Upload the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train_queries.json\") as f:\n",
        "    train_queries = json.load(f)\n",
        "\n",
        "with open(\"train_gold_mapping.json\") as f:\n",
        "    train_gold_mapping = json.load(f)\n",
        "\n",
        "with open(\"shuffled_pre_ranking.json\") as f:\n",
        "    pre_ranking = json.load(f)\n",
        "\n",
        "with open(\"queries_content_with_features.json\") as f:\n",
        "    queries_content = json.load(f)\n",
        "\n",
        "with open(\"documents_content_with_features.json\") as f:\n",
        "    docs_content = json.load(f)\n"
      ],
      "metadata": {
        "id": "219pfpWn4Ked"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK99BDFUI9W0"
      },
      "source": [
        "**important recall**\n",
        "\n",
        "The data we need for this task are:\n",
        "\n",
        "| Dataset                | Role                          | Example Use Case                                                                 |\n",
        "|------------------------|-------------------------------|----------------------------------------------------------------------------------|\n",
        "| `json_citing_train`    | Training queries              | Fit TF-IDF/BM25 models and generate rankings for evaluation.                     |\n",
        "| `json_citing_test`     | Test queries                  | Final evaluation (unseen during training).                                       |\n",
        "| `json_nonciting`       | Retrieval corpus              | Search space for finding relevant patents.                                       |\n",
        "| `json_citing_to_cited` | Ground-truth mappings (train) | Validate if top-100 retrieved patents include the true cited patents from `json_nonciting`. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBKkjR4t9v15"
      },
      "source": [
        "## 2.3. Creation of the tf-idf vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1. Description + features"
      ],
      "metadata": {
        "id": "f3yUgI5ZcX77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# the function\n",
        "\n",
        "doc_corpus_description_F = create_corpus(docs_content, text_type='description_F')\n",
        "query_corpus_description_F = create_corpus(queries_content, text_type='description_F')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8rPM7hC0442",
        "outputId": "3af70d1f-d5ec-4ed6-fff7-7168d16a9b4b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents without description_F: 0\n",
            "Number of documents without description_F: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "1VWRmb2NfHm8"
      },
      "outputs": [],
      "source": [
        "# description + features  Text TF_IDF (training data)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf_vectorizer1 = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_features=60000,\n",
        "    ngram_range=(1, 1),\n",
        "    strip_accents='unicode',\n",
        "    sublinear_tf= True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply tfidf\n",
        "tfidf_matrix_docs, tfidf_matrix_queries = create_tfidf_matrix(doc_corpus_description_F, query_corpus_description_F, tfidf_vectorizer1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "61cb35bdd0054306a0fab00696baddc3",
            "e765b654c6024b35b240729963243dd0",
            "1992f80ee3d64915a189161dc90bc069",
            "358eed99e12244a796f923279ce6f87e",
            "184721bb719a44899d5a1c82ac56bacb",
            "86b6e3b450a3414f861760576577cecc",
            "9809ffedcf0c429c8e2d958435d1a2db",
            "a6df8c47dd6c48c5b11d762640c7a846",
            "5e6eb149d076442cb7f41a481f1751eb",
            "4ab091fe0f284fe6b20ba6bb369f4f83",
            "7f9d6d6b23d5411984b2aebd02931b48"
          ]
        },
        "id": "UNiH4iVS2jlO",
        "outputId": "3c63b130-d4b9-4a3a-cbb2-6703668411dd"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing descriptions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TF-IDF:   0%|          | 0/930 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61cb35bdd0054306a0fab00696baddc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 44097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the shaps\n",
        "print(tfidf_matrix_docs.shape)\n",
        "print(tfidf_matrix_queries.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWowTWDF-aoB",
        "outputId": "7c0feea0-4b6f-4893-910f-547a1560a5de"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 44097)\n",
            "(30, 44097)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the cosin sim\n",
        "cosine_similarities = cosine_similarity(tfidf_matrix_queries, tfidf_matrix_docs)\n",
        "cosine_similarities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCJKVMPy-enS",
        "outputId": "4da96679-649f-454a-9ffe-95a0923402fa"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15815984, 0.11145126, 0.15740679, ..., 0.19005678, 0.1404056 ,\n",
              "        0.1199359 ],\n",
              "       [0.14495315, 0.12965319, 0.16803329, ..., 0.14603708, 0.11912082,\n",
              "        0.11616464],\n",
              "       [0.15546634, 0.1466232 , 0.20957066, ..., 0.15128853, 0.15313469,\n",
              "        0.15032352],\n",
              "       ...,\n",
              "       [0.18621809, 0.18497118, 0.18615221, ..., 0.12256428, 0.13582251,\n",
              "        0.11543172],\n",
              "       [0.0850097 , 0.08299926, 0.09220746, ..., 0.101946  , 0.08674313,\n",
              "        0.06535791],\n",
              "       [0.19998599, 0.17811146, 0.28175976, ..., 0.2326327 , 0.29343263,\n",
              "        0.26685374]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_rank = top_k_ranks(queries_content, docs_content, cosine_similarities, k=10)"
      ],
      "metadata": {
        "id": "tDgIggj6-n29"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('prediction2_tfidf_descF.json', 'w') as f:\n",
        "    json.dump(top_k_rank, f)"
      ],
      "metadata": {
        "id": "JTzjW4mx-sWO"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2. Descrition"
      ],
      "metadata": {
        "id": "jq2JKif3cdH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# the function\n",
        "\n",
        "doc_corpus_description_F = create_corpus(docs_content, text_type='description')\n",
        "query_corpus_description_F = create_corpus(queries_content, text_type='description')\n",
        "\n",
        "# description + features  Text TF_IDF (training data)\n",
        "tfidf_matrix_docs, tfidf_matrix_queries = create_tfidf_matrix(doc_corpus_description_F, query_corpus_description_F, tfidf_vectorizer1)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf_vectorizer1 = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_features=60000,\n",
        "    ngram_range=(1, 1),\n",
        "    strip_accents='unicode',\n",
        "    sublinear_tf= True\n",
        "    )\n",
        "\n",
        "# computing the cosin sim\n",
        "cosine_similarities = cosine_similarity(tfidf_matrix_queries, tfidf_matrix_docs)\n",
        "cosine_similarities\n",
        "\n",
        "top_k_rank = top_k_ranks(queries_content, docs_content, cosine_similarities, k=10)\n",
        "\n",
        "with open('prediction2_tfidf_desc.json', 'w') as f:\n",
        "    json.dump(top_k_rank, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "1c3ad1a6ba6f4a1d92aaf7ddb2bd2b6d",
            "b09910c26588452d8ad5ec2a971d8bf8",
            "ad2dcf1a1c84400a9a4497e90fab9d5c",
            "49e0073037cb4be0b36ae3b4d9bf53b8",
            "0b48ac8d7ce4483e9e5a92724fcecb1c",
            "11a1e85d71954aa9a1a792fabf4c3b07",
            "bacd72039d9e4922acbed6a4691bbbd5",
            "078ffe57d5d54b01a2f91c8e368b9a09",
            "e78abf4620cd4a608a7998d55be65c90",
            "8b5cf3fea3704229b08ebc0c4eec14a8",
            "b95080f801a3446d88d3392d57dc5f8b"
          ]
        },
        "id": "yrBiNyeycf7w",
        "outputId": "fcbec330-1802-4507-a5ad-3cdb46257025"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents without description: 0\n",
            "Number of documents without description: 0\n",
            "Vectorizing descriptions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TF-IDF:   0%|          | 0/930 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c3ad1a6ba6f4a1d92aaf7ddb2bd2b6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 43913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Algorithim RRF"
      ],
      "metadata": {
        "id": "e2lvbVWs_nsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def reciprocal_rank_fusion(rankings_list, k=60):\n",
        "    \"\"\"\n",
        "    Combines multiple ranked lists using Reciprocal Rank Fusion\n",
        "\n",
        "    Args:\n",
        "        rankings_list (list of dict): List of dictionaries where each dict has\n",
        "            {query_id: [ordered list of document IDs]}\n",
        "        k (int): Smoothing parameter (typically 60 by default // a value used by the community)\n",
        "\n",
        "    Returns:\n",
        "        dict: {query_id: [ordered list of merged document IDs]}\n",
        "    \"\"\"\n",
        "    fused_rankings = {}\n",
        "\n",
        "    # Get all unique query IDs\n",
        "    query_ids = set.intersection(*[set(r.keys()) for r in rankings_list])\n",
        "\n",
        "    for qid in query_ids:\n",
        "        doc_scores = defaultdict(float)\n",
        "\n",
        "        # Calculate RRF scores for each ranking\n",
        "        for ranking in rankings_list:\n",
        "            ranked_docs = ranking[qid]\n",
        "            for rank_pos, doc_id in enumerate(ranked_docs):\n",
        "                doc_scores[doc_id] += 1 / (k + rank_pos + 1)  # +1 because ranks are 0-indexed\n",
        "\n",
        "        # Sort documents by descending RRF score\n",
        "        sorted_docs = sorted(doc_scores.items(), key=lambda x: -x[1])\n",
        "\n",
        "        # Extract ordered document IDs\n",
        "        fused_rankings[qid] = [doc_id for doc_id, score in sorted_docs]\n",
        "\n",
        "    return fused_rankings\n",
        "\n",
        "def load_ranking(file_path):\n",
        "    \"\"\"\n",
        "    Load a ranking from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n"
      ],
      "metadata": {
        "id": "C6ow_WRS_MuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. tfidf_descF + MPNET_description"
      ],
      "metadata": {
        "id": "4B_AomlQc79E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sparse_rankings = load_ranking(\"prediction2_tfidf_descF.json\")\n",
        "dense_rankings = load_ranking(\"prediction2_MPNET_description.json\")\n",
        "\n",
        "combined_ranking = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Iterate over the query IDs and their corresponding rankings\n",
        "for query_id, ranked_docs in combined_ranking.items():\n",
        "  print(f\"Query ID: {query_id}\")\n",
        "  for i, doc_id in enumerate(ranked_docs):\n",
        "      print(f\"Rank {i+1}: {doc_id}\") # Print rank and document ID\n",
        "\n",
        "\n",
        "# Save fused results if needed\n",
        "output_file = \"rrf_prediction2.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(combined_ranking, f)\n",
        "print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "id": "MwKH_ms-c9rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading truth and prediction\n",
        "Checking Accuracy\n",
        "Scores:\n",
        "{'recall_at_3': 0.30873015873015874, 'recall_at_5': 0.34523809523809523, 'recall_at_10': 0.37063492063492065, 'recall_at_20': 0.6797619047619048, 'mean_rank': 14.105952380952383, 'mean_inv_rank': 0.19188916357316593, 'mean_average_precision': 0.27379514070307864}\n",
        "Scoring completed"
      ],
      "metadata": {
        "id": "VYegEzpgdG4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. tfidf_descF + MPNET_DescFeat"
      ],
      "metadata": {
        "id": "_AQJ-ITEdIXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sparse_rankings = load_ranking(\"prediction2_tfidf_descF.json\")\n",
        "dense_rankings = load_ranking(\"prediction2_MPNET_DescFeat.json\")\n",
        "\n",
        "combined_ranking = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Iterate over the query IDs and their corresponding rankings\n",
        "for query_id, ranked_docs in combined_ranking.items():\n",
        "  print(f\"Query ID: {query_id}\")\n",
        "  for i, doc_id in enumerate(ranked_docs):\n",
        "      print(f\"Rank {i+1}: {doc_id}\") # Print rank and document ID\n",
        "\n",
        "\n",
        "# Save fused results if needed\n",
        "output_file = \"rrf_prediction2_tfidfDescF_MPNETDescFeat.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(combined_ranking, f)\n",
        "print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKYPkkC_dHOo",
        "outputId": "940e0ffb-c3f4-4bc8-e535-39a3976b3a75"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query ID: 103964109\n",
            "Rank 1: 87488738\n",
            "Rank 2: 87285519\n",
            "Rank 3: 104761777\n",
            "Rank 4: 110338873\n",
            "Rank 5: 94546339\n",
            "Rank 6: 101598636\n",
            "Rank 7: 105078785\n",
            "Rank 8: 102035322\n",
            "Rank 9: 84923580\n",
            "Rank 10: 44437432\n",
            "Rank 11: 96138054\n",
            "Rank 12: 92631163\n",
            "Rank 13: 91358966\n",
            "Rank 14: 74364787\n",
            "Rank 15: 89655285\n",
            "Rank 16: 70494531\n",
            "Rank 17: 86686331\n",
            "Rank 18: 93007218\n",
            "Rank 19: 65451984\n",
            "Rank 20: 85915967\n",
            "Rank 21: 81098918\n",
            "Rank 22: 93196199\n",
            "Rank 23: 94596291\n",
            "Rank 24: 1662314\n",
            "Rank 25: 82807300\n",
            "Rank 26: 74999904\n",
            "Rank 27: 73189654\n",
            "Rank 28: 101974338\n",
            "Rank 29: 112489610\n",
            "Rank 30: 91801222\n",
            "Query ID: 75800075\n",
            "Rank 1: 34284570\n",
            "Rank 2: 84214328\n",
            "Rank 3: 76825949\n",
            "Rank 4: 75692075\n",
            "Rank 5: 7588356\n",
            "Rank 6: 81692381\n",
            "Rank 7: 74966633\n",
            "Rank 8: 70999237\n",
            "Rank 9: 62288211\n",
            "Rank 10: 43687538\n",
            "Rank 11: 34173412\n",
            "Rank 12: 64972313\n",
            "Rank 13: 73305870\n",
            "Rank 14: 35300504\n",
            "Rank 15: 81704710\n",
            "Rank 16: 87092702\n",
            "Rank 17: 93085483\n",
            "Rank 18: 86183849\n",
            "Rank 19: 22823110\n",
            "Rank 20: 71238892\n",
            "Rank 21: 77197418\n",
            "Rank 22: 62194904\n",
            "Rank 23: 73750287\n",
            "Rank 24: 77144269\n",
            "Rank 25: 61870386\n",
            "Rank 26: 33464411\n",
            "Rank 27: 35197610\n",
            "Rank 28: 43796291\n",
            "Rank 29: 43878177\n",
            "Rank 30: 35215942\n",
            "Rank 31: 7228433\n",
            "Rank 32: 76120190\n",
            "Query ID: 76109416\n",
            "Rank 1: 76109416\n",
            "Rank 2: 43845712\n",
            "Rank 3: 86772879\n",
            "Rank 4: 44149931\n",
            "Rank 5: 86120389\n",
            "Rank 6: 74871145\n",
            "Rank 7: 75226918\n",
            "Rank 8: 92580522\n",
            "Rank 9: 67929958\n",
            "Rank 10: 72024697\n",
            "Rank 11: 1212129\n",
            "Rank 12: 90897974\n",
            "Rank 13: 71010602\n",
            "Rank 14: 43237025\n",
            "Rank 15: 79148717\n",
            "Rank 16: 44268155\n",
            "Rank 17: 98417973\n",
            "Rank 18: 96952506\n",
            "Rank 19: 66358\n",
            "Rank 20: 45066980\n",
            "Rank 21: 86586319\n",
            "Rank 22: 83775044\n",
            "Rank 23: 87097786\n",
            "Rank 24: 85956111\n",
            "Rank 25: 84518942\n",
            "Rank 26: 68498126\n",
            "Rank 27: 6825461\n",
            "Rank 28: 1859328\n",
            "Rank 29: 83915124\n",
            "Rank 30: 89081482\n",
            "Query ID: 70563808\n",
            "Rank 1: 70563808\n",
            "Rank 2: 43891147\n",
            "Rank 3: 77540953\n",
            "Rank 4: 66791385\n",
            "Rank 5: 87318046\n",
            "Rank 6: 73843030\n",
            "Rank 7: 6383581\n",
            "Rank 8: 72133315\n",
            "Rank 9: 105795426\n",
            "Rank 10: 69551594\n",
            "Rank 11: 62199485\n",
            "Rank 12: 86860100\n",
            "Rank 13: 45525493\n",
            "Rank 14: 66478420\n",
            "Rank 15: 59356913\n",
            "Rank 16: 43824316\n",
            "Rank 17: 7445616\n",
            "Rank 18: 76578541\n",
            "Rank 19: 7949497\n",
            "Rank 20: 61287856\n",
            "Rank 21: 45039835\n",
            "Rank 22: 46288752\n",
            "Rank 23: 78164659\n",
            "Rank 24: 7706134\n",
            "Rank 25: 75429864\n",
            "Rank 26: 14687460\n",
            "Rank 27: 6936022\n",
            "Rank 28: 44519425\n",
            "Rank 29: 13902208\n",
            "Rank 30: 1651911\n",
            "Rank 31: 7807387\n",
            "Rank 32: 8125158\n",
            "Rank 33: 45760699\n",
            "Rank 34: 7728171\n",
            "Rank 35: 7305297\n",
            "Query ID: 72214279\n",
            "Rank 1: 73313951\n",
            "Rank 2: 78285896\n",
            "Rank 3: 77750612\n",
            "Rank 4: 78874284\n",
            "Rank 5: 66704376\n",
            "Rank 6: 74719750\n",
            "Rank 7: 86201489\n",
            "Rank 8: 66704221\n",
            "Rank 9: 66859488\n",
            "Rank 10: 70443794\n",
            "Rank 11: 7323805\n",
            "Rank 12: 76635780\n",
            "Rank 13: 6786492\n",
            "Rank 14: 1024924\n",
            "Rank 15: 5188978\n",
            "Rank 16: 97541974\n",
            "Rank 17: 7024647\n",
            "Rank 18: 61941302\n",
            "Rank 19: 7409445\n",
            "Rank 20: 95087186\n",
            "Rank 21: 80491195\n",
            "Rank 22: 43855508\n",
            "Rank 23: 62204608\n",
            "Rank 24: 73575071\n",
            "Rank 25: 4112132\n",
            "Rank 26: 7186024\n",
            "Rank 27: 1052098\n",
            "Rank 28: 7126783\n",
            "Rank 29: 7185266\n",
            "Rank 30: 95793433\n",
            "Query ID: 85685768\n",
            "Rank 1: 101485622\n",
            "Rank 2: 101540987\n",
            "Rank 3: 7874471\n",
            "Rank 4: 103242931\n",
            "Rank 5: 93463606\n",
            "Rank 6: 92933013\n",
            "Rank 7: 92906077\n",
            "Rank 8: 90415246\n",
            "Rank 9: 91034639\n",
            "Rank 10: 91230085\n",
            "Rank 11: 94616956\n",
            "Rank 12: 22854327\n",
            "Rank 13: 96992323\n",
            "Rank 14: 86711677\n",
            "Rank 15: 6716158\n",
            "Rank 16: 43124738\n",
            "Rank 17: 87659292\n",
            "Rank 18: 92322829\n",
            "Rank 19: 5399125\n",
            "Rank 20: 91467629\n",
            "Rank 21: 22926275\n",
            "Rank 22: 71483822\n",
            "Rank 23: 79386554\n",
            "Rank 24: 68036945\n",
            "Rank 25: 44105210\n",
            "Rank 26: 98140923\n",
            "Rank 27: 100252809\n",
            "Rank 28: 43287174\n",
            "Rank 29: 80775193\n",
            "Rank 30: 91796062\n",
            "Query ID: 79740635\n",
            "Rank 1: 80463331\n",
            "Rank 2: 64815601\n",
            "Rank 3: 75024859\n",
            "Rank 4: 80126462\n",
            "Rank 5: 62141731\n",
            "Rank 6: 89202129\n",
            "Rank 7: 81276441\n",
            "Rank 8: 89202146\n",
            "Rank 9: 32931094\n",
            "Rank 10: 77324818\n",
            "Rank 11: 33448504\n",
            "Rank 12: 98938772\n",
            "Rank 13: 33473034\n",
            "Rank 14: 77144959\n",
            "Rank 15: 79096739\n",
            "Rank 16: 71772339\n",
            "Rank 17: 97072553\n",
            "Rank 18: 94502562\n",
            "Rank 19: 20176022\n",
            "Rank 20: 69278139\n",
            "Rank 21: 7582109\n",
            "Rank 22: 72282319\n",
            "Rank 23: 22271872\n",
            "Rank 24: 43110403\n",
            "Rank 25: 77783945\n",
            "Rank 26: 83374518\n",
            "Rank 27: 6507475\n",
            "Rank 28: 64764746\n",
            "Rank 29: 32251980\n",
            "Rank 30: 69050704\n",
            "Rank 31: 80781908\n",
            "Rank 32: 7937000\n",
            "Rank 33: 13938283\n",
            "Rank 34: 7332283\n",
            "Rank 35: 82301362\n",
            "Query ID: 100251983\n",
            "Rank 1: 100251983\n",
            "Rank 2: 91560811\n",
            "Rank 3: 90490909\n",
            "Rank 4: 93331965\n",
            "Rank 5: 82206845\n",
            "Rank 6: 88392348\n",
            "Rank 7: 93007808\n",
            "Rank 8: 96091957\n",
            "Rank 9: 89295990\n",
            "Rank 10: 82028496\n",
            "Rank 11: 107325691\n",
            "Rank 12: 106996649\n",
            "Rank 13: 96059580\n",
            "Rank 14: 97292661\n",
            "Rank 15: 89672703\n",
            "Rank 16: 78872192\n",
            "Rank 17: 72140435\n",
            "Rank 18: 100515176\n",
            "Rank 19: 33473034\n",
            "Rank 20: 90670288\n",
            "Rank 21: 45282121\n",
            "Rank 22: 94669658\n",
            "Rank 23: 104436949\n",
            "Rank 24: 94029448\n",
            "Rank 25: 86073872\n",
            "Rank 26: 78547811\n",
            "Rank 27: 98600374\n",
            "Rank 28: 46598360\n",
            "Rank 29: 80167129\n",
            "Rank 30: 88463494\n",
            "Query ID: 68249923\n",
            "Rank 1: 86874453\n",
            "Rank 2: 35300504\n",
            "Rank 3: 86319625\n",
            "Rank 4: 43783883\n",
            "Rank 5: 22791064\n",
            "Rank 6: 45407719\n",
            "Rank 7: 94133702\n",
            "Rank 8: 4102206\n",
            "Rank 9: 65179742\n",
            "Rank 10: 95326577\n",
            "Rank 11: 61870386\n",
            "Rank 12: 73750287\n",
            "Rank 13: 92458890\n",
            "Rank 14: 35215942\n",
            "Rank 15: 89313603\n",
            "Rank 16: 83106147\n",
            "Rank 17: 66204675\n",
            "Rank 18: 1880329\n",
            "Rank 19: 7503954\n",
            "Rank 20: 75001201\n",
            "Rank 21: 44330428\n",
            "Rank 22: 80790764\n",
            "Rank 23: 4811621\n",
            "Rank 24: 7191590\n",
            "Rank 25: 84067048\n",
            "Rank 26: 68984248\n",
            "Rank 27: 13900435\n",
            "Rank 28: 35246469\n",
            "Rank 29: 96103327\n",
            "Rank 30: 22538180\n",
            "Rank 31: 17811615\n",
            "Rank 32: 80619246\n",
            "Rank 33: 66785381\n",
            "Rank 34: 84151582\n",
            "Rank 35: 89264734\n",
            "Query ID: 79482665\n",
            "Rank 1: 71022105\n",
            "Rank 2: 84540103\n",
            "Rank 3: 83083320\n",
            "Rank 4: 93318781\n",
            "Rank 5: 93279107\n",
            "Rank 6: 73293133\n",
            "Rank 7: 88449039\n",
            "Rank 8: 44666167\n",
            "Rank 9: 95908606\n",
            "Rank 10: 92503480\n",
            "Rank 11: 93592423\n",
            "Rank 12: 73497949\n",
            "Rank 13: 87571623\n",
            "Rank 14: 6903999\n",
            "Rank 15: 81582469\n",
            "Rank 16: 4095476\n",
            "Rank 17: 68914227\n",
            "Rank 18: 103621196\n",
            "Rank 19: 46019842\n",
            "Rank 20: 67370804\n",
            "Rank 21: 86402797\n",
            "Rank 22: 88456909\n",
            "Rank 23: 102635100\n",
            "Rank 24: 93524596\n",
            "Rank 25: 110233006\n",
            "Rank 26: 87300637\n",
            "Rank 27: 87107633\n",
            "Rank 28: 72279718\n",
            "Rank 29: 89030165\n",
            "Rank 30: 70930284\n",
            "\n",
            "Saved fused results to rrf_prediction2_tfidfDescF_MPNETDescFeat.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. tfidf_desc + MPNET_description MPNET_DescFeat"
      ],
      "metadata": {
        "id": "atxAl2Y9d7ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sparse_rankings = load_ranking(\"prediction2_tfidf_desc.json\")\n",
        "dense_rankings = load_ranking(\"prediction2_MPNET_description.json\")\n",
        "\n",
        "combined_ranking = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Iterate over the query IDs and their corresponding rankings\n",
        "for query_id, ranked_docs in combined_ranking.items():\n",
        "  print(f\"Query ID: {query_id}\")\n",
        "  for i, doc_id in enumerate(ranked_docs):\n",
        "      print(f\"Rank {i+1}: {doc_id}\") # Print rank and document ID\n",
        "\n",
        "\n",
        "# Save fused results if needed\n",
        "output_file = \"rrf_prediction2_tfidfDesc_MPNETDesc.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(combined_ranking, f)\n",
        "print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21JJIMIEd2aO",
        "outputId": "8b25789b-7122-43e2-cfed-a8851841287b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query ID: 103964109\n",
            "Rank 1: 87488738\n",
            "Rank 2: 87285519\n",
            "Rank 3: 104761777\n",
            "Rank 4: 110338873\n",
            "Rank 5: 94546339\n",
            "Rank 6: 101598636\n",
            "Rank 7: 105078785\n",
            "Rank 8: 102035322\n",
            "Rank 9: 84923580\n",
            "Rank 10: 44437432\n",
            "Rank 11: 96138054\n",
            "Rank 12: 92631163\n",
            "Rank 13: 91358966\n",
            "Rank 14: 74364787\n",
            "Rank 15: 89655285\n",
            "Rank 16: 70494531\n",
            "Rank 17: 86686331\n",
            "Rank 18: 93007218\n",
            "Rank 19: 65451984\n",
            "Rank 20: 85915967\n",
            "Rank 21: 81098918\n",
            "Rank 22: 93196199\n",
            "Rank 23: 94596291\n",
            "Rank 24: 1662314\n",
            "Rank 25: 82807300\n",
            "Rank 26: 74999904\n",
            "Rank 27: 73189654\n",
            "Rank 28: 101974338\n",
            "Rank 29: 112489610\n",
            "Rank 30: 91801222\n",
            "Query ID: 75800075\n",
            "Rank 1: 34284570\n",
            "Rank 2: 84214328\n",
            "Rank 3: 76825949\n",
            "Rank 4: 75692075\n",
            "Rank 5: 7588356\n",
            "Rank 6: 81692381\n",
            "Rank 7: 74966633\n",
            "Rank 8: 70999237\n",
            "Rank 9: 62288211\n",
            "Rank 10: 43687538\n",
            "Rank 11: 34173412\n",
            "Rank 12: 64972313\n",
            "Rank 13: 73305870\n",
            "Rank 14: 35300504\n",
            "Rank 15: 81704710\n",
            "Rank 16: 87092702\n",
            "Rank 17: 93085483\n",
            "Rank 18: 86183849\n",
            "Rank 19: 22823110\n",
            "Rank 20: 71238892\n",
            "Rank 21: 77197418\n",
            "Rank 22: 62194904\n",
            "Rank 23: 73750287\n",
            "Rank 24: 77144269\n",
            "Rank 25: 61870386\n",
            "Rank 26: 33464411\n",
            "Rank 27: 35197610\n",
            "Rank 28: 43796291\n",
            "Rank 29: 43878177\n",
            "Rank 30: 35215942\n",
            "Rank 31: 7228433\n",
            "Rank 32: 76120190\n",
            "Query ID: 76109416\n",
            "Rank 1: 76109416\n",
            "Rank 2: 43845712\n",
            "Rank 3: 86772879\n",
            "Rank 4: 44149931\n",
            "Rank 5: 86120389\n",
            "Rank 6: 74871145\n",
            "Rank 7: 75226918\n",
            "Rank 8: 92580522\n",
            "Rank 9: 72024697\n",
            "Rank 10: 87097786\n",
            "Rank 11: 1212129\n",
            "Rank 12: 90897974\n",
            "Rank 13: 71010602\n",
            "Rank 14: 43237025\n",
            "Rank 15: 79148717\n",
            "Rank 16: 44268155\n",
            "Rank 17: 67929958\n",
            "Rank 18: 98417973\n",
            "Rank 19: 96952506\n",
            "Rank 20: 66358\n",
            "Rank 21: 45066980\n",
            "Rank 22: 86586319\n",
            "Rank 23: 83775044\n",
            "Rank 24: 85956111\n",
            "Rank 25: 84518942\n",
            "Rank 26: 68498126\n",
            "Rank 27: 6825461\n",
            "Rank 28: 1859328\n",
            "Rank 29: 83915124\n",
            "Rank 30: 89081482\n",
            "Query ID: 70563808\n",
            "Rank 1: 70563808\n",
            "Rank 2: 43891147\n",
            "Rank 3: 77540953\n",
            "Rank 4: 66791385\n",
            "Rank 5: 87318046\n",
            "Rank 6: 73843030\n",
            "Rank 7: 6383581\n",
            "Rank 8: 72133315\n",
            "Rank 9: 105795426\n",
            "Rank 10: 69551594\n",
            "Rank 11: 62199485\n",
            "Rank 12: 86860100\n",
            "Rank 13: 45525493\n",
            "Rank 14: 66478420\n",
            "Rank 15: 59356913\n",
            "Rank 16: 43824316\n",
            "Rank 17: 7445616\n",
            "Rank 18: 76578541\n",
            "Rank 19: 7949497\n",
            "Rank 20: 61287856\n",
            "Rank 21: 45039835\n",
            "Rank 22: 46288752\n",
            "Rank 23: 78164659\n",
            "Rank 24: 7706134\n",
            "Rank 25: 75429864\n",
            "Rank 26: 14687460\n",
            "Rank 27: 6936022\n",
            "Rank 28: 44519425\n",
            "Rank 29: 13902208\n",
            "Rank 30: 1651911\n",
            "Rank 31: 7807387\n",
            "Rank 32: 8125158\n",
            "Rank 33: 45760699\n",
            "Rank 34: 7728171\n",
            "Rank 35: 7305297\n",
            "Query ID: 72214279\n",
            "Rank 1: 73313951\n",
            "Rank 2: 78285896\n",
            "Rank 3: 77750612\n",
            "Rank 4: 78874284\n",
            "Rank 5: 66704376\n",
            "Rank 6: 74719750\n",
            "Rank 7: 86201489\n",
            "Rank 8: 66704221\n",
            "Rank 9: 66859488\n",
            "Rank 10: 70443794\n",
            "Rank 11: 7323805\n",
            "Rank 12: 76635780\n",
            "Rank 13: 6786492\n",
            "Rank 14: 1024924\n",
            "Rank 15: 5188978\n",
            "Rank 16: 97541974\n",
            "Rank 17: 7024647\n",
            "Rank 18: 61941302\n",
            "Rank 19: 7409445\n",
            "Rank 20: 95087186\n",
            "Rank 21: 80491195\n",
            "Rank 22: 43855508\n",
            "Rank 23: 62204608\n",
            "Rank 24: 73575071\n",
            "Rank 25: 4112132\n",
            "Rank 26: 7186024\n",
            "Rank 27: 1052098\n",
            "Rank 28: 7126783\n",
            "Rank 29: 7185266\n",
            "Rank 30: 95793433\n",
            "Query ID: 85685768\n",
            "Rank 1: 101485622\n",
            "Rank 2: 101540987\n",
            "Rank 3: 7874471\n",
            "Rank 4: 103242931\n",
            "Rank 5: 92906077\n",
            "Rank 6: 92933013\n",
            "Rank 7: 90415246\n",
            "Rank 8: 96992323\n",
            "Rank 9: 91034639\n",
            "Rank 10: 91230085\n",
            "Rank 11: 94616956\n",
            "Rank 12: 22854327\n",
            "Rank 13: 93463606\n",
            "Rank 14: 86711677\n",
            "Rank 15: 6716158\n",
            "Rank 16: 43124738\n",
            "Rank 17: 87659292\n",
            "Rank 18: 92322829\n",
            "Rank 19: 5399125\n",
            "Rank 20: 91467629\n",
            "Rank 21: 22926275\n",
            "Rank 22: 71483822\n",
            "Rank 23: 79386554\n",
            "Rank 24: 68036945\n",
            "Rank 25: 44105210\n",
            "Rank 26: 98140923\n",
            "Rank 27: 100252809\n",
            "Rank 28: 43287174\n",
            "Rank 29: 80775193\n",
            "Rank 30: 91796062\n",
            "Query ID: 79740635\n",
            "Rank 1: 80463331\n",
            "Rank 2: 64815601\n",
            "Rank 3: 75024859\n",
            "Rank 4: 80126462\n",
            "Rank 5: 62141731\n",
            "Rank 6: 89202129\n",
            "Rank 7: 32931094\n",
            "Rank 8: 89202146\n",
            "Rank 9: 81276441\n",
            "Rank 10: 77324818\n",
            "Rank 11: 33473034\n",
            "Rank 12: 98938772\n",
            "Rank 13: 33448504\n",
            "Rank 14: 77144959\n",
            "Rank 15: 79096739\n",
            "Rank 16: 71772339\n",
            "Rank 17: 97072553\n",
            "Rank 18: 94502562\n",
            "Rank 19: 20176022\n",
            "Rank 20: 69278139\n",
            "Rank 21: 7582109\n",
            "Rank 22: 72282319\n",
            "Rank 23: 22271872\n",
            "Rank 24: 43110403\n",
            "Rank 25: 77783945\n",
            "Rank 26: 83374518\n",
            "Rank 27: 6507475\n",
            "Rank 28: 64764746\n",
            "Rank 29: 32251980\n",
            "Rank 30: 69050704\n",
            "Rank 31: 80781908\n",
            "Rank 32: 7937000\n",
            "Rank 33: 13938283\n",
            "Rank 34: 7332283\n",
            "Rank 35: 82301362\n",
            "Query ID: 100251983\n",
            "Rank 1: 100251983\n",
            "Rank 2: 91560811\n",
            "Rank 3: 90490909\n",
            "Rank 4: 93331965\n",
            "Rank 5: 82206845\n",
            "Rank 6: 88392348\n",
            "Rank 7: 96091957\n",
            "Rank 8: 82028496\n",
            "Rank 9: 89295990\n",
            "Rank 10: 93007808\n",
            "Rank 11: 107325691\n",
            "Rank 12: 106996649\n",
            "Rank 13: 96059580\n",
            "Rank 14: 97292661\n",
            "Rank 15: 89672703\n",
            "Rank 16: 78872192\n",
            "Rank 17: 72140435\n",
            "Rank 18: 100515176\n",
            "Rank 19: 33473034\n",
            "Rank 20: 90670288\n",
            "Rank 21: 45282121\n",
            "Rank 22: 94669658\n",
            "Rank 23: 104436949\n",
            "Rank 24: 94029448\n",
            "Rank 25: 86073872\n",
            "Rank 26: 78547811\n",
            "Rank 27: 98600374\n",
            "Rank 28: 46598360\n",
            "Rank 29: 80167129\n",
            "Rank 30: 88463494\n",
            "Query ID: 68249923\n",
            "Rank 1: 86874453\n",
            "Rank 2: 35300504\n",
            "Rank 3: 86319625\n",
            "Rank 4: 43783883\n",
            "Rank 5: 22791064\n",
            "Rank 6: 45407719\n",
            "Rank 7: 94133702\n",
            "Rank 8: 4102206\n",
            "Rank 9: 65179742\n",
            "Rank 10: 95326577\n",
            "Rank 11: 61870386\n",
            "Rank 12: 35215942\n",
            "Rank 13: 92458890\n",
            "Rank 14: 73750287\n",
            "Rank 15: 89313603\n",
            "Rank 16: 73350347\n",
            "Rank 17: 66204675\n",
            "Rank 18: 1880329\n",
            "Rank 19: 7503954\n",
            "Rank 20: 75001201\n",
            "Rank 21: 44330428\n",
            "Rank 22: 80790764\n",
            "Rank 23: 4811621\n",
            "Rank 24: 7191590\n",
            "Rank 25: 84067048\n",
            "Rank 26: 68984248\n",
            "Rank 27: 13900435\n",
            "Rank 28: 35246469\n",
            "Rank 29: 96103327\n",
            "Rank 30: 22538180\n",
            "Rank 31: 17811615\n",
            "Rank 32: 80619246\n",
            "Rank 33: 66785381\n",
            "Rank 34: 84151582\n",
            "Rank 35: 89264734\n",
            "Query ID: 79482665\n",
            "Rank 1: 71022105\n",
            "Rank 2: 84540103\n",
            "Rank 3: 83083320\n",
            "Rank 4: 93279107\n",
            "Rank 5: 93318781\n",
            "Rank 6: 73293133\n",
            "Rank 7: 88449039\n",
            "Rank 8: 44666167\n",
            "Rank 9: 92503480\n",
            "Rank 10: 95908606\n",
            "Rank 11: 93592423\n",
            "Rank 12: 73497949\n",
            "Rank 13: 87571623\n",
            "Rank 14: 6903999\n",
            "Rank 15: 81582469\n",
            "Rank 16: 4095476\n",
            "Rank 17: 68914227\n",
            "Rank 18: 103621196\n",
            "Rank 19: 46019842\n",
            "Rank 20: 67370804\n",
            "Rank 21: 86402797\n",
            "Rank 22: 88456909\n",
            "Rank 23: 102635100\n",
            "Rank 24: 93524596\n",
            "Rank 25: 110233006\n",
            "Rank 26: 87300637\n",
            "Rank 27: 87107633\n",
            "Rank 28: 72279718\n",
            "Rank 29: 89030165\n",
            "Rank 30: 70930284\n",
            "\n",
            "Saved fused results to rrf_prediction2_tfidfDesc_MPNETDesc.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. tfidf_desc + MPNET_DescFeat"
      ],
      "metadata": {
        "id": "wavW-844eWDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sparse_rankings = load_ranking(\"prediction2_tfidf_desc.json\")\n",
        "dense_rankings = load_ranking(\"prediction2_MPNET_DescFeat.json\")\n",
        "\n",
        "combined_ranking = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "\n",
        "# Iterate over the query IDs and their corresponding rankings\n",
        "for query_id, ranked_docs in combined_ranking.items():\n",
        "  print(f\"Query ID: {query_id}\")\n",
        "  for i, doc_id in enumerate(ranked_docs):\n",
        "      print(f\"Rank {i+1}: {doc_id}\") # Print rank and document ID\n",
        "\n",
        "\n",
        "# Save fused results if needed\n",
        "output_file = \"rrf_prediction2_tfidfDesc_MPNETDescFeat.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(combined_ranking, f)\n",
        "print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYDIhvNReTO6",
        "outputId": "d05cfbc5-df8a-4929-9eab-ea7edf086e76"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query ID: 103964109\n",
            "Rank 1: 87488738\n",
            "Rank 2: 87285519\n",
            "Rank 3: 104761777\n",
            "Rank 4: 110338873\n",
            "Rank 5: 94546339\n",
            "Rank 6: 101598636\n",
            "Rank 7: 105078785\n",
            "Rank 8: 102035322\n",
            "Rank 9: 84923580\n",
            "Rank 10: 44437432\n",
            "Rank 11: 96138054\n",
            "Rank 12: 92631163\n",
            "Rank 13: 91358966\n",
            "Rank 14: 74364787\n",
            "Rank 15: 89655285\n",
            "Rank 16: 70494531\n",
            "Rank 17: 86686331\n",
            "Rank 18: 93007218\n",
            "Rank 19: 65451984\n",
            "Rank 20: 85915967\n",
            "Rank 21: 81098918\n",
            "Rank 22: 93196199\n",
            "Rank 23: 94596291\n",
            "Rank 24: 1662314\n",
            "Rank 25: 82807300\n",
            "Rank 26: 74999904\n",
            "Rank 27: 73189654\n",
            "Rank 28: 101974338\n",
            "Rank 29: 112489610\n",
            "Rank 30: 91801222\n",
            "Query ID: 75800075\n",
            "Rank 1: 34284570\n",
            "Rank 2: 84214328\n",
            "Rank 3: 76825949\n",
            "Rank 4: 75692075\n",
            "Rank 5: 7588356\n",
            "Rank 6: 81692381\n",
            "Rank 7: 74966633\n",
            "Rank 8: 70999237\n",
            "Rank 9: 62288211\n",
            "Rank 10: 43687538\n",
            "Rank 11: 34173412\n",
            "Rank 12: 64972313\n",
            "Rank 13: 73305870\n",
            "Rank 14: 35300504\n",
            "Rank 15: 81704710\n",
            "Rank 16: 87092702\n",
            "Rank 17: 93085483\n",
            "Rank 18: 86183849\n",
            "Rank 19: 22823110\n",
            "Rank 20: 71238892\n",
            "Rank 21: 77197418\n",
            "Rank 22: 62194904\n",
            "Rank 23: 73750287\n",
            "Rank 24: 77144269\n",
            "Rank 25: 61870386\n",
            "Rank 26: 33464411\n",
            "Rank 27: 35197610\n",
            "Rank 28: 43796291\n",
            "Rank 29: 43878177\n",
            "Rank 30: 35215942\n",
            "Rank 31: 7228433\n",
            "Rank 32: 76120190\n",
            "Query ID: 76109416\n",
            "Rank 1: 76109416\n",
            "Rank 2: 43845712\n",
            "Rank 3: 86772879\n",
            "Rank 4: 44149931\n",
            "Rank 5: 86120389\n",
            "Rank 6: 74871145\n",
            "Rank 7: 75226918\n",
            "Rank 8: 92580522\n",
            "Rank 9: 72024697\n",
            "Rank 10: 87097786\n",
            "Rank 11: 1212129\n",
            "Rank 12: 90897974\n",
            "Rank 13: 71010602\n",
            "Rank 14: 43237025\n",
            "Rank 15: 79148717\n",
            "Rank 16: 44268155\n",
            "Rank 17: 67929958\n",
            "Rank 18: 98417973\n",
            "Rank 19: 96952506\n",
            "Rank 20: 66358\n",
            "Rank 21: 45066980\n",
            "Rank 22: 86586319\n",
            "Rank 23: 83775044\n",
            "Rank 24: 85956111\n",
            "Rank 25: 84518942\n",
            "Rank 26: 68498126\n",
            "Rank 27: 6825461\n",
            "Rank 28: 1859328\n",
            "Rank 29: 83915124\n",
            "Rank 30: 89081482\n",
            "Query ID: 70563808\n",
            "Rank 1: 70563808\n",
            "Rank 2: 43891147\n",
            "Rank 3: 77540953\n",
            "Rank 4: 66791385\n",
            "Rank 5: 87318046\n",
            "Rank 6: 73843030\n",
            "Rank 7: 6383581\n",
            "Rank 8: 72133315\n",
            "Rank 9: 105795426\n",
            "Rank 10: 69551594\n",
            "Rank 11: 62199485\n",
            "Rank 12: 86860100\n",
            "Rank 13: 45525493\n",
            "Rank 14: 66478420\n",
            "Rank 15: 59356913\n",
            "Rank 16: 43824316\n",
            "Rank 17: 7445616\n",
            "Rank 18: 76578541\n",
            "Rank 19: 7949497\n",
            "Rank 20: 61287856\n",
            "Rank 21: 45039835\n",
            "Rank 22: 46288752\n",
            "Rank 23: 78164659\n",
            "Rank 24: 7706134\n",
            "Rank 25: 75429864\n",
            "Rank 26: 14687460\n",
            "Rank 27: 6936022\n",
            "Rank 28: 44519425\n",
            "Rank 29: 13902208\n",
            "Rank 30: 1651911\n",
            "Rank 31: 7807387\n",
            "Rank 32: 8125158\n",
            "Rank 33: 45760699\n",
            "Rank 34: 7728171\n",
            "Rank 35: 7305297\n",
            "Query ID: 72214279\n",
            "Rank 1: 73313951\n",
            "Rank 2: 78285896\n",
            "Rank 3: 77750612\n",
            "Rank 4: 78874284\n",
            "Rank 5: 66704376\n",
            "Rank 6: 74719750\n",
            "Rank 7: 86201489\n",
            "Rank 8: 66704221\n",
            "Rank 9: 66859488\n",
            "Rank 10: 70443794\n",
            "Rank 11: 7323805\n",
            "Rank 12: 76635780\n",
            "Rank 13: 6786492\n",
            "Rank 14: 1024924\n",
            "Rank 15: 5188978\n",
            "Rank 16: 97541974\n",
            "Rank 17: 7024647\n",
            "Rank 18: 61941302\n",
            "Rank 19: 7409445\n",
            "Rank 20: 95087186\n",
            "Rank 21: 80491195\n",
            "Rank 22: 43855508\n",
            "Rank 23: 62204608\n",
            "Rank 24: 73575071\n",
            "Rank 25: 4112132\n",
            "Rank 26: 7186024\n",
            "Rank 27: 1052098\n",
            "Rank 28: 7126783\n",
            "Rank 29: 7185266\n",
            "Rank 30: 95793433\n",
            "Query ID: 85685768\n",
            "Rank 1: 101485622\n",
            "Rank 2: 101540987\n",
            "Rank 3: 7874471\n",
            "Rank 4: 103242931\n",
            "Rank 5: 92906077\n",
            "Rank 6: 92933013\n",
            "Rank 7: 90415246\n",
            "Rank 8: 96992323\n",
            "Rank 9: 91034639\n",
            "Rank 10: 91230085\n",
            "Rank 11: 94616956\n",
            "Rank 12: 22854327\n",
            "Rank 13: 93463606\n",
            "Rank 14: 86711677\n",
            "Rank 15: 6716158\n",
            "Rank 16: 43124738\n",
            "Rank 17: 87659292\n",
            "Rank 18: 92322829\n",
            "Rank 19: 5399125\n",
            "Rank 20: 91467629\n",
            "Rank 21: 22926275\n",
            "Rank 22: 71483822\n",
            "Rank 23: 79386554\n",
            "Rank 24: 68036945\n",
            "Rank 25: 44105210\n",
            "Rank 26: 98140923\n",
            "Rank 27: 100252809\n",
            "Rank 28: 43287174\n",
            "Rank 29: 80775193\n",
            "Rank 30: 91796062\n",
            "Query ID: 79740635\n",
            "Rank 1: 80463331\n",
            "Rank 2: 64815601\n",
            "Rank 3: 75024859\n",
            "Rank 4: 80126462\n",
            "Rank 5: 62141731\n",
            "Rank 6: 89202129\n",
            "Rank 7: 32931094\n",
            "Rank 8: 89202146\n",
            "Rank 9: 81276441\n",
            "Rank 10: 77324818\n",
            "Rank 11: 33473034\n",
            "Rank 12: 98938772\n",
            "Rank 13: 33448504\n",
            "Rank 14: 77144959\n",
            "Rank 15: 79096739\n",
            "Rank 16: 71772339\n",
            "Rank 17: 97072553\n",
            "Rank 18: 94502562\n",
            "Rank 19: 20176022\n",
            "Rank 20: 69278139\n",
            "Rank 21: 7582109\n",
            "Rank 22: 72282319\n",
            "Rank 23: 22271872\n",
            "Rank 24: 43110403\n",
            "Rank 25: 77783945\n",
            "Rank 26: 83374518\n",
            "Rank 27: 6507475\n",
            "Rank 28: 64764746\n",
            "Rank 29: 32251980\n",
            "Rank 30: 69050704\n",
            "Rank 31: 80781908\n",
            "Rank 32: 7937000\n",
            "Rank 33: 13938283\n",
            "Rank 34: 7332283\n",
            "Rank 35: 82301362\n",
            "Query ID: 100251983\n",
            "Rank 1: 100251983\n",
            "Rank 2: 91560811\n",
            "Rank 3: 90490909\n",
            "Rank 4: 93331965\n",
            "Rank 5: 82206845\n",
            "Rank 6: 88392348\n",
            "Rank 7: 96091957\n",
            "Rank 8: 82028496\n",
            "Rank 9: 89295990\n",
            "Rank 10: 93007808\n",
            "Rank 11: 107325691\n",
            "Rank 12: 106996649\n",
            "Rank 13: 96059580\n",
            "Rank 14: 97292661\n",
            "Rank 15: 89672703\n",
            "Rank 16: 78872192\n",
            "Rank 17: 72140435\n",
            "Rank 18: 100515176\n",
            "Rank 19: 33473034\n",
            "Rank 20: 90670288\n",
            "Rank 21: 45282121\n",
            "Rank 22: 94669658\n",
            "Rank 23: 104436949\n",
            "Rank 24: 94029448\n",
            "Rank 25: 86073872\n",
            "Rank 26: 78547811\n",
            "Rank 27: 98600374\n",
            "Rank 28: 46598360\n",
            "Rank 29: 80167129\n",
            "Rank 30: 88463494\n",
            "Query ID: 68249923\n",
            "Rank 1: 86874453\n",
            "Rank 2: 35300504\n",
            "Rank 3: 86319625\n",
            "Rank 4: 43783883\n",
            "Rank 5: 22791064\n",
            "Rank 6: 45407719\n",
            "Rank 7: 94133702\n",
            "Rank 8: 4102206\n",
            "Rank 9: 65179742\n",
            "Rank 10: 95326577\n",
            "Rank 11: 61870386\n",
            "Rank 12: 35215942\n",
            "Rank 13: 92458890\n",
            "Rank 14: 73750287\n",
            "Rank 15: 89313603\n",
            "Rank 16: 73350347\n",
            "Rank 17: 66204675\n",
            "Rank 18: 1880329\n",
            "Rank 19: 7503954\n",
            "Rank 20: 75001201\n",
            "Rank 21: 44330428\n",
            "Rank 22: 80790764\n",
            "Rank 23: 4811621\n",
            "Rank 24: 7191590\n",
            "Rank 25: 84067048\n",
            "Rank 26: 68984248\n",
            "Rank 27: 13900435\n",
            "Rank 28: 35246469\n",
            "Rank 29: 96103327\n",
            "Rank 30: 22538180\n",
            "Rank 31: 17811615\n",
            "Rank 32: 80619246\n",
            "Rank 33: 66785381\n",
            "Rank 34: 84151582\n",
            "Rank 35: 89264734\n",
            "Query ID: 79482665\n",
            "Rank 1: 71022105\n",
            "Rank 2: 84540103\n",
            "Rank 3: 83083320\n",
            "Rank 4: 93279107\n",
            "Rank 5: 93318781\n",
            "Rank 6: 73293133\n",
            "Rank 7: 88449039\n",
            "Rank 8: 44666167\n",
            "Rank 9: 92503480\n",
            "Rank 10: 95908606\n",
            "Rank 11: 93592423\n",
            "Rank 12: 73497949\n",
            "Rank 13: 87571623\n",
            "Rank 14: 6903999\n",
            "Rank 15: 81582469\n",
            "Rank 16: 4095476\n",
            "Rank 17: 68914227\n",
            "Rank 18: 103621196\n",
            "Rank 19: 46019842\n",
            "Rank 20: 67370804\n",
            "Rank 21: 86402797\n",
            "Rank 22: 88456909\n",
            "Rank 23: 102635100\n",
            "Rank 24: 93524596\n",
            "Rank 25: 110233006\n",
            "Rank 26: 87300637\n",
            "Rank 27: 87107633\n",
            "Rank 28: 72279718\n",
            "Rank 29: 89030165\n",
            "Rank 30: 70930284\n",
            "\n",
            "Saved fused results to rrf_prediction2_tfidfDesc_MPNETDescFeat.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "froCg-Saegpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61cb35bdd0054306a0fab00696baddc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e765b654c6024b35b240729963243dd0",
              "IPY_MODEL_1992f80ee3d64915a189161dc90bc069",
              "IPY_MODEL_358eed99e12244a796f923279ce6f87e"
            ],
            "layout": "IPY_MODEL_184721bb719a44899d5a1c82ac56bacb"
          }
        },
        "e765b654c6024b35b240729963243dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b6e3b450a3414f861760576577cecc",
            "placeholder": "​",
            "style": "IPY_MODEL_9809ffedcf0c429c8e2d958435d1a2db",
            "value": "TF-IDF: 100%"
          }
        },
        "1992f80ee3d64915a189161dc90bc069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6df8c47dd6c48c5b11d762640c7a846",
            "max": 930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e6eb149d076442cb7f41a481f1751eb",
            "value": 930
          }
        },
        "358eed99e12244a796f923279ce6f87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab091fe0f284fe6b20ba6bb369f4f83",
            "placeholder": "​",
            "style": "IPY_MODEL_7f9d6d6b23d5411984b2aebd02931b48",
            "value": " 930/930 [00:12&lt;00:00, 69.60it/s]"
          }
        },
        "184721bb719a44899d5a1c82ac56bacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b6e3b450a3414f861760576577cecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9809ffedcf0c429c8e2d958435d1a2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6df8c47dd6c48c5b11d762640c7a846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6eb149d076442cb7f41a481f1751eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ab091fe0f284fe6b20ba6bb369f4f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9d6d6b23d5411984b2aebd02931b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3ad1a6ba6f4a1d92aaf7ddb2bd2b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b09910c26588452d8ad5ec2a971d8bf8",
              "IPY_MODEL_ad2dcf1a1c84400a9a4497e90fab9d5c",
              "IPY_MODEL_49e0073037cb4be0b36ae3b4d9bf53b8"
            ],
            "layout": "IPY_MODEL_0b48ac8d7ce4483e9e5a92724fcecb1c"
          }
        },
        "b09910c26588452d8ad5ec2a971d8bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a1e85d71954aa9a1a792fabf4c3b07",
            "placeholder": "​",
            "style": "IPY_MODEL_bacd72039d9e4922acbed6a4691bbbd5",
            "value": "TF-IDF: 100%"
          }
        },
        "ad2dcf1a1c84400a9a4497e90fab9d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078ffe57d5d54b01a2f91c8e368b9a09",
            "max": 930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e78abf4620cd4a608a7998d55be65c90",
            "value": 930
          }
        },
        "49e0073037cb4be0b36ae3b4d9bf53b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b5cf3fea3704229b08ebc0c4eec14a8",
            "placeholder": "​",
            "style": "IPY_MODEL_b95080f801a3446d88d3392d57dc5f8b",
            "value": " 930/930 [00:13&lt;00:00, 70.96it/s]"
          }
        },
        "0b48ac8d7ce4483e9e5a92724fcecb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a1e85d71954aa9a1a792fabf4c3b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacd72039d9e4922acbed6a4691bbbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078ffe57d5d54b01a2f91c8e368b9a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e78abf4620cd4a608a7998d55be65c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b5cf3fea3704229b08ebc0c4eec14a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95080f801a3446d88d3392d57dc5f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}