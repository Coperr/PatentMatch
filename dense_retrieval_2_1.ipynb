{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E4iAVd-eqO5"
      },
      "source": [
        "## !! Important: Do not forget to save your notebook frequently to avoid losing your progress if the colab session crashes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVR1DtqCeqO7"
      },
      "source": [
        "### Download precalculated embedding tables\n",
        "\n",
        "We have preencoded all the texts into vectors and saved them as numpy tables to save time. You can download this zipped file to your current Google Colab working space under the `content` directory by following the steps below, ensuring it won't occupy any space in your Google Drive.\n",
        "\n",
        "However, please note that you will need to redownload it each time you quit Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxEkWrtVeqO8",
        "outputId": "c0a5d693-f322-4430-b3fa-3a092081be3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK\n",
            "From (redirected): https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK&confirm=t&uuid=2c1a5b21-9180-43fb-b3b4-39e8d4104fab\n",
            "To: /content/embeddings.tar.gz\n",
            "100% 316M/316M [00:05<00:00, 61.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download precalculated embeddings via a google drive shared link\n",
        "!gdown 'https://drive.google.com/uc?id=1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK'\n",
        "\n",
        "# if error \"failed to retrieve file url: too many users ....\" ==> solution:\n",
        "# https://stackoverflow.com/questions/65312867/how-to-download-large-file-from-google-drive-from-terminal-gdown-doesnt-work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-oVL1rHeqO9"
      },
      "source": [
        "if error \"failed to retrieve file url: too many users ....\" => solution:\n",
        "https://stackoverflow.com/questions/65312867/how-to-download-large-file-from-google-drive-from-terminal-gdown-doesnt-work\n",
        "\n",
        "\n",
        "**TODO: replace ACCESS_TOKEN in the next block** (your personal token generateed following the steps in previous solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Sc7jQDeqO9"
      },
      "outputs": [],
      "source": [
        "# ACCESS_TOKEN = \"ya29.a0Ad52N39RvcgSxR64dCWPRT2zf7ryi0ib0oPhXi7lte1Nho0Agtz0eTf7cmND4VDIQGSHw0IA6RqL_Zi1T7MsYiObSIrdn3anaSMSZPUBN1To4WSDcuPcYRkUC6xoZOdU2MkHTb_IZCQI5nOJEdY0UH20rNAG4cAXBdsvaCgYKAUgSARMSFQHGX2Mi3HfwxDpNGH4ku8ghMpfEPg0171\" # CHANGE TO YOUR OWN TOKEN\n",
        "# FILE_ID1 = \"1DHw-DdRB8xjTqvK-jU3Sol_-8VG4ACZK\" # DO NOT CHANGE\n",
        "# FILE_NAME1 = \"embeddings.tar.gz\" # DO NOT CHANGE\n",
        "\n",
        "# # print the command that you are going to run\n",
        "# print(f'! curl -H \"Authorization: Bearer {ACCESS_TOKEN}\" https://www.googleapis.com/drive/v3/files/{FILE_ID1}?alt=media -o {FILE_NAME1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6jYp-QBeqO9"
      },
      "outputs": [],
      "source": [
        "# # run the command\n",
        "# ! curl -H \"Authorization: Bearer ya29.a0Ad52N39RvcgSxR64dCWPRT2zf7ryi0ib0oPhXi7lte1Nho0Agtz0eTf7cmND4VDIQGSHw0IA6RqL_Zi1T7MsYiObSIrdn3anaSMSZPUBN1To4WSDcuPcYRkUC6xoZOdU2MkHTb_IZCQI5nOJEdY0UH20rNAG4cAXBdsvaCgYKAUgSARMSFQHGX2Mi3HfwxDpNGH4ku8ghMpfEPg0171\" https://www.googleapis.com/drive/v3/files/1ZNHJE4qXLgRLlQGYjGtpufd-56ydZfM4?alt=media -o embeddings.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDZGu7p1eqO9",
        "outputId": "c228ccbc-d8fc-45aa-9514-4a130f6dc3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_precalculated_docs/\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
            "embeddings_precalculated_train/\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
            "embeddings_precalculated_test/\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_TA.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_TA.json\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_claims.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_claims.json\n",
            "embeddings_precalculated_test/embeddings_PatentSBERTa_mean_TAC.npy\n",
            "embeddings_precalculated_test/app_ids_PatentSBERTa_mean_TAC.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
            "embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
            "embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n"
          ]
        }
      ],
      "source": [
        "# unzip the file  (may take around 10 mins)\n",
        "! tar -xvzf ./embeddings.tar.gz\n",
        "\n",
        "# remove the zip file\n",
        "! rm embeddings.tar.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6oSSGD_eqO9"
      },
      "source": [
        "### Download citation mapping\n",
        "\n",
        "You can download them in the same manner as embedding tables, or alternatively, drag them directly into the `content` directory if you've already downloaded the file to your local PC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_gfogheqO-",
        "outputId": "41c2bf6f-1f3f-4dd6-bf1c-0e2dec8c5106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun\n",
            "To: /content/citation_mapping.tar.gz\n",
            "\r  0% 0.00/264k [00:00<?, ?B/s]\r100% 264k/264k [00:00<00:00, 5.64MB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown 'https://drive.google.com/uc?id=1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nk8ZeFZeqO-"
      },
      "outputs": [],
      "source": [
        "# # same solution if error \"failed to retrieve file url: too many users ....\"\n",
        "\n",
        "# FILE_ID2 = \"1cbXtZBzBMRmLsBX4W08pCWnK0dJNYTun\" # DO NOT CHANGE\n",
        "# FILE_NAME2 = \"citation_mapping.tar.gz\" # DO NOT CHANGE\n",
        "\n",
        "# # print the command that you are going to run\n",
        "# print(f'! curl -H \"Authorization: Bearer {ACCESS_TOKEN}\" https://www.googleapis.com/drive/v3/files/{FILE_ID2}?alt=media -o {FILE_NAME2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "156Lk_CpeqO-"
      },
      "outputs": [],
      "source": [
        "## run the command\n",
        "# ! curl -H \"Authorization: Bearer ya29.a0Ad52N38YT1rg1pylsmsVav74fF8nFNaHSaIQMRNEmu47r4fdmNqf1R6GzzgavIVgLJlkwB2s1K5d2oaxq15VVb9dMIBLPhY9Ul0G4GSrP_jNgYwljBCV7oEMIAVkIatlCuoM5DBqZEfOu05aaLSvYU63Y_qsvhFWn9AaaCgYKAQMSARMSFQHGX2Mi8czeY5M2cvOV-OUbAFmYkw0171\" https://www.googleapis.com/drive/v3/files/1mOCcOmM_AcLG3qK_mxM_SYp-2OgDys-L?alt=media -o citation_mapping.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_M9T0jieqO-",
        "outputId": "2b2f2879-be36-431e-de40-45d3c9f13708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Citation_JSONs/\n",
            "Citation_JSONs/Citation_Train.json\n"
          ]
        }
      ],
      "source": [
        "# unzip the file  (may take around 10 mins)\n",
        "! tar -xvzf ./citation_mapping.tar.gz\n",
        "\n",
        "# remove the zip file\n",
        "! rm citation_mapping.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM1Pj-ioeqO-"
      },
      "source": [
        "# Dense retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cHHm-AV8eqO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si8uyrk9eqO_"
      },
      "outputs": [],
      "source": [
        "# Model settings\n",
        "MODEL_NAME = \"all-MiniLM-L6-v2\"  # Choose from: \"all-MiniLM-L6-v2\" or \"PatentSBERTa\"\n",
        "CONTENT_TYPE = \"TA\"              # Choose from: \"TA\", \"claims\", or \"TAC\"\n",
        "POOLING = \"mean\"                 # The pooling strategy used in create_embeddings.py\n",
        "QUERY_SET = \"train\"              # Choose from: \"train\" or \"test\"\n",
        "SAVE_RESULTS = False\n",
        "\n",
        "# Retrieval settings\n",
        "TOP_N = 100  # Number of documents to retrieve for each query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leXBaamIeqO_"
      },
      "outputs": [],
      "source": [
        "# Colab paths\n",
        "BASE_DIR = \"/content\"\n",
        "DOC_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_docs\")\n",
        "TRAIN_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_train\")\n",
        "TEST_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings_precalculated_test\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"results\")\n",
        "CITATION_FILE = os.path.join(BASE_DIR, \"Citation_JSONs/Citation_Train.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsFfnqzleqO_"
      },
      "outputs": [],
      "source": [
        "# Embedding files\n",
        "DOC_EMBEDDING_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.npy\")\n",
        "DOC_APP_IDS_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.json\")\n",
        "\n",
        "# Select query embedding directory based on QUERY_SET\n",
        "QUERY_EMBEDDING_DIR = TRAIN_EMBEDDING_DIR if QUERY_SET == \"train\" else TEST_EMBEDDING_DIR\n",
        "QUERY_EMBEDDING_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.npy\")\n",
        "QUERY_APP_IDS_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE}.json\")\n",
        "\n",
        "# Evaluation settings\n",
        "K_VALUE = 10  # K value for Recall@K evaluation\n",
        "METRICS_TYPE = \"all\"  # Metrics to calculate: \"recall_at_k\", \"mean_ranking\", \"mean_inv_ranking\", or \"all\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w64uFYNoeqO_"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uh1OV-OeqO_"
      },
      "outputs": [],
      "source": [
        "# === CELL: Utility functions for cosine similarity ===\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
        "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
        "    \"\"\"\n",
        "    if not isinstance(a, torch.Tensor):\n",
        "        a = torch.tensor(a)\n",
        "\n",
        "    if not isinstance(b, torch.Tensor):\n",
        "        b = torch.tensor(b)\n",
        "\n",
        "    if len(a.shape) == 1:\n",
        "        a = a.unsqueeze(0)\n",
        "\n",
        "    if len(b.shape) == 1:\n",
        "        b = b.unsqueeze(0)\n",
        "\n",
        "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
        "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
        "\n",
        "def pytorch_cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
        "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
        "    \"\"\"\n",
        "    return cos_sim(a, b)\n",
        "\n",
        "# === CELL: Utility functions for evaluation metrics ===\n",
        "def mean_recall_at_k(true_labels, predicted_labels, k=10):\n",
        "    \"\"\"\n",
        "    Calculate the mean Recall@k for a list of recommendations.\n",
        "    \"\"\"\n",
        "    recalls_at_k = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate Recall@k for each recommendation list\n",
        "        true_set = set(true)\n",
        "        k = min(k, len(pred))\n",
        "        relevant_count = sum(1 for item in pred[:k] if item in true_set)\n",
        "        recalls_at_k.append(relevant_count / len(true_set) if len(true_set) > 0 else 0)\n",
        "\n",
        "    # Calculate the mean Recall@k\n",
        "    mean_recall = sum(recalls_at_k) / len(recalls_at_k) if recalls_at_k else 0\n",
        "\n",
        "    return mean_recall\n",
        "\n",
        "def mean_inv_ranking(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Calculate the mean of lists of the mean inverse rank of true relevant items\n",
        "    in the lists of sorted recommended items.\n",
        "    \"\"\"\n",
        "    mean_ranks = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate the inverse rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        ranks = []\n",
        "        for item in true:\n",
        "            try:\n",
        "                rank = 1 / (pred.index(item) + 1)\n",
        "            except ValueError:\n",
        "                rank = 0  # If item not found, assign 0\n",
        "            ranks.append(rank)\n",
        "\n",
        "        # Calculate the mean inverse rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
        "        mean_ranks.append(mean_rank)\n",
        "\n",
        "    # Calculate the mean of the mean inverse ranks across all recommendation lists\n",
        "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
        "\n",
        "    return mean_of_mean_ranks\n",
        "\n",
        "def mean_ranking(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Calculate the mean of lists of the mean rank of true relevant items\n",
        "    in the lists of sorted recommended items.\n",
        "    \"\"\"\n",
        "    mean_ranks = []\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        # Calculate the rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        ranks = []\n",
        "        for item in true:\n",
        "            try:\n",
        "                rank = pred.index(item) + 1\n",
        "            except ValueError:\n",
        "                rank = len(pred)  # If item not found, assign the length of the list\n",
        "            ranks.append(rank)\n",
        "\n",
        "        # Calculate the mean rank of true relevant items\n",
        "        # in the recommendation list\n",
        "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
        "        mean_ranks.append(mean_rank)\n",
        "\n",
        "    # Calculate the mean of the mean ranks across all recommendation lists\n",
        "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
        "\n",
        "    return mean_of_mean_ranks\n",
        "\n",
        "# === CELL: Citation utility functions ===\n",
        "def citation_to_citing_to_cited_dict(citations):\n",
        "    \"\"\"\n",
        "    Put a citation mapping in a dict format\n",
        "    \"\"\"\n",
        "    # Initialize an empty dictionary to store the results\n",
        "    citing_to_cited_dict = {}\n",
        "\n",
        "    # Iterate over the items in the JSON list\n",
        "    for citation in citations:\n",
        "        # Check if the citing id already exists in the resulting dictionary\n",
        "        if citation[0] in citing_to_cited_dict:\n",
        "            # If the citing id exists, append the cited id to the existing list\n",
        "            citing_to_cited_dict[citation[0]].append(citation[2])\n",
        "        else:\n",
        "            # If the citing id doesn't exist, create a new list with the cited id for that citing id\n",
        "            citing_to_cited_dict[citation[0]] = [citation[2]]\n",
        "\n",
        "    return citing_to_cited_dict\n",
        "\n",
        "def get_true_and_predicted(citing_to_cited_dict, recommendations_dict):\n",
        "    \"\"\"\n",
        "    Get the true and predicted labels for the metrics calculation.\n",
        "    \"\"\"\n",
        "    # Initialize lists to store true labels and predicted labels\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    not_in_citation_mapping = 0\n",
        "\n",
        "    # Iterate over the items in both dictionaries\n",
        "    for citing_id in recommendations_dict.keys():\n",
        "        # Check if the citing_id is present in both dictionaries\n",
        "        if citing_id in citing_to_cited_dict:\n",
        "            # If yes, append the recommended items from both dictionaries to the respective lists\n",
        "            true_labels.append(citing_to_cited_dict[citing_id])\n",
        "            predicted_labels.append(recommendations_dict[citing_id])\n",
        "        else:\n",
        "            print(citing_id, \"not in citation mapping\")\n",
        "            not_in_citation_mapping += 1\n",
        "\n",
        "    return true_labels, predicted_labels, not_in_citation_mapping\n",
        "\n",
        "# === CELL: Function to load embeddings ===\n",
        "def load_embeddings_and_ids(embedding_file, app_ids_file):\n",
        "    \"\"\"\n",
        "    Load the embeddings and application IDs from saved files\n",
        "    \"\"\"\n",
        "    print(f\"Loading embeddings from {embedding_file}\")\n",
        "    embeddings = torch.from_numpy(np.load(embedding_file))\n",
        "\n",
        "    print(f\"Loading app_ids from {app_ids_file}\")\n",
        "    with open(app_ids_file, 'r') as f:\n",
        "        app_ids = json.load(f)\n",
        "\n",
        "    print(f\"Loaded {len(embeddings)} embeddings and {len(app_ids)} app_ids\")\n",
        "    return embeddings, app_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_57rjN4LeqO_"
      },
      "source": [
        "## Load document and query embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-G7iCVreqPA",
        "outputId": "a77b3de9-da62-490d-d0d5-05b9f405f0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings from /content/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "Loading app_ids from /content/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "Loaded 16837 embeddings and 16837 app_ids\n",
            "Loading embeddings from /content/embeddings_precalculated_test/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
            "Loading app_ids from /content/embeddings_precalculated_test/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
            "Loaded 1000 embeddings and 1000 app_ids\n",
            "Running retrieval with 1000 queries against 16837 documents\n"
          ]
        }
      ],
      "source": [
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# Load document embeddings and app_ids\n",
        "doc_embeddings, doc_app_ids = load_embeddings_and_ids(DOC_EMBEDDING_FILE, DOC_APP_IDS_FILE)\n",
        "\n",
        "# Load query embeddings and app_ids\n",
        "query_embeddings, query_app_ids = load_embeddings_and_ids(QUERY_EMBEDDING_FILE, QUERY_APP_IDS_FILE)\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "doc_embeddings = doc_embeddings.to(device)\n",
        "query_embeddings = query_embeddings.to(device)\n",
        "\n",
        "print(f\"Running retrieval with {len(query_embeddings)} queries against {len(doc_embeddings)} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4KnUoieqPA",
        "outputId": "3acfb72c-9038-4ce1-8835-f2db841bc0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100 results for query 3708804A1:\n",
            "App ID: 2169237A2, Similarity: 0.6300\n",
            "App ID: 3543539A1, Similarity: 0.6215\n",
            "App ID: 3067624A1, Similarity: 0.6027\n",
            "App ID: 3444468A1, Similarity: 0.5983\n",
            "App ID: 3034804A1, Similarity: 0.5953\n",
            "App ID: 3290716A1, Similarity: 0.5943\n",
            "App ID: 2224100A2, Similarity: 0.5932\n",
            "App ID: 3216987A1, Similarity: 0.5848\n",
            "App ID: 2540994A1, Similarity: 0.5845\n",
            "App ID: 3187692A1, Similarity: 0.5804\n",
            "App ID: 2631434A2, Similarity: 0.5801\n",
            "App ID: 3269930A1, Similarity: 0.5798\n",
            "App ID: 3184750A1, Similarity: 0.5789\n",
            "App ID: 3034794A1, Similarity: 0.5770\n",
            "App ID: 2402616A1, Similarity: 0.5752\n",
            "App ID: 1788688B1, Similarity: 0.5749\n",
            "App ID: 2792850A1, Similarity: 0.5731\n",
            "App ID: 3382280A1, Similarity: 0.5729\n",
            "App ID: 3098382A1, Similarity: 0.5721\n",
            "App ID: 2746536A1, Similarity: 0.5719\n",
            "App ID: 3441618A1, Similarity: 0.5714\n",
            "App ID: 3163025A1, Similarity: 0.5709\n",
            "App ID: 2716914A1, Similarity: 0.5660\n",
            "App ID: 3321474A1, Similarity: 0.5659\n",
            "App ID: 2905477A1, Similarity: 0.5653\n",
            "App ID: 2851568A1, Similarity: 0.5653\n",
            "App ID: 3112592A1, Similarity: 0.5650\n",
            "App ID: 3361053A1, Similarity: 0.5638\n",
            "App ID: 1903287B1, Similarity: 0.5635\n",
            "App ID: 2410186A1, Similarity: 0.5621\n",
            "App ID: 2157289A2, Similarity: 0.5605\n",
            "App ID: 3034797A1, Similarity: 0.5583\n",
            "App ID: 3228856A1, Similarity: 0.5579\n",
            "App ID: 3611352A2, Similarity: 0.5577\n",
            "App ID: 3032068A1, Similarity: 0.5552\n",
            "App ID: 2354459A2, Similarity: 0.5552\n",
            "App ID: 3409895A1, Similarity: 0.5549\n",
            "App ID: 2905118A1, Similarity: 0.5538\n",
            "App ID: 2803825A1, Similarity: 0.5521\n",
            "App ID: 3401505A1, Similarity: 0.5520\n",
            "App ID: 2610378A1, Similarity: 0.5513\n",
            "App ID: 3388636A1, Similarity: 0.5509\n",
            "App ID: 3032176A1, Similarity: 0.5505\n",
            "App ID: 3156610A1, Similarity: 0.5500\n",
            "App ID: 3333403A1, Similarity: 0.5492\n",
            "App ID: 2206956A2, Similarity: 0.5491\n",
            "App ID: 3081759A1, Similarity: 0.5483\n",
            "App ID: 3085923A1, Similarity: 0.5463\n",
            "App ID: 3034796A1, Similarity: 0.5456\n",
            "App ID: 2657482A1, Similarity: 0.5453\n",
            "App ID: 3321489A1, Similarity: 0.5450\n",
            "App ID: 3382240A1, Similarity: 0.5445\n",
            "App ID: 3404233A1, Similarity: 0.5438\n",
            "App ID: 1795755B1, Similarity: 0.5409\n",
            "App ID: 2944772A1, Similarity: 0.5391\n",
            "App ID: 2567754A1, Similarity: 0.5367\n",
            "App ID: 2784267A2, Similarity: 0.5365\n",
            "App ID: 3587740A1, Similarity: 0.5363\n",
            "App ID: 3415437A1, Similarity: 0.5362\n",
            "App ID: 3553283A1, Similarity: 0.5356\n",
            "App ID: 3196481A1, Similarity: 0.5348\n",
            "App ID: 3187691A1, Similarity: 0.5347\n",
            "App ID: 2587026A2, Similarity: 0.5344\n",
            "App ID: 3557003A1, Similarity: 0.5336\n",
            "App ID: 2390178A2, Similarity: 0.5290\n",
            "App ID: 3318720A1, Similarity: 0.5283\n",
            "App ID: 2463483A2, Similarity: 0.5279\n",
            "App ID: 3115590A1, Similarity: 0.5277\n",
            "App ID: 2615338A1, Similarity: 0.5276\n",
            "App ID: 1942305B1, Similarity: 0.5268\n",
            "App ID: 3260687A1, Similarity: 0.5246\n",
            "App ID: 2221486A2, Similarity: 0.5242\n",
            "App ID: 1741935B1, Similarity: 0.5235\n",
            "App ID: 3015772A1, Similarity: 0.5235\n",
            "App ID: 2369043A2, Similarity: 0.5229\n",
            "App ID: 1750001B1, Similarity: 0.5201\n",
            "App ID: 3115576A1, Similarity: 0.5199\n",
            "App ID: 2570629A1, Similarity: 0.5185\n",
            "App ID: 2405206A1, Similarity: 0.5180\n",
            "App ID: 3070336A1, Similarity: 0.5176\n",
            "App ID: 3269947A1, Similarity: 0.5170\n",
            "App ID: 2940307A1, Similarity: 0.5160\n",
            "App ID: 2538140A2, Similarity: 0.5129\n",
            "App ID: 1772624B1, Similarity: 0.5118\n",
            "App ID: 3205821A1, Similarity: 0.5108\n",
            "App ID: 2295763A2, Similarity: 0.5103\n",
            "App ID: 1719637B1, Similarity: 0.5099\n",
            "App ID: 2607656A2, Similarity: 0.5098\n",
            "App ID: 2463489A1, Similarity: 0.5095\n",
            "App ID: 3211319A1, Similarity: 0.5095\n",
            "App ID: 3354889A1, Similarity: 0.5093\n",
            "App ID: 3118417A1, Similarity: 0.5087\n",
            "App ID: 2551021A1, Similarity: 0.5086\n",
            "App ID: 3315732A1, Similarity: 0.5086\n",
            "App ID: 3587751A1, Similarity: 0.5077\n",
            "App ID: 3480434A1, Similarity: 0.5074\n",
            "App ID: 2568118A1, Similarity: 0.5067\n",
            "App ID: 2243929A2, Similarity: 0.5065\n",
            "App ID: 3181824A1, Similarity: 0.5064\n",
            "App ID: 2944794A1, Similarity: 0.5059\n"
          ]
        }
      ],
      "source": [
        "def retrieve_by_app_id(target_app_id, query_app_ids, query_embeddings, doc_embeddings, doc_app_ids, top_n=10):\n",
        "    \"\"\"\n",
        "    Retrieve top N documents for a single query by its app_id\n",
        "\n",
        "    Parameters:\n",
        "    - target_app_id: The application ID of the query to search for\n",
        "    - query_app_ids: List of all query application IDs\n",
        "    - query_embeddings: Embeddings for all queries\n",
        "    - doc_embeddings: Embeddings for all documents in the corpus\n",
        "    - doc_app_ids: Application IDs for all documents\n",
        "    - top_n: Number of results to return\n",
        "\n",
        "    Returns:\n",
        "    - List of top N document app_ids similar to the query\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Find the index of the target app_id in query_app_ids\n",
        "        query_index = query_app_ids.index(target_app_id)\n",
        "\n",
        "        # Get the corresponding embedding\n",
        "        query_embedding = query_embeddings[query_index].unsqueeze(0)\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        cos_scores = pytorch_cos_sim(query_embedding, doc_embeddings)[0].cpu()\n",
        "\n",
        "        # Sort results and get top N\n",
        "        top_n_index = torch.argsort(cos_scores, descending=True)[:top_n].numpy()\n",
        "\n",
        "        # Get application IDs of top N documents\n",
        "        top_n_app_ids = [doc_app_ids[i] for i in top_n_index]\n",
        "        top_n_scores = [cos_scores[i].item() for i in top_n_index]\n",
        "\n",
        "        return top_n_app_ids, top_n_scores\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Error: Application ID '{target_app_id}' not found in query_app_ids\")\n",
        "        return [], []\n",
        "\n",
        "# Example usage\n",
        "target_app_id = query_app_ids[0]  # Replace with the specific app_id you want to query\n",
        "retrieved_app_ids, similarity_scores = retrieve_by_app_id(\n",
        "    target_app_id,\n",
        "    query_app_ids,\n",
        "    query_embeddings,\n",
        "    doc_embeddings,\n",
        "    doc_app_ids,\n",
        "    top_n=TOP_N\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(f\"Top {TOP_N} results for query {target_app_id}:\")\n",
        "for app_id, score in zip(retrieved_app_ids, similarity_scores):\n",
        "    print(f\"App ID: {app_id}, Similarity: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6IoJ7FHeqPA"
      },
      "source": [
        "## Perform retrieval for each query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIxU_ZLOeqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90b904a-57ea-477c-cdc7-63e1a7b830b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 472.21it/s]\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "for i, (query_embedding, query_id) in enumerate(tqdm(zip(query_embeddings, query_app_ids), total=len(query_embeddings))):\n",
        "    # Compute cosine similarity\n",
        "    query_embedding = query_embedding.unsqueeze(0)\n",
        "    cos_scores = pytorch_cos_sim(query_embedding, doc_embeddings)[0].cpu()\n",
        "\n",
        "    # Sort results and get top N\n",
        "    top_n_index = torch.argsort(cos_scores, descending=True)[:TOP_N].numpy()\n",
        "\n",
        "    # Get application IDs of top N documents\n",
        "    top_n_app_ids = [doc_app_ids[i] for i in top_n_index]\n",
        "    results[query_id] = top_n_app_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVtXsgC0eqPA"
      },
      "source": [
        "## Save results (if applicable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzMZZgU7eqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c05e55-a799-40d9-a426-f2df944486bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved retrieval results to /content/results/prediction1.json\n"
          ]
        }
      ],
      "source": [
        "if QUERY_SET == \"train\":\n",
        "    output_file = f\"{OUTPUT_DIR}/{MODEL_NAME}_{CONTENT_TYPE}_{QUERY_SET}_retrieved.json\"\n",
        "else:\n",
        "    output_file = f\"{OUTPUT_DIR}/prediction1.json\"  # Standard filename for test predictions\n",
        "\n",
        "if SAVE_RESULTS:\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f)\n",
        "    print(f\"Saved retrieval results to {output_file}\")\n",
        "else:\n",
        "    print(f\"Results not saved (SAVE_RESULTS={SAVE_RESULTS})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVZ9FwoReqPA"
      },
      "source": [
        "## Evaluation (for training set only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LZOd-6JeqPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a7fc84-3e52-489e-c08b-799ad0b33e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating train set results...\n",
            "Loading citation data from /content/Citation_JSONs/Citation_Train.json\n",
            "\n",
            "Evaluation Results:\n",
            "-------------------\n",
            "Recall@10: 0.5459\n",
            "Mean Ranking: 29.5900\n",
            "Mean Inverse Ranking: 0.3453\n",
            "\n",
            "Number of patents measured: 6831\n",
            "Number of patents not in citation mapping: 0\n"
          ]
        }
      ],
      "source": [
        "if QUERY_SET == \"train\":\n",
        "    print(\"Evaluating train set results...\")\n",
        "\n",
        "    # Load citation mapping\n",
        "    print(f\"Loading citation data from {CITATION_FILE}\")\n",
        "    with open(CITATION_FILE, 'r') as f:\n",
        "        citations = json.load(f)\n",
        "\n",
        "    # Convert citations to citing-to-cited dictionary\n",
        "    citing_to_cited_dict = citation_to_citing_to_cited_dict(citations)\n",
        "\n",
        "    # Get true and predicted labels\n",
        "    true_labels, predicted_labels, not_in_citation_mapping = get_true_and_predicted(\n",
        "        citing_to_cited_dict, results\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(\"-------------------\")\n",
        "\n",
        "    if METRICS_TYPE in ['recall_at_k', 'all']:\n",
        "        recall_at_k = mean_recall_at_k(true_labels, predicted_labels, k=K_VALUE)\n",
        "        print(f\"Recall@{K_VALUE}: {recall_at_k:.4f}\")\n",
        "\n",
        "    if METRICS_TYPE in ['mean_ranking', 'all']:\n",
        "        mean_rank = mean_ranking(true_labels, predicted_labels)\n",
        "        print(f\"Mean Ranking: {mean_rank:.4f}\")\n",
        "\n",
        "    if METRICS_TYPE in ['mean_inv_ranking', 'all']:\n",
        "        mean_inv_rank = mean_inv_ranking(true_labels, predicted_labels)\n",
        "        print(f\"Mean Inverse Ranking: {mean_inv_rank:.4f}\")\n",
        "\n",
        "    print(f\"\\nNumber of patents measured: {len(predicted_labels)}\")\n",
        "    print(f\"Number of patents not in citation mapping: {not_in_citation_mapping}\")\n",
        "else:\n",
        "    print(\"\\nTest set retrieval completed. No evaluation performed.\")\n",
        "    if SAVE_RESULTS:\n",
        "        print(f\"Predictions saved to {OUTPUT_DIR}/prediction1.json\")\n",
        "    print(\"Note: For the test set, citation data is not available for evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcXigwGceqPA"
      },
      "source": [
        "# TODOs : Reciprocal Rank Fusion and Embedding Combinations\n",
        "\n",
        "## Reciprocal Rank Fusion (RRF)\n",
        "\n",
        "Reciprocal Rank Fusion is a simple yet effective method for combining multiple ranking lists. Instead of using raw scores from different retrieval systems, RRF uses the *positions* of documents in each ranking list:\n",
        "\n",
        "1. For each document in any of the ranking lists, calculate:\n",
        "   ```\n",
        "   RRF_score(d) = ∑ 1/(k + rank_i(d))\n",
        "   ```\n",
        "   Where `k` is a constant (typically 60) that mitigates the impact of high rankings, and `rank_i(d)` is the rank of document `d` in the i-th ranking list.\n",
        "\n",
        "2. If a document doesn't appear in a ranking list, its contribution to the sum is zero.\n",
        "\n",
        "3. Re-rank documents by their RRF scores in descending order.\n",
        "\n",
        "## Implementation Expectations\n",
        "\n",
        "Students are expected to:\n",
        "\n",
        "* Implement RRF to combine rankings from different retrieval methods (sparse, dense)\n",
        "* Experiment with embedding combinations using various aggregation strategies:\n",
        "  * **Sum**: Adding embedding vectors\n",
        "  * **Average**: Taking the mean of embedding vectors\n",
        "  * **Concatenation**: Joining vectors end-to-end\n",
        "  * **Weighted combinations**: Assigning different weights to different embeddings\n",
        "\n",
        "* Try combining embeddings of the same model but different content types:\n",
        "  * PatentSBERTa TA with PatentSBERTa claims\n",
        "  * PatentSBERTa TA with PatentSBERTa TAC\n",
        "  * And other combinations\n",
        "\n",
        "## Analysis and Evaluation\n",
        "\n",
        "Your submission will be evaluated on:\n",
        "\n",
        "* **Creativity**: Exploring novel combinations and beyond standard methods\n",
        "* **Research depth**: Investigating why certain combinations work better\n",
        "* **Analysis quality**: Providing insights about which strategies perform best and why\n",
        "* **Experimental rigor**: Systematically testing different approaches\n",
        "\n",
        "The information retrieval field is rapidly evolving - creative approaches that surpass traditional methods are strongly encouraged. The most innovative and effective solution will earn the challenge bonus and valuable CV credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References:\n",
        "\n",
        "https://github.com/opensearch-project/neural-search/issues/865\n",
        "\n",
        "https://rodgerbenham.github.io/bc17-adcs.pdf\n",
        "\n",
        "https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\n",
        "\n",
        "https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a\n",
        "\n",
        "https://arxiv.org/html/2503.20698v1\n",
        "\n",
        "https://arxiv.org/pdf/2210.11934\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hLWSf4hRr52r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best spars ranking method ( from task 1)\n",
        "### using tfidf\n",
        "### using bm25"
      ],
      "metadata": {
        "id": "Z-Mijh5WvawU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of RRF algorithm"
      ],
      "metadata": {
        "id": "R9OmbO_2vGtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def reciprocal_rank_fusion(rankings_list, k=60):\n",
        "    \"\"\"\n",
        "    Combines multiple ranked lists using Reciprocal Rank Fusion\n",
        "\n",
        "    Args:\n",
        "        rankings_list (list of dict): List of dictionaries where each dict has\n",
        "            {query_id: [ordered list of document IDs]}\n",
        "        k (int): Smoothing parameter (typically 60 by default // a value used by the community)\n",
        "\n",
        "    Returns:\n",
        "        dict: {query_id: [ordered list of merged document IDs]}\n",
        "    \"\"\"\n",
        "    fused_rankings = {}\n",
        "\n",
        "    # Get all unique query IDs\n",
        "    query_ids = set.intersection(*[set(r.keys()) for r in rankings_list])\n",
        "\n",
        "    for qid in query_ids:\n",
        "        doc_scores = defaultdict(float)\n",
        "\n",
        "        # Calculate RRF scores for each ranking\n",
        "        for ranking in rankings_list:\n",
        "            ranked_docs = ranking[qid]\n",
        "            for rank_pos, doc_id in enumerate(ranked_docs):\n",
        "                doc_scores[doc_id] += 1 / (k + rank_pos + 1)  # +1 because ranks are 0-indexed\n",
        "\n",
        "        # Sort documents by descending RRF score\n",
        "        sorted_docs = sorted(doc_scores.items(), key=lambda x: -x[1])\n",
        "\n",
        "        # Extract ordered document IDs\n",
        "        fused_rankings[qid] = [doc_id for doc_id, score in sorted_docs]\n",
        "\n",
        "    return fused_rankings\n"
      ],
      "metadata": {
        "id": "1qm4gevAvPlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ranking(file_path):\n",
        "    \"\"\"Load a saved ranking from JSON file\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Load different ranking results (from previous labs)\n",
        "dense_rankings = load_ranking(\"results/prediction1.json\")  # From current dense retrieval for ranking\n",
        "sparse_rankings = load_ranking(\"results/prediction1_tfidf.json\")     # From previous sparse retrieval\n",
        "\n",
        "# Perform RRF fusion\n",
        "fused_results = reciprocal_rank_fusion([dense_rankings, sparse_rankings], k=10)\n",
        "\n",
        "# Evaluate fused results\n",
        "if QUERY_SET == \"train\":\n",
        "    true_labels, predicted_labels, _ = get_true_and_predicted(\n",
        "        citing_to_cited_dict, fused_results\n",
        "    )\n",
        "\n",
        "    print(\"\\nFused Results Evaluation:\")\n",
        "    print(f\"Recall@{K_VALUE}: {mean_recall_at_k(true_labels, predicted_labels, K_VALUE):.4f}\")\n",
        "    print(f\"Mean Inverse Rank: {mean_inv_ranking(true_labels, predicted_labels):.4f}\")\n",
        "\n",
        "# Save fused results if needed\n",
        "if SAVE_RESULTS:\n",
        "    output_file = f\"{OUTPUT_DIR}/rrf_fused_results.json\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(fused_results, f)\n",
        "    print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8I1Jpq73Jhk",
        "outputId": "065dccfc-8e15-4b1c-d925-63c046627e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved fused results to /content/results/rrf_fused_results100.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def weighted_rrf(rankings_list, weights, k=60):\n",
        "    Modified RRF with per-system weights\n",
        "    # ... same initial setup ...\n",
        "    for ranking, weight in zip(rankings_list, weights):\n",
        "        for rank_pos, doc_id in enumerate(ranking[qid]):\n",
        "            doc_scores[doc_id] += weight * (1 / (k + rank_pos + 1))\n",
        "    # ... rest remains the same ...\n",
        "\n",
        "# Usage: Give dense retrieval more weight\n",
        "fused = weighted_rrf([dense, sparse], weights=[0.7, 0.3])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wk_cqorLvxeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "8I7sF9MA96QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def reciprocal_rank_fusionC(ranking_lists, k=60):\n",
        "    \"\"\"\n",
        "    Combine multiple ranked lists using Reciprocal Rank Fusion (RRF).\n",
        "\n",
        "    Parameters:\n",
        "      ranking_lists (list of lists): Each inner list is a ranking (ordered document IDs)\n",
        "      k (int): Hyperparameter to smooth scores (commonly set to 60)\n",
        "\n",
        "    Returns:\n",
        "      List of tuples (doc_id, fused_score) sorted by descending score.\n",
        "    \"\"\"\n",
        "    fused_scores = defaultdict(float)\n",
        "\n",
        "    # For each retrieval method's ranking list\n",
        "    for ranking in ranking_lists:\n",
        "        for rank, doc_id in enumerate(ranking):\n",
        "            # Add the RRF contribution from this ranking\n",
        "            fused_scores[doc_id] += 1.0 / (k + rank + 1)\n",
        "\n",
        "    # Sort documents by their fused score (highest first)\n",
        "    fused_ranking = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return fused_ranking\n"
      ],
      "metadata": {
        "id": "rSlpsOKh964y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_rankings = load_ranking(\"results/prediction1.json\")  # From current dense retrieval for ranking\n",
        "sparse_rankings = load_ranking(\"results/prediction1_tfidf.json\")     # From previous sparse retrieval\n",
        "combined_ranking = reciprocal_rank_fusionC([dense_rankings, sparse_rankings], k=10)\n",
        "# Print top results\n",
        "for doc_id, score in combined_ranking:\n",
        "  print(doc_id, score)\n",
        "\n",
        "# Save fused results if needed\n",
        "if SAVE_RESULTS:\n",
        "    output_file = f\"{OUTPUT_DIR}/rrf_fused_results.json\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(fused_results, f)\n",
        "    print(f\"\\nSaved fused results to {output_file}\")"
      ],
      "metadata": {
        "id": "VGHSKEF5-L2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining embeddings functions:\n",
        "Experimenting with embedding combinations using various aggregation strategies:\n",
        "\n",
        "- Sum: Adding embedding vectors\n",
        "- Average: Taking the mean of embedding vectors\n",
        "- Concatenation: Joining vectors end-to-end\n",
        "- Weighted combinations: Assigning different weights to different embeddings"
      ],
      "metadata": {
        "id": "SjBanjNf_lnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model-Specific Considerations**\n",
        "\n",
        "| Model | Description | Embedding Size |\n",
        "|--------|------------|----------------|\n",
        "| `all-MiniLM-L6-v2*` | General-purpose, fast & lightweight | 384 |\n",
        "| `all-MiniLM-L12-v2*` | Larger MiniLM model for better quality | 768 |\n",
        "| `paraphrase-MiniLM-L6-v2` | Optimized for paraphrase detection | 384 |\n",
        "| `Sentence-BERT*` (`all-mpnet-base-v2`) | Strong general-purpose embeddings | 768 |\n",
        "| `PatentSBERTa*` | Specialized in patent documents | 768 |\n",
        "| `SPECTER*` | Scientific document embeddings | 768 |\n",
        "| `SimCSE*` | Contrastive learning-based embeddings | 768 |\n",
        "| `LaBSE*` | Multilingual sentence embeddings | 768 |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8Daq0EiXdEvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v-siFV9do8F",
        "outputId": "f08b885c-0168-4225-834a-c2dec2e45eef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "tar_file_path = '/content/drive/My Drive/datasets.tar'\n",
        "json_files = 'datasets'  # Assuming 'datasets' is a folder inside the tar archive\n",
        "\n",
        "try:\n",
        "  with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "    tar_ref.extractall('/content/datasets')  # Extract to a temporary directory\n",
        "\n",
        "  # Assuming 'datasets' is a folder containing your CSV file\n",
        "  df = pd.read_csv(f'/content/datasets/{json_files}/your_csv_file.csv')\n",
        "  # Replace 'your_csv_file.csv' with the actual file name\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found at {tar_file_path}\")\n",
        "except KeyError:\n",
        "  print(f\"Error: File or directory {json_files} not found inside the tar archive.\")\n",
        "except Exception as e:\n",
        "  print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaU5mzechr58",
        "outputId": "b25ae883-61d1-41db-d89e-3bcfa6fba110"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Error: File not found at /content/drive/My Drive/datasets.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        contents = json.load(file)\n",
        "    return contents\n",
        "\n",
        "json_citing_train = load_json_data(\"./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json\")\n",
        "json_citing_test = load_json_data(\"./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TEST.json\")\n",
        "\n",
        "json_nonciting = load_json_data(\"./datasets/Content_JSONs/Cited_2020_Uncited_2010-2019_Cleaned_Content_22k/CLEANED_CONTENT_DATASET_cited_patents_by_2020_uncited_2010-2019.json\")\n",
        "json_citing_to_cited = load_json_data(\"./datasets/Citation_JSONs/Citation_Train.json\") # Citing ids are unique\n"
      ],
      "metadata": {
        "id": "4Z4a7M9ah2yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python create_embeddings.py \\\n",
        "    --model \"AI-Growth-Lab/PatentSBERTa\" \\\n",
        "    --pooling mean \\\n",
        "    --input_file ./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json \\\n",
        "    --output_dir ./patentsberta_embeddings \\\n",
        "    --content_types TA,claims,TAC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7GuyHw8hHFg",
        "outputId": "af3cc578-f722-4f59-b2c1-e0c1ae67b846"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-04 11:21:06.606782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743765666.858829    6665 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743765666.921654    6665 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-04 11:21:07.402723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded 6831 documents from ./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json\n",
            "config.json: 100% 671/671 [00:00<00:00, 3.93MB/s]\n",
            "pytorch_model.bin: 100% 438M/438M [00:03<00:00, 140MB/s] \n",
            "tokenizer_config.json: 100% 440/440 [00:00<00:00, 3.01MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 6.75MB/s]\n",
            "model.safetensors:   0% 0.00/438M [00:00<?, ?B/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 18.2MB/s]\n",
            "model.safetensors:  12% 52.4M/438M [00:00<00:03, 103MB/s] \n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.67MB/s]\n",
            "model.safetensors:  17% 73.4M/438M [00:00<00:02, 130MB/s]Traceback (most recent call last):\n",
            "  File \"/content/create_embeddings.py\", line 114, in <module>\n",
            "    main()\n",
            "  File \"/content/create_embeddings.py\", line 75, in main\n",
            "    model = SentenceTransformer(modules=[base_model, pooling_model]).to('cuda')\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1343, in to\n",
            "    return self._apply(convert)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 1 more time]\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 930, in _apply\n",
            "    param_applied = fn(param)\n",
            "                    ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1329, in convert\n",
            "    return t.to(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 319, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "model.safetensors: 100% 438M/438M [00:02<00:00, 172MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation Functions\n",
        "\n",
        "def combine_sum(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by element-wise summation.\n",
        "    \"\"\"\n",
        "    return emb1 + emb2\n",
        "\n",
        "def combine_average(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by taking their element-wise average.\n",
        "    \"\"\"\n",
        "    return (emb1 + emb2) / 2\n",
        "\n",
        "def combine_concatenate(emb1, emb2):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by concatenating them along the last dimension.\n",
        "    \"\"\"\n",
        "    return np.concatenate((emb1, emb2), axis=-1)\n",
        "\n",
        "def combine_weighted(emb1, emb2, weight1=0.5, weight2=0.5):\n",
        "    \"\"\"\n",
        "    Combine two embeddings by a weighted sum.\n",
        "\n",
        "    Parameters:\n",
        "      weight1: weight for emb1\n",
        "      weight2: weight for emb2\n",
        "    \"\"\"\n",
        "    return weight1 * emb1 + weight2 * emb2\n",
        "\n",
        "# a function that takes a list of embeddings and combines them with the chosen strategy.\n",
        "def combine_multiple_embeddings(embeddings, method=\"average\", weights=None):\n",
        "    \"\"\"\n",
        "    Combine multiple embeddings using the specified method.\n",
        "\n",
        "    Parameters:\n",
        "      embeddings (list of np.array): List of embedding vectors.\n",
        "      method (str): One of \"sum\", \"average\", \"concatenate\", \"weighted\".\n",
        "      weights (list of float): Only used for \"weighted\" method. Should sum to 1.\n",
        "\n",
        "    Returns:\n",
        "      np.array: The combined embedding.\n",
        "    \"\"\"\n",
        "    if method == \"sum\":\n",
        "        combined = np.sum(embeddings, axis=0)\n",
        "    elif method == \"average\":\n",
        "        combined = np.mean(embeddings, axis=0)\n",
        "    elif method == \"concatenate\":\n",
        "        combined = np.concatenate(embeddings, axis=-1)\n",
        "    elif method == \"weighted\":\n",
        "        if weights is None or len(weights) != len(embeddings):\n",
        "            raise ValueError(\"Provide a weights list with the same length as embeddings\")\n",
        "        combined = np.zeros_like(embeddings[0], dtype=float)\n",
        "        for emb, w in zip(embeddings, weights):\n",
        "            combined += w * emb\n",
        "    else:\n",
        "        raise ValueError(\"Unknown method: choose from 'sum', 'average', 'concatenate', or 'weighted'\")\n",
        "    return combined"
      ],
      "metadata": {
        "id": "-ohgyFMP_qkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Experimental Combination Matrix"
      ],
      "metadata": {
        "id": "B4BK9dFXTuW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# List of models\n",
        "embedding_models = [\n",
        "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"sentence-transformers/all-MiniLM-L12-v2\",\n",
        "    \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
        "    \"sentence-transformers/all-mpnet-base-v2\",  # Alternative to \"Sentence-BERT\"\n",
        "    \"AI-Growth-Lab/PatentSBERTa\",  # PatentSBERTa model\n",
        "    \"allenai/specter\",  # SPECTER for scientific documents\n",
        "    \"princeton-nlp/sup-simcse-roberta-base\",  # SimCSE model\n",
        "    \"sentence-transformers/LaBSE\"  # LaBSE for multilingual embeddings\n",
        "]\n",
        "\n",
        "# just an example on text\n",
        "texts = [\n",
        "    \"Deep learning is transforming the field of artificial intelligence.\",\n",
        "    \"Patent documents contain important legal and technical information.\",\n",
        "    \"Scientific papers use complex terminology to describe research.\"\n",
        "]\n",
        "\n",
        "# Dictionary to store embeddings\n",
        "embeddings_dict = {}\n",
        "\n",
        "# Generate embeddings for each model\n",
        "for model_name in embedding_models:\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Compute embeddings\n",
        "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
        "\n",
        "    # Store embeddings\n",
        "    embeddings_dict[model_name] = embeddings\n",
        "\n",
        "    print(f\"Generated embeddings shape for {model_name}: {embeddings.shape}\")\n",
        "\n",
        "# Example: Access embeddings from a specific model\n",
        "print(\"\\nExample embedding from 'all-MiniLM-L6-v2':\")\n",
        "print(embeddings_dict[\"sentence-transformers/all-MiniLM-L6-v2\"][0])"
      ],
      "metadata": {
        "id": "2yLif3cVU-6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying Different Embedding Combinations\n",
        "\n",
        "# Suppose you have precomputed embeddings for each model. For demonstration, we'll generate random vectors.\n",
        "# In practice, load your actual embeddings from file.\n",
        "def generate_random_embedding(dim=768):\n",
        "    return np.random.rand(dim)\n",
        "\n",
        "# Create dummy embeddings for a single document/query from various models:\n",
        "embeddings = {\n",
        "    \"all-MiniLM-L6-v2\": generate_random_embedding(384),\n",
        "    \"all-MiniLM-L12-v2\": generate_random_embedding(768),\n",
        "    \"paraphrase-MiniLM-L6-v2\": generate_random_embedding(384),\n",
        "    \"Sentence-BERT\": generate_random_embedding(768),\n",
        "    \"PatentSBERTa_TA\": generate_random_embedding(768),   # Title & Abstract\n",
        "    \"PatentSBERTa_claims\": generate_random_embedding(768), # Claims\n",
        "    \"PatentSBERTa_TAC\": generate_random_embedding(768),    # Title, Abstract, Claims\n",
        "    \"SPECTER\": generate_random_embedding(768),\n",
        "    \"SimCSE\": generate_random_embedding(768),\n",
        "    \"LaBSE\": generate_random_embedding(768)\n",
        "}\n",
        "\n",
        "# Example 1: Combine PatentSBERTa TA with PatentSBERTa claims using average\n",
        "combined_patent_avg = combine_average(embeddings[\"PatentSBERTa_TA\"], embeddings[\"PatentSBERTa_claims\"])\n",
        "print(\"Combined (Average) PatentSBERTa TA + claims:\", combined_patent_avg.shape)\n",
        "\n",
        "# Example 2: Combine PatentSBERTa TA with PatentSBERTa TAC using weighted sum (e.g., give more weight to TA)\n",
        "combined_patent_weighted = combine_weighted(embeddings[\"PatentSBERTa_TA\"], embeddings[\"PatentSBERTa_TAC\"],\n",
        "                                            weight1=0.7, weight2=0.3)\n",
        "print(\"Combined (Weighted) PatentSBERTa TA + TAC:\", combined_patent_weighted.shape)\n",
        "\n",
        "# Example 3: Concatenate embeddings from two different models, e.g., all-MiniLM-L6-v2 and Sentence-BERT\n",
        "combined_concat = combine_concatenate(embeddings[\"all-MiniLM-L6-v2\"], embeddings[\"Sentence-BERT\"])\n",
        "print(\"Combined (Concatenation) all-MiniLM-L6-v2 + Sentence-BERT:\", combined_concat.shape)\n",
        "\n",
        "# Example 4: Combine multiple embeddings from different models using the generic function.\n",
        "# Here, we combine embeddings from three models with the \"weighted\" method.\n",
        "selected_models = [\"SPECTER\", \"SimCSE\", \"LaBSE\"]\n",
        "selected_embeddings = [embeddings[m] for m in selected_models]\n",
        "# For instance, we set weights such that they sum to 1:\n",
        "weights = [0.4, 0.35, 0.25]\n",
        "combined_multiple_weighted = combine_multiple_embeddings(selected_embeddings, method=\"weighted\", weights=weights)\n",
        "print(\"Combined (Weighted) SPECTER + SimCSE + LaBSE:\", combined_multiple_weighted.shape)\n",
        "\n",
        "# Example 5: Combining multiple embeddings using concatenation\n",
        "combined_multiple_concat = combine_multiple_embeddings(selected_embeddings, method=\"concatenate\")\n",
        "print(\"Combined (Concatenation) SPECTER + SimCSE + LaBSE:\", combined_multiple_concat.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWI_XiajVNth",
        "outputId": "b7ab1143-64b3-49e5-fdc1-d651fdaa90ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined (Average) PatentSBERTa TA + claims: (768,)\n",
            "Combined (Weighted) PatentSBERTa TA + TAC: (768,)\n",
            "Combined (Concatenation) all-MiniLM-L6-v2 + Sentence-BERT: (1152,)\n",
            "Combined (Weighted) SPECTER + SimCSE + LaBSE: (768,)\n",
            "Combined (Concatenation) SPECTER + SimCSE + LaBSE: (2304,)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}